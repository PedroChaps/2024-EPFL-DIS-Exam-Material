{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce735581",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-15T16:25:29.044684Z",
     "iopub.status.busy": "2023-12-15T16:25:29.044114Z",
     "iopub.status.idle": "2023-12-15T16:25:32.414304Z",
     "shell.execute_reply": "2023-12-15T16:25:32.412840Z"
    },
    "papermill": {
     "duration": 3.380725,
     "end_time": "2023-12-15T16:25:32.417679",
     "exception": false,
     "start_time": "2023-12-15T16:25:29.036954",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# IMPORT STUFF\n",
    "import pandas as pd\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "import string\n",
    "import math\n",
    "from collections import Counter\n",
    "import json\n",
    "import os\n",
    "import ast\n",
    "import multiprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2840b206",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:25:32.431755Z",
     "iopub.status.busy": "2023-12-15T16:25:32.431122Z",
     "iopub.status.idle": "2023-12-15T16:25:32.437226Z",
     "shell.execute_reply": "2023-12-15T16:25:32.435933Z"
    },
    "papermill": {
     "duration": 0.015117,
     "end_time": "2023-12-15T16:25:32.439951",
     "exception": false,
     "start_time": "2023-12-15T16:25:32.424834",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# SET SOME GLOBAL VARIABLES\n",
    "QUERIES_PATH = \"/kaggle/input/dis2023-project1-data/queries.jsonl\"\n",
    "CORPUS_PATH = \"/kaggle/input/dis2023-project1-data/corpus.jsonl\"\n",
    "SAVEFILE_PATH = '/kaggle/input/savefile-txt/savefile.txt'\n",
    "SAVEFILE_QUERIES_PATH = '/kaggle/input/savefile-queries-txt/savefile_queries.txt'\n",
    "RESULTS_PATH = '/kaggle/working/submission.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "95dd1b9e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:25:32.452151Z",
     "iopub.status.busy": "2023-12-15T16:25:32.451188Z",
     "iopub.status.idle": "2023-12-15T16:25:32.464098Z",
     "shell.execute_reply": "2023-12-15T16:25:32.462908Z"
    },
    "papermill": {
     "duration": 0.021278,
     "end_time": "2023-12-15T16:25:32.466543",
     "exception": false,
     "start_time": "2023-12-15T16:25:32.445265",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 1e+03 ns, total: 5 µs\n",
      "Wall time: 7.87 µs\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "' Commented as we have preprocessed files as part of the input\\n\\n# TOKENIZE CORPUS TEXTS AND SAVE TO SAVE-FILE\\nif not os.path.exists(SAVEFILE_PATH):\\n    with open(CORPUS_PATH) as f:\\n        raw_corpus = f.readlines()\\n        corpus = [json.loads(q) for q in raw_corpus]\\n        \\n    stemmer = PorterStemmer() \\n    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\\n\\n    f = open(SAVEFILE_PATH, \"a\")\\n    def tokenizeAndSave(nr, text):\\n        text = text.strip().translate(trans)\\n        tokens = nltk.word_tokenize(text)\\n        stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words(\\'english\\')]\\n        f.write(str(nr) + \",\" + \\' \\'.join(stemmed) + \"\\n\")\\n\\n    for c in corpus:\\n        tokenizeAndSave(int(c[\"_id\"]), c[\"text\"])\\n    f.close()\\n\\n# TOKENIZE QUERIES AND SAVE TO SAVE-FILE\\nif not os.path.exists(SAVEFILE_QUERIES_PATH):\\n    queries = dict()\\n    with open(QUERIES_PATH) as f:\\n        raw_queries = f.readlines()\\n        for q in raw_queries:\\n            obj = json.loads(q)\\n            queries[int(obj[\"_id\"])] = obj[\"text\"]\\n            \\n    stemmer = PorterStemmer() \\n    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\\n    \\n    f = open(SAVEFILE_QUERIES_PATH, \"a\")\\n    def tokenizeAndSave(nr, text):\\n        text = text.strip().translate(trans)\\n        tokens = nltk.word_tokenize(text)\\n        stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words(\\'english\\')]\\n        f.write(str(nr) + \",\" + \\' \\'.join(stemmed) + \"\\n\")\\n\\n    for q in queries.keys():\\n        tokenizeAndSave(q, queries[q])\\n    f.close()\\n'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "# --------- PREPROCESSING START ---------\n",
    "\"\"\" Commented as we have preprocessed files as part of the input\n",
    "\n",
    "# TOKENIZE CORPUS TEXTS AND SAVE TO SAVE-FILE\n",
    "if not os.path.exists(SAVEFILE_PATH):\n",
    "    with open(CORPUS_PATH) as f:\n",
    "        raw_corpus = f.readlines()\n",
    "        corpus = [json.loads(q) for q in raw_corpus]\n",
    "        \n",
    "    stemmer = PorterStemmer() \n",
    "    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "\n",
    "    f = open(SAVEFILE_PATH, \"a\")\n",
    "    def tokenizeAndSave(nr, text):\n",
    "        text = text.strip().translate(trans)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words('english')]\n",
    "        f.write(str(nr) + \",\" + ' '.join(stemmed) + \"\\n\")\n",
    "\n",
    "    for c in corpus:\n",
    "        tokenizeAndSave(int(c[\"_id\"]), c[\"text\"])\n",
    "    f.close()\n",
    "\n",
    "# TOKENIZE QUERIES AND SAVE TO SAVE-FILE\n",
    "if not os.path.exists(SAVEFILE_QUERIES_PATH):\n",
    "    queries = dict()\n",
    "    with open(QUERIES_PATH) as f:\n",
    "        raw_queries = f.readlines()\n",
    "        for q in raw_queries:\n",
    "            obj = json.loads(q)\n",
    "            queries[int(obj[\"_id\"])] = obj[\"text\"]\n",
    "            \n",
    "    stemmer = PorterStemmer() \n",
    "    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "    \n",
    "    f = open(SAVEFILE_QUERIES_PATH, \"a\")\n",
    "    def tokenizeAndSave(nr, text):\n",
    "        text = text.strip().translate(trans)\n",
    "        tokens = nltk.word_tokenize(text)\n",
    "        stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words('english')]\n",
    "        f.write(str(nr) + \",\" + ' '.join(stemmed) + \"\\n\")\n",
    "\n",
    "    for q in queries.keys():\n",
    "        tokenizeAndSave(q, queries[q])\n",
    "    f.close()\n",
    "\"\"\"\n",
    "# --------- PREPROCESSING END ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1dbb0497",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:25:32.478625Z",
     "iopub.status.busy": "2023-12-15T16:25:32.477609Z",
     "iopub.status.idle": "2023-12-15T16:27:12.445877Z",
     "shell.execute_reply": "2023-12-15T16:27:12.444173Z"
    },
    "papermill": {
     "duration": 99.98185,
     "end_time": "2023-12-15T16:27:12.453177",
     "exception": false,
     "start_time": "2023-12-15T16:25:32.471327",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 28s, sys: 7.93 s, total: 1min 36s\n",
      "Wall time: 1min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --------- LOADING DATA START ---------\n",
    "# LOAD TEXTS FROM FILES\n",
    "# load documents\n",
    "documents = {}\n",
    "with open(SAVEFILE_PATH) as f:\n",
    "    raw = f.readlines()\n",
    "    for line in raw:\n",
    "        nr, txt = line.split(',')\n",
    "        documents[int(nr)] = txt.split()\n",
    "\n",
    "# load queries\n",
    "queries = {}\n",
    "with open(SAVEFILE_QUERIES_PATH) as f:\n",
    "    raw = f.readlines()\n",
    "    for line in raw:\n",
    "        nr, txt = line.split(',')\n",
    "        queries[int(nr)] = txt.split()\n",
    "\n",
    "# TRAIN- AND TEST-FILES\n",
    "TASK1_TEST = '/kaggle/input/dis-project-1-text-retrieval/task1_test.tsv'\n",
    "TASK1_TRAIN = '/kaggle/input/dis-project-1-text-retrieval/task1_train.tsv'\n",
    "TASK2_TEST = '/kaggle/input/dis-project-1-text-retrieval/task2_test.tsv'\n",
    "TASK2_TRAIN = '/kaggle/input/dis-project-1-text-retrieval/task2_train.tsv'\n",
    "\n",
    "# read in train-data of task1\n",
    "tb = pd.read_table(TASK1_TRAIN)\n",
    "ind_gen = list(tb.iterrows())\n",
    "task1_traindata = {}\n",
    "for _, v in ind_gen:\n",
    "    task1_traindata[int(v['query-id'])] = int(v['corpus-id'])\n",
    "    \n",
    "# read in test-data of task1\n",
    "tb = pd.read_table(TASK1_TEST)\n",
    "ind_gen = list(tb.iterrows())\n",
    "task1_tests = []\n",
    "for _, v in ind_gen:\n",
    "    task1_tests.append((int(v['id']), int(v['query-id'])))\n",
    "\n",
    "# read in train-data of task2\n",
    "tb = pd.read_table(TASK2_TRAIN)\n",
    "ind_gen = list(tb.iterrows())\n",
    "task2_traindata = {}\n",
    "for _, v in ind_gen:\n",
    "    task2_traindata[int(v['query-id'])] = (ast.literal_eval(v['corpus-id']), ast.literal_eval(v['score']))\n",
    "\n",
    "# read in test-data of task2\n",
    "tb = pd.read_table(TASK2_TEST)\n",
    "ind_gen = list(tb.iterrows())\n",
    "task2_tests = []\n",
    "for _, v in ind_gen:\n",
    "    task2_tests.append((int(v['id']), int(v['query-id']), ast.literal_eval(v['corpus-id'])))\n",
    "# --------- LOADING DATA END ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "70328b51",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:27:12.465032Z",
     "iopub.status.busy": "2023-12-15T16:27:12.464281Z",
     "iopub.status.idle": "2023-12-15T16:27:12.472505Z",
     "shell.execute_reply": "2023-12-15T16:27:12.471236Z"
    },
    "papermill": {
     "duration": 0.017186,
     "end_time": "2023-12-15T16:27:12.475075",
     "exception": false,
     "start_time": "2023-12-15T16:27:12.457889",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Open results file\n",
    "f = open(RESULTS_PATH, \"w\")\n",
    "f.write('id,corpus-id,score\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "31e38682",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:27:12.488185Z",
     "iopub.status.busy": "2023-12-15T16:27:12.487736Z",
     "iopub.status.idle": "2023-12-15T16:36:16.804725Z",
     "shell.execute_reply": "2023-12-15T16:36:16.802122Z"
    },
    "papermill": {
     "duration": 544.327539,
     "end_time": "2023-12-15T16:36:16.808017",
     "exception": false,
     "start_time": "2023-12-15T16:27:12.480478",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "500\n",
      "1000\n",
      "1500\n",
      "2000\n",
      "2500\n",
      "3000\n",
      "3500\n",
      "4000\n",
      "4500\n",
      "5000\n",
      "5500\n",
      "6000\n",
      "6500\n",
      "7000\n",
      "CPU times: user 1min 7s, sys: 3.06 s, total: 1min 10s\n",
      "Wall time: 9min 4s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# --------- COMPUTATION TASK 1 START ---------\n",
    "# create the inverted index\n",
    "inv_idx = {}\n",
    "for nr in documents.keys():\n",
    "    for word in set(documents[nr]):\n",
    "        if word in inv_idx:\n",
    "            inv_idx[word].append(nr)\n",
    "        else:\n",
    "            inv_idx[word] = [nr]\n",
    "    \n",
    "# use inverted index to get n \"most important\" documents from corpus\n",
    "def doc_full_ranking(query, n):\n",
    "    indices = []\n",
    "    for word in query:\n",
    "        if word in inv_idx:\n",
    "            indices += inv_idx[word]\n",
    "    return [nr for nr,_ in Counter(indices).most_common(n)]\n",
    "\n",
    "# create a vocabulary from some texts\n",
    "def voc_from_txts(texts):\n",
    "    voc = set()\n",
    "    voc.update(*texts)\n",
    "    voc = list(voc)\n",
    "    return voc\n",
    "\n",
    "# calculate idf-values for all terms in a vocabulary\n",
    "def idf_values(voc, txts):\n",
    "    idf = {}\n",
    "    num_txts = len(txts)\n",
    "    for term in voc:\n",
    "        idf[term] = num_txts/sum(term in txt for txt in txts)\n",
    "    return idf\n",
    "\n",
    "# vectorize documents in \"doc\" list based on TF-IDF metric\n",
    "def vectorize(doc, voc, idf):\n",
    "    counts = Counter(doc)\n",
    "    max_count = counts.most_common(1)[0][1]\n",
    "    \n",
    "    vector = [0]*len(voc)\n",
    "    for i,term in enumerate(voc):\n",
    "        c = counts[term]\n",
    "        if c != 0:\n",
    "            vector[i] = idf[term] * c/max_count\n",
    "    return vector\n",
    "\n",
    "# calculate cosine simliarity between two vectors\n",
    "def cosine_similarity(v1,v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    if sumxy == 0:\n",
    "            result = 0\n",
    "    else:\n",
    "            result = sumxy/math.sqrt(sumxx*sumyy)\n",
    "    return result\n",
    "\n",
    "# classic Vector Retrieval based on TF-IDF metric\n",
    "def vector_retrieval(query, doc_ids, n):\n",
    "    docs = [documents[did] for did in doc_ids]\n",
    "    voc = voc_from_txts(docs)\n",
    "    idfs = idf_values(voc, docs)\n",
    "    \n",
    "    vecs = [vectorize(s, voc, idfs) for s in docs]\n",
    "    query_vec = vectorize(query, voc, idfs)\n",
    "    \n",
    "    sims = [(d, cosine_similarity(query_vec, v)) for d, v in zip(doc_ids, vecs)]\n",
    "    sims = sorted(sims, key=lambda item: -item[1])\n",
    "    return [d for d,_ in sims[:n]]\n",
    "\n",
    "# main retrieval for a single query\n",
    "def retrieval(qid):\n",
    "    n_small = 10\n",
    "    n_big = 70\n",
    "    assert n_small <= n_big\n",
    "    query = queries[qid]\n",
    "    # Step 1: use inverted index\n",
    "    extracted_docs = doc_full_ranking(query, n_big)\n",
    "    # Step 2: use vector retrieval on documents extracted in phase 1\n",
    "    extracted_docs = vector_retrieval(query, extracted_docs, n_small)\n",
    "    return extracted_docs\n",
    "    \n",
    "\"\"\"# Training Data\n",
    "PROCESSES = 4\n",
    "keys = list(task1_traindata.keys())[:100]\n",
    "params = []\n",
    "for k in keys:\n",
    "    params.append((k,))\n",
    "with multiprocessing.Pool(PROCESSES) as pool:\n",
    "    results = [pool.apply_async(retrieval, p) for p in params]\n",
    "\n",
    "    correct = 0\n",
    "    for i, r in enumerate(results):\n",
    "        extracted_docs = r.get()\n",
    "        solution = task1_traindata[keys[i]]\n",
    "        if solution in extracted_docs:\n",
    "            correct += 1\n",
    "        if (i+1) % 10 == 0:\n",
    "            print((i+1), correct, \"->\", (correct / (i + 1)) * 100, \"%\")\n",
    "\"\"\"\n",
    "\n",
    "# Testing Data\n",
    "PROCESSES = 4\n",
    "params = []\n",
    "for i,qid in task1_tests:\n",
    "    params.append((i,(qid,)))\n",
    "with multiprocessing.Pool(PROCESSES) as pool:\n",
    "    results = [(i, pool.apply_async(retrieval, p)) for i,p in params]\n",
    "    for i, r in results:\n",
    "        extracted_docs = r.get()\n",
    "        # write to results file\n",
    "        f.write(f\"{i},\\\"{extracted_docs}\\\",-1\\n\")\n",
    "        if i % 500 == 0:\n",
    "            print(i)\n",
    "# --------- COMPUTATION TASK 1 END ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ff670f6",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:36:16.824749Z",
     "iopub.status.busy": "2023-12-15T16:36:16.824255Z",
     "iopub.status.idle": "2023-12-15T16:36:36.467024Z",
     "shell.execute_reply": "2023-12-15T16:36:36.465246Z"
    },
    "papermill": {
     "duration": 19.655185,
     "end_time": "2023-12-15T16:36:36.470070",
     "exception": false,
     "start_time": "2023-12-15T16:36:16.814885",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# --------- COMPUTATION TASK 2 START ---------\n",
    "# map cosine-similarities to the set {0, 1, 2, 3} \n",
    "def float_to_rank(f):\n",
    "    if f > .1:\n",
    "        return 3\n",
    "    if f > .05:\n",
    "        return 2\n",
    "    if f > .01:\n",
    "        return 1\n",
    "    return 0\n",
    "\n",
    "# re-rank documents based on a query\n",
    "def topk_reranking(qid, corpusids):\n",
    "    reranking_docs = [documents[cid] for cid in corpusids]\n",
    "    reranking_voc = voc_from_txts(reranking_docs)\n",
    "    reranking_idf = idf_values(reranking_voc, reranking_docs)\n",
    "    \n",
    "    reranking_vecs = [vectorize(s, reranking_voc, reranking_idf) for s in reranking_docs]\n",
    "    query_vec = vectorize(queries[qid], reranking_voc, reranking_idf)\n",
    "    \n",
    "    sims = [float_to_rank(cosine_similarity(query_vec, v)) for v in reranking_vecs]\n",
    "    return sims\n",
    "\n",
    "\"\"\"# Training Data\n",
    "avg = 0\n",
    "for qid in task2_traindata.keys():\n",
    "    corpusids, scores = task2_traindata[qid]\n",
    "    res = topk_reranking(qid, corpusids)\n",
    "    # TODO: somehow this gives a completely wrong result :(\n",
    "    how_good = sum(a == b for a,b in zip(scores, res)) / len(scores)\n",
    "    avg += how_good\n",
    "# note: this gets an average of around 42%. if we just always return 0 we get >60% :(\n",
    "print(\"Average: \", (avg / len(task2_traindata.keys())) * 100, \"%\")\"\"\"\n",
    "\n",
    "# Testing Data\n",
    "for i, qid, corpusids in task2_tests:\n",
    "    res = topk_reranking(qid, corpusids)\n",
    "    f.write(f\"{i},-1,\\\"{res}\\\"\\n\")\n",
    "# --------- COMPUTATION TASK 2 END ---------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "da52a075",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-15T16:36:36.486556Z",
     "iopub.status.busy": "2023-12-15T16:36:36.486073Z",
     "iopub.status.idle": "2023-12-15T16:36:36.492698Z",
     "shell.execute_reply": "2023-12-15T16:36:36.491085Z"
    },
    "papermill": {
     "duration": 0.019146,
     "end_time": "2023-12-15T16:36:36.495939",
     "exception": false,
     "start_time": "2023-12-15T16:36:36.476793",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Close results file\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae8180b7",
   "metadata": {
    "papermill": {
     "duration": 0.01314,
     "end_time": "2024-01-16T11:32:17.308564",
     "exception": false,
     "start_time": "2024-01-16T11:32:17.295424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project 2, Recommender System\n",
    "## 1. Preparation\n",
    "#### First we import everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6b5225",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:17.336315Z",
     "iopub.status.busy": "2024-01-16T11:32:17.335869Z",
     "iopub.status.idle": "2024-01-16T11:32:30.958707Z",
     "shell.execute_reply": "2024-01-16T11:32:30.957487Z"
    },
    "papermill": {
     "duration": 13.640073,
     "end_time": "2024-01-16T11:32:30.961678",
     "exception": false,
     "start_time": "2024-01-16T11:32:17.321605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.62 s, sys: 1.6 s, total: 7.22 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# IMPORT STUFF\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483b290",
   "metadata": {
    "papermill": {
     "duration": 0.014373,
     "end_time": "2024-01-16T11:32:30.990022",
     "exception": false,
     "start_time": "2024-01-16T11:32:30.975649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Then we define the paths to the needed input- and output-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0555312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:31.019068Z",
     "iopub.status.busy": "2024-01-16T11:32:31.017954Z",
     "iopub.status.idle": "2024-01-16T11:32:31.026702Z",
     "shell.execute_reply": "2024-01-16T11:32:31.025623Z"
    },
    "papermill": {
     "duration": 0.025994,
     "end_time": "2024-01-16T11:32:31.029514",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.003520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DIRECTORIES\n",
    "MAIN_DIR = '/kaggle'\n",
    "INPUT_DIR = MAIN_DIR + '/input'\n",
    "WORKING_DIR = MAIN_DIR + '/working'\n",
    "DATA_DIR = INPUT_DIR + '/dis-project-2-recommender-systems'\n",
    "\n",
    "# DATA FILES\n",
    "LINKS = DATA_DIR + '/links.csv'\n",
    "MOVIES = DATA_DIR + '/movies.csv'\n",
    "TAGS = DATA_DIR + '/tags.csv'\n",
    "TEST_DATA = DATA_DIR + '/test_set_no_ratings.csv'\n",
    "TRAIN_DATA = DATA_DIR + '/train_ratings.csv'\n",
    "\n",
    "# PREPROCESSED AND SCRAPED FILES\n",
    "PCC_INPUT = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/pcc.csv/pcc.csv'\n",
    "TMDB_DATA = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/scraped.txt/scraped.txt'\n",
    "\n",
    "# SAMPLE SOLUTION\n",
    "SOLUTIONS = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/solutions.xls'\n",
    "\n",
    "# OUTPUT FILES\n",
    "PCC = WORKING_DIR + '/pcc.csv'\n",
    "SUBMISSION = WORKING_DIR + '/submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c693e5",
   "metadata": {
    "papermill": {
     "duration": 0.012672,
     "end_time": "2024-01-16T11:32:31.055722",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.043050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### In this section we load / read all the from the input files into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6974370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:31.086102Z",
     "iopub.status.busy": "2024-01-16T11:32:31.085660Z",
     "iopub.status.idle": "2024-01-16T11:32:32.073068Z",
     "shell.execute_reply": "2024-01-16T11:32:32.071653Z"
    },
    "papermill": {
     "duration": 1.006494,
     "end_time": "2024-01-16T11:32:32.075929",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.069435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 605 ms, sys: 189 ms, total: 795 ms\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# READ DATA FROM INPUT FILES\n",
    "link_data = pd.read_csv(LINKS)\n",
    "movie_raw = pd.read_csv(MOVIES)\n",
    "tag_data = pd.read_csv(TAGS)\n",
    "test_data = pd.read_csv(TEST_DATA)\n",
    "train_raw = pd.read_csv(TRAIN_DATA)\n",
    "pcc_data = pd.read_csv(PCC_INPUT)\n",
    "with open(TMDB_DATA, 'r') as tmdb_file:\n",
    "    tmdb_json = [json.loads(entry) for entry in tmdb_file.read().split('\\n')[:-1]]\n",
    "solution_raw = pd.read_csv(SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34252b87",
   "metadata": {
    "papermill": {
     "duration": 0.013689,
     "end_time": "2024-01-16T11:32:32.104247",
     "exception": false,
     "start_time": "2024-01-16T11:32:32.090558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We then create different lists and dictionaries that will later be used for more efficient data-lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa0c9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:32.133319Z",
     "iopub.status.busy": "2024-01-16T11:32:32.132617Z",
     "iopub.status.idle": "2024-01-16T11:32:45.834786Z",
     "shell.execute_reply": "2024-01-16T11:32:45.833009Z"
    },
    "papermill": {
     "duration": 13.719682,
     "end_time": "2024-01-16T11:32:45.837494",
     "exception": false,
     "start_time": "2024-01-16T11:32:32.117812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 24.6 ms, total: 13.6 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CREATE DIFFERENT WAYS TO LOOK-UP DATA\n",
    "# train-data\n",
    "train_data = []\n",
    "for _, row in train_raw.iterrows():\n",
    "    train_data.append((int(row['userId']), int(row['movieId']), float(row['rating']), int(row['timestamp'])))\n",
    "\n",
    "# solution-data\n",
    "solution_data = []\n",
    "for _, row in solution_raw.iterrows():\n",
    "    solution_data.append((int(row['userId']), int(row['movieId']), float(row['rating']), -1))\n",
    "    \n",
    "# movie-data (title, year and genres) for each movie-id\n",
    "movie_data = dict()\n",
    "for _, movie in movie_raw.iterrows():\n",
    "    mid = int(movie['movieId'])\n",
    "    try:\n",
    "        year = int(movie['title'].split()[-1][1:-1])\n",
    "    except:\n",
    "        year = 1990 # This happens 13 times out of the 9742 movies. For those we just assume 1990\n",
    "    title = ' '.join(movie['title'].split()[:-1])\n",
    "    genres = movie['genres'].split('|')\n",
    "    movie_data[mid] = {'title': title, 'year': year, 'genres': genres}\n",
    "\n",
    "# rating loop-up for a specific movie-id and user-id\n",
    "# TODO: replace with \"user_rating_db\"\n",
    "ratings_per_mid_uid = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if mid not in ratings_per_mid_uid:\n",
    "        ratings_per_mid_uid[mid] = dict()\n",
    "    ratings_per_mid_uid[mid][uid] = rating\n",
    "\n",
    "# ratings-per-movie\n",
    "ratings_per_movie = dict()\n",
    "for _, mid, rating, _ in train_data:\n",
    "    if mid not in ratings_per_movie:\n",
    "        ratings_per_movie[mid] = []\n",
    "    ratings_per_movie[mid].append(rating)\n",
    "\n",
    "# average rating per movie\n",
    "avg_ratings = dict()\n",
    "for mid in ratings_per_movie:\n",
    "    avg_ratings[mid] = sum(ratings_per_movie[mid]) / len(ratings_per_movie[mid])\n",
    "\n",
    "# for each user and each genre a list of ratings he/she has given\n",
    "user_genre_ratings = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if uid not in user_genre_ratings:\n",
    "        user_genre_ratings[uid] = dict()\n",
    "\n",
    "    for genre in movie_data[mid]['genres']:\n",
    "        if genre not in user_genre_ratings[uid]:\n",
    "            user_genre_ratings[uid][genre] = []\n",
    "        user_genre_ratings[uid][genre].append(rating)\n",
    "\n",
    "# for each user the ratings he/she has given\n",
    "rat_per_user = dict()\n",
    "for uid, _, rating, _ in train_data:\n",
    "    if uid not in rat_per_user:\n",
    "        rat_per_user[uid] = []\n",
    "    rat_per_user[uid].append(rating)\n",
    "\n",
    "# for each user the average rating he/she has given\n",
    "avg_rat_per_user = dict()\n",
    "for uid in rat_per_user:\n",
    "    avg_rat_per_user[uid] = sum(rat_per_user[uid]) / len(rat_per_user[uid])\n",
    "\n",
    "# all existing ratings for users and movies\n",
    "user_rating_db = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if uid not in user_rating_db:\n",
    "        user_rating_db[uid] = dict()\n",
    "    user_rating_db[uid][mid] = rating\n",
    "\n",
    "# all users\n",
    "users = set()\n",
    "for _, row in train_raw.iterrows():\n",
    "    users.add(int(row['userId']))\n",
    "users = list(users)\n",
    "\n",
    "# all movies\n",
    "movies = []\n",
    "for mid in movie_data:\n",
    "    movies.append(mid)\n",
    "\n",
    "# tags database\n",
    "tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    uid, mid, tag = int(row['userId']), int(row['movieId']), row['tag']\n",
    "    if uid not in tags:\n",
    "        tags[uid] = dict()\n",
    "    if mid not in tags[uid]:\n",
    "        tags[uid][mid] = \"\"\n",
    "    tags[uid][mid] += \" \" + tag\n",
    "\n",
    "# movie tags\n",
    "movie_tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    mid, tag = int(row['movieId']), row['tag']\n",
    "    if mid not in movie_tags:\n",
    "        movie_tags[mid] = \"\"\n",
    "    movie_tags[mid] += \" \" + tag\n",
    "\n",
    "# user tags\n",
    "user_tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    uid, tag = int(row['userId']), row['tag']\n",
    "    if uid not in user_tags:\n",
    "        user_tags[uid] = \"\"\n",
    "    user_tags[uid] += \" \" + tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaa491",
   "metadata": {
    "papermill": {
     "duration": 0.013697,
     "end_time": "2024-01-16T11:32:45.865178",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.851481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here we define general helper-methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f947575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:45.893627Z",
     "iopub.status.busy": "2024-01-16T11:32:45.893196Z",
     "iopub.status.idle": "2024-01-16T11:32:45.907586Z",
     "shell.execute_reply": "2024-01-16T11:32:45.906289Z"
    },
    "papermill": {
     "duration": 0.031569,
     "end_time": "2024-01-16T11:32:45.910040",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.878471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96 µs, sys: 0 ns, total: 96 µs\n",
      "Wall time: 101 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# round a float to the nearest half-star\n",
    "def half_star(x: float) -> float:\n",
    "    return round(x*2)/2\n",
    "\n",
    "# calculate the RSME between two lists\n",
    "def RSME(calculated: list[float], actual: list[float]):\n",
    "    assert len(calculated) == len(actual)\n",
    "    return math.sqrt(sum((c - a)**2 for c,a in zip(calculated, actual))/len(actual))\n",
    "\n",
    "# test a specific rate-function on some data\n",
    "def test_rate_on_data(rate: Callable[[int, int], float], data: list[int, int, float, int], max_iter: int) -> float:\n",
    "    if max_iter < 0:\n",
    "        max_iter = len(data)\n",
    "    calculated = []\n",
    "    actual = []\n",
    "    for i, (uid, mid, rating, _) in enumerate(data):\n",
    "        calculated.append(half_star(rate(uid, mid)))\n",
    "        actual.append(rating)\n",
    "        if i >= max_iter:\n",
    "            break\n",
    "    rsme = RSME(calculated, actual)\n",
    "    print(f\"RSME: {rsme}\")\n",
    "    return rsme\n",
    "\n",
    "# test a specific rate-function on the training data\n",
    "def test_rate_on_train_data(rate: Callable[[int, int], float], max_iter: int) -> float:\n",
    "    return test_rate_on_data(rate, train_data, max_iter)\n",
    "\n",
    "# test a specific rate-function on the sample solution\n",
    "def test_rate_on_solution(rate: Callable[[int, int], float], max_iter) -> float:\n",
    "    return test_rate_on_data(rate, solution_data, max_iter)\n",
    "\n",
    "# create a submission using a specific rate-function\n",
    "def generate_submission(rate: Callable[[int, int], float]) -> None:\n",
    "    f = open(SUBMISSION, 'w')\n",
    "    f.write(\"Id,rating\\n\")\n",
    "    for i, row in test_data.iterrows():\n",
    "        rating = half_star(rate(int(row['userId']), int(row['movieId'])))\n",
    "        f.write(f\"{row['Id']},{rating}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db383dfc",
   "metadata": {
    "papermill": {
     "duration": 0.01312,
     "end_time": "2024-01-16T11:32:45.936980",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.923860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Preprocessing\n",
    "#### First we compute the cosine-similarities between all user-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a225be23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:45.966928Z",
     "iopub.status.busy": "2024-01-16T11:32:45.966480Z",
     "iopub.status.idle": "2024-01-16T11:32:46.012135Z",
     "shell.execute_reply": "2024-01-16T11:32:46.010722Z"
    },
    "papermill": {
     "duration": 0.063487,
     "end_time": "2024-01-16T11:32:46.014647",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.951160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 ms, sys: 0 ns, total: 26.7 ms\n",
      "Wall time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_user_tag_similarities():\n",
    "    # TF-IDF vectorization and cosine similarity calculation between all user-pairs (given their tags)\n",
    "    uid_list = dict()\n",
    "    documents = []\n",
    "    for i, uid in enumerate(user_tags):\n",
    "        documents.append(user_tags[uid])\n",
    "        uid_list[uid] = i\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english')\n",
    "    features = tf.fit_transform(documents)\n",
    "\n",
    "    cosine_sims = linear_kernel(tf.transform(documents), features)\n",
    "    return uid_list, cosine_sims\n",
    "\n",
    "tag_uid_list, tag_cosine_sims = get_user_tag_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0992a",
   "metadata": {
    "papermill": {
     "duration": 0.013216,
     "end_time": "2024-01-16T11:32:46.041686",
     "exception": false,
     "start_time": "2024-01-16T11:32:46.028470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Then we calculate the Pearson Correlation Coefficient between all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9750d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:46.073398Z",
     "iopub.status.busy": "2024-01-16T11:32:46.072673Z",
     "iopub.status.idle": "2024-01-16T11:33:10.669209Z",
     "shell.execute_reply": "2024-01-16T11:33:10.667596Z"
    },
    "papermill": {
     "duration": 24.616642,
     "end_time": "2024-01-16T11:33:10.672132",
     "exception": false,
     "start_time": "2024-01-16T11:32:46.055490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 43.8 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pearson correlation coefficient between two users\n",
    "def pcc(u1, u2):\n",
    "    nominator = 0\n",
    "    denominator1 = 0\n",
    "    denominator2 = 0\n",
    "    for mid in ratings_per_movie:\n",
    "        if mid not in ratings_per_movie:\n",
    "            print(\"WHAT?\")\n",
    "            return 0\n",
    "        avg_rat1 = 2.5\n",
    "        if u1 in avg_rat_per_user:\n",
    "            avg_rat1 = avg_rat_per_user[u1]\n",
    "        avg_rat2 = 2.5\n",
    "        if u2 in avg_rat_per_user:\n",
    "            avg_rat2 = avg_rat_per_user[u2]\n",
    "\n",
    "        if u1 in ratings_per_movie[mid]:\n",
    "            diff1 = ratings_per_movie[mid][u1] - avg_rat1\n",
    "            denominator1 += diff1**2\n",
    "        if u2 in ratings_per_movie[mid]:\n",
    "            diff2 = ratings_per_movie[mid][u2] - avg_rat2\n",
    "            denominator2 += diff2**2\n",
    "        if u1 in ratings_per_movie[mid] and u2 in ratings_per_movie[mid]:\n",
    "            diff1 = ratings_per_movie[mid][u1] - avg_rat1\n",
    "            diff2 = ratings_per_movie[mid][u2] - avg_rat2\n",
    "            nominator += diff1 * diff2\n",
    "    denominator1 = math.sqrt(denominator1)\n",
    "    denominator2 = math.sqrt(denominator2)\n",
    "    if denominator1 == 0 or denominator2 == 0:\n",
    "        return 0\n",
    "    return nominator / (denominator1 * denominator2)\n",
    "\n",
    "def tagsim(u1, u2):\n",
    "    try:\n",
    "        idx1 = tag_uid_list[u1]\n",
    "        idx2 = tag_uid_list[u2]\n",
    "        return tag_cosine_sims[idx1][idx2]\n",
    "    except:\n",
    "        pass\n",
    "    return -1\n",
    "\n",
    "# calculate pcc for all user-user pairs\n",
    "def all_pccs(users):\n",
    "    pccs = dict()\n",
    "    for u in users:\n",
    "        pccs[u] = dict()\n",
    "    print(len(users))\n",
    "    for i, (u1, u2) in enumerate(itertools.product(users, repeat=2)):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(i)\n",
    "        sim = pcc(u1, u2)\n",
    "        #tsim = tagsim(u1, u2)\n",
    "        #if tsim != -1:\n",
    "        #    sim += tagsim(u1, u2)\n",
    "        #    sim /= 2\n",
    "        pccs[u1][u2] = sim\n",
    "        pccs[u2][u1] = sim\n",
    "    return pccs\n",
    "\n",
    "# load all user ids that appear in the train-data\n",
    "def get_all_users():\n",
    "    users = set()\n",
    "    for uid, _, _, _ in train_data:\n",
    "        users.add(uid)\n",
    "    return users \n",
    "\n",
    "# Calculate Pearson Correlation Coefficients and save them to a file\n",
    "# Note: this takes around 50min\n",
    "def calculate_pccs():\n",
    "    pccs = all_pccs(users)\n",
    "    \n",
    "    f = open(PCC, 'w')\n",
    "    for u1 in pccs:\n",
    "        for u2 in pccs[u1]:\n",
    "            f.write(f\"{u1},{u2},{pccs[u1][u2]}\\n\")\n",
    "    f.close()\n",
    "\n",
    "# Load Pearson Correlation Coefficients from file\n",
    "def load_pccs():\n",
    "    pcc_raw = pd.read_csv(PCC_INPUT)\n",
    "    pcc_data = dict()\n",
    "    for _, pcc in pcc_raw.iterrows():\n",
    "        u1, u2, sim = int(pcc['u1']), int(pcc['u2']), float(pcc['sim'])\n",
    "        if u1 not in pcc_data:\n",
    "            pcc_data[u1] = dict()\n",
    "        if u2 not in pcc_data:\n",
    "            pcc_data[u2] = dict()\n",
    "        pcc_data[u1][u2] = sim\n",
    "        pcc_data[u2][u1] = sim\n",
    "    return pcc_data\n",
    "\n",
    "def get_pccs():\n",
    "    if not os.path.exists(PCC_INPUT):\n",
    "        calculate_pccs()\n",
    "    return load_pccs()\n",
    "\n",
    "pcc_data = get_pccs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8f076",
   "metadata": {
    "papermill": {
     "duration": 0.013619,
     "end_time": "2024-01-16T11:33:10.699884",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.686265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We also tokenize and stemm the data scraped from TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed9ed47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:10.730152Z",
     "iopub.status.busy": "2024-01-16T11:33:10.729699Z",
     "iopub.status.idle": "2024-01-16T11:33:10.738975Z",
     "shell.execute_reply": "2024-01-16T11:33:10.737695Z"
    },
    "papermill": {
     "duration": 0.027614,
     "end_time": "2024-01-16T11:33:10.741616",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.714002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\ndef get_tmdb_data():\\n    stemmer = PorterStemmer() \\n    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\\n\\n    tmdb_data = dict()\\n    for i, jsn in enumerate(tmdb_json):\\n        if jsn != {} and \\'overview\\' in jsn:\\n            text = jsn[\\'overview\\'].strip().translate(trans)\\n            tokens = nltk.word_tokenize(text)\\n            stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words(\\'english\\')]        \\n            tmdb_data[jsn[\\'id\\']] = stemmed\\n    return tmdb_data\\n\\ntmdb_data = get_tmdb_data()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove this as it is currently not needed\n",
    "\"\"\"%%time\n",
    "def get_tmdb_data():\n",
    "    stemmer = PorterStemmer() \n",
    "    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "\n",
    "    tmdb_data = dict()\n",
    "    for i, jsn in enumerate(tmdb_json):\n",
    "        if jsn != {} and 'overview' in jsn:\n",
    "            text = jsn['overview'].strip().translate(trans)\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words('english')]        \n",
    "            tmdb_data[jsn['id']] = stemmed\n",
    "    return tmdb_data\n",
    "\n",
    "tmdb_data = get_tmdb_data()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c75961",
   "metadata": {
    "papermill": {
     "duration": 0.014045,
     "end_time": "2024-01-16T11:33:10.769976",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.755931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Lastly we compute the cosine-similarities between all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b990ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:10.800879Z",
     "iopub.status.busy": "2024-01-16T11:33:10.800082Z",
     "iopub.status.idle": "2024-01-16T11:33:22.578983Z",
     "shell.execute_reply": "2024-01-16T11:33:22.576641Z"
    },
    "papermill": {
     "duration": 11.797614,
     "end_time": "2024-01-16T11:33:22.581898",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.784284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 1.35 s, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_movie_similarities():\n",
    "    # TF-IDF vectorization and cosine similarity calculation between all document pairs\n",
    "    raw_overviews = dict()\n",
    "    for i, jsn in enumerate(tmdb_json):\n",
    "        if jsn != {} and 'overview' in jsn:      \n",
    "            raw_overviews[jsn['id']] = jsn['overview']        \n",
    "\n",
    "    mid_list = dict()\n",
    "    documents = []\n",
    "    for i, row in link_data.iterrows():\n",
    "        mid = int(row['movieId'])\n",
    "        overview = \"\"\n",
    "        try:\n",
    "            overview = raw_overviews[int(row['tmdbId'])]\n",
    "        except:\n",
    "            pass\n",
    "        # add all tags associated to this movie\n",
    "        if mid in movie_tags:\n",
    "            overview += \" \" + movie_tags[mid]\n",
    "        documents.append(overview)\n",
    "        mid_list[mid] = i\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,5), min_df = 1, stop_words = 'english')\n",
    "    features = tf.fit_transform(documents)\n",
    "\n",
    "    cosine_sims = linear_kernel(tf.transform(documents), features)\n",
    "    return mid_list, cosine_sims\n",
    "\n",
    "mid_list, cosine_sims = get_movie_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d836b7",
   "metadata": {
    "papermill": {
     "duration": 0.014132,
     "end_time": "2024-01-16T11:33:22.610753",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.596621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Define Different Rating Methods\n",
    "### 3.1 Rate everything 3.5 Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7120782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.712010Z",
     "iopub.status.busy": "2024-01-16T11:33:22.711365Z",
     "iopub.status.idle": "2024-01-16T11:33:22.716886Z",
     "shell.execute_reply": "2024-01-16T11:33:22.716091Z"
    },
    "papermill": {
     "duration": 0.025032,
     "end_time": "2024-01-16T11:33:22.719144",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.694112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return 3.5 stars, no matter what\n",
    "def rate_35(uid, mid):\n",
    "    return 3.5\n",
    "\n",
    "# test_rate_on_train_data(rate_35, 1000)\n",
    "# test_rate_on_solution(rate_35, -1)\n",
    "#generate_submission(rate_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a4ba9",
   "metadata": {
    "papermill": {
     "duration": 0.014228,
     "end_time": "2024-01-16T11:33:22.748371",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.734143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.2 Movie average-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c522321a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.779472Z",
     "iopub.status.busy": "2024-01-16T11:33:22.778695Z",
     "iopub.status.idle": "2024-01-16T11:33:22.784980Z",
     "shell.execute_reply": "2024-01-16T11:33:22.784122Z"
    },
    "papermill": {
     "duration": 0.024714,
     "end_time": "2024-01-16T11:33:22.787374",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.762660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return the average rating given to a specific movie\n",
    "def rate_movie_average(uid, mid):\n",
    "    if mid not in avg_ratings:\n",
    "        return 3.5\n",
    "    return avg_ratings[mid]\n",
    "\n",
    "# test_rate_on_train_data(rate_movie_average, 1000)\n",
    "# test_rate_on_solution(rate_movie_average, -1)\n",
    "#generate_submission(rate_movie_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537ca24",
   "metadata": {
    "papermill": {
     "duration": 0.01368,
     "end_time": "2024-01-16T11:33:22.815114",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.801434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3 User average-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ef0711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.845525Z",
     "iopub.status.busy": "2024-01-16T11:33:22.844446Z",
     "iopub.status.idle": "2024-01-16T11:33:22.851339Z",
     "shell.execute_reply": "2024-01-16T11:33:22.850152Z"
    },
    "papermill": {
     "duration": 0.024811,
     "end_time": "2024-01-16T11:33:22.853938",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.829127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return the average rating a user has given in the past\n",
    "def rate_user_average(uid, mid):\n",
    "    return avg_rat_per_user[uid]\n",
    "\n",
    "# test_rate_on_train_data(rate_user_average, 1000)\n",
    "# test_rate_on_solution(rate_user_average, -1)\n",
    "# generate_submission(rate_user_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4195b1",
   "metadata": {
    "papermill": {
     "duration": 0.013943,
     "end_time": "2024-01-16T11:33:22.883108",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.869165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.4 Average between 3.2 and 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2fd74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.914540Z",
     "iopub.status.busy": "2024-01-16T11:33:22.913675Z",
     "iopub.status.idle": "2024-01-16T11:33:22.921597Z",
     "shell.execute_reply": "2024-01-16T11:33:22.920021Z"
    },
    "papermill": {
     "duration": 0.026395,
     "end_time": "2024-01-16T11:33:22.924032",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.897637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 34.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we return the average between the average rating for the movie and the average rating given by the user\n",
    "def rate_average_movie_and_user(uid, mid):\n",
    "    return (rate_movie_average(uid, mid) + rate_user_average(uid, mid)) / 2\n",
    "\n",
    "#test_rate_on_train_data(rate_average_movie_and_user, 1000)\n",
    "# test_rate_on_solution(rate_average_movie_and_user, -1)\n",
    "# generate_submission(rate_average_movie_and_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc733c37",
   "metadata": {
    "papermill": {
     "duration": 0.014547,
     "end_time": "2024-01-16T11:33:22.952751",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.938204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.5 User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036d1087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.985723Z",
     "iopub.status.busy": "2024-01-16T11:33:22.985285Z",
     "iopub.status.idle": "2024-01-16T11:33:22.994033Z",
     "shell.execute_reply": "2024-01-16T11:33:22.992737Z"
    },
    "papermill": {
     "duration": 0.028385,
     "end_time": "2024-01-16T11:33:22.996916",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.968531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_user_based(uid, mid):\n",
    "    nom, denom = 0, 0\n",
    "    if mid in ratings_per_mid_uid:\n",
    "        for u2 in ratings_per_mid_uid[mid]:\n",
    "            sim = pcc_data[uid][u2]\n",
    "            nom += sim * (ratings_per_mid_uid[mid][u2] - avg_rat_per_user[u2])\n",
    "            denom += abs(sim)\n",
    "    \n",
    "    avg = avg_rat_per_user[uid]\n",
    "    frac = 0\n",
    "    if denom != 0:\n",
    "        frac = nom / denom # TODO: why is denom sometimes 0?\n",
    "    return avg + frac\n",
    "\n",
    "# test_rate_on_train_data(rate_user_based, 1000)\n",
    "# test_rate_on_solution(rate_user_based, -1)\n",
    "# generate_submission(rate_user_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f2e8a",
   "metadata": {
    "papermill": {
     "duration": 0.014166,
     "end_time": "2024-01-16T11:33:23.025432",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.011266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.6 Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9bbfdac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:23.055935Z",
     "iopub.status.busy": "2024-01-16T11:33:23.055471Z",
     "iopub.status.idle": "2024-01-16T11:33:23.064240Z",
     "shell.execute_reply": "2024-01-16T11:33:23.063007Z"
    },
    "papermill": {
     "duration": 0.02727,
     "end_time": "2024-01-16T11:33:23.066960",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.039690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_item_based(uid, mid):\n",
    "    nom = 0\n",
    "    denom = 0\n",
    "    for mid2 in user_rating_db[uid]:\n",
    "        idx1 = mid_list[mid]\n",
    "        idx2 = mid_list[mid2]\n",
    "        \n",
    "        sim = cosine_sims[idx1][idx2]\n",
    "        nom += sim * user_rating_db[uid][mid2]\n",
    "        denom += abs(sim)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 3.5 # this happens if the scraped data didn't contain an overview for the filem with id \"mid\"\n",
    "    rating = nom / denom\n",
    "    return rating\n",
    "\n",
    "# test_rate_on_train_data(rate_item_based, 1000)\n",
    "# test_rate_on_solution(rate_item_based, -1)\n",
    "# generate_submission(rate_item_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd776f5",
   "metadata": {
    "papermill": {
     "duration": 0.014147,
     "end_time": "2024-01-16T11:33:23.096255",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.082108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.7 Average Item-based User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8372aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:23.128526Z",
     "iopub.status.busy": "2024-01-16T11:33:23.128132Z",
     "iopub.status.idle": "2024-01-16T11:33:42.769958Z",
     "shell.execute_reply": "2024-01-16T11:33:42.768451Z"
    },
    "papermill": {
     "duration": 19.661151,
     "end_time": "2024-01-16T11:33:42.772747",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.111596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 4.21 ms, total: 19.6 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_item_user_based(uid, mid):\n",
    "    return (rate_user_based(uid, mid) + rate_item_based(uid, mid)) / 2\n",
    "\n",
    "# test_rate_on_train_data(rate_item_user_based, 1000)\n",
    "# test_rate_on_solution(rate_item_user_based, -1)\n",
    "generate_submission(rate_item_user_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daacec7",
   "metadata": {
    "papermill": {
     "duration": 0.014022,
     "end_time": "2024-01-16T11:33:42.801481",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.787459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.8 Average over all previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ba8b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.833763Z",
     "iopub.status.busy": "2024-01-16T11:33:42.833351Z",
     "iopub.status.idle": "2024-01-16T11:33:42.841169Z",
     "shell.execute_reply": "2024-01-16T11:33:42.839873Z"
    },
    "papermill": {
     "duration": 0.027321,
     "end_time": "2024-01-16T11:33:42.843539",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.816218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_all_average(uid, mid):\n",
    "    rat = (rate_movie_average(uid, mid) + rate_user_average(uid, mid)\n",
    "            + rate_user_based(uid, mid) + rate_item_based(uid, mid)) / 4.\n",
    "    return rat\n",
    "\n",
    "# test_rate_on_train_data(rate_all_average, 1000)\n",
    "# test_rate_on_solution(rate_all_average, -1)\n",
    "# generate_submission(rate_all_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622221a",
   "metadata": {
    "papermill": {
     "duration": 0.01412,
     "end_time": "2024-01-16T11:33:42.872584",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.858464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.9 Neural Network using Tensorflow\n",
    "#### 3.9.1 Generating Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4ed5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.904269Z",
     "iopub.status.busy": "2024-01-16T11:33:42.903828Z",
     "iopub.status.idle": "2024-01-16T11:33:42.911967Z",
     "shell.execute_reply": "2024-01-16T11:33:42.910994Z"
    },
    "papermill": {
     "duration": 0.027059,
     "end_time": "2024-01-16T11:33:42.914696",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.887637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\n# Neural Net Inputs and Outputs\\ndef getGenreBitmap(mid):\\n    bitmap = []\\n    genres = [\\'Action\\', \\'Adventure\\', \\'Animation\\', \"Children\\'s Comedy\", \\'Crime\\', \\'Documentary\\', \\'Drama\\', \\'Fantasy\\', \\'Film-Noir\\', \\'Horror\\', \\'Musical\\', \\'Mystery\\', \\'Romance\\', \\'Sci-Fi\\', \\'Thriller\\', \\'War\\', \\'Western\\', \\'(no genres listed)\\']\\n    for genre in genres:\\n        bitmap.append((0,1)[genre in movie_data[mid][\\'genres\\']])\\n    return bitmap\\n\\ndef getUserBitmap(uid):\\n    bitmap = len(users) * [0]\\n    bitmap[users.index(uid)] = 1\\n    return bitmap\\n\\ndef getMovieBitmap(mid):\\n    bitmap = len(movies) * [0]\\n    bitmap[movies.index(mid)] = 1\\n    return bitmap\\n\\ndef getData(uid, mid):\\n    mBitmap = getGenreBitmap(mid)\\n    uBitmap = getUserBitmap(uid)\\n    return mBitmap + uBitmap\\n\\nnn_training = {\\'in\\': [], \\'out\\': []}\\nfor uid, mid, rating, _ in train_data:\\n    nn_training[\\'in\\'].append(getData(uid, mid))\\n    nn_training[\\'out\\'].append(rating)\\n\\nnn_testing = {\\'in\\': [], \\'out\\': []}\\nfor uid, mid, rating, _ in solution_data:\\n    nn_testing[\\'in\\'].append(getData(uid, mid))\\n    nn_testing[\\'out\\'].append(rating)\\n\\nX_train, X_test, y_train, y_test = train_test_split(np.array(nn_training[\\'in\\']), np.array(nn_training[\\'out\\']))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# Neural Net Inputs and Outputs\n",
    "def getGenreBitmap(mid):\n",
    "    bitmap = []\n",
    "    genres = ['Action', 'Adventure', 'Animation', \"Children's Comedy\", 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', '(no genres listed)']\n",
    "    for genre in genres:\n",
    "        bitmap.append((0,1)[genre in movie_data[mid]['genres']])\n",
    "    return bitmap\n",
    "\n",
    "def getUserBitmap(uid):\n",
    "    bitmap = len(users) * [0]\n",
    "    bitmap[users.index(uid)] = 1\n",
    "    return bitmap\n",
    "\n",
    "def getMovieBitmap(mid):\n",
    "    bitmap = len(movies) * [0]\n",
    "    bitmap[movies.index(mid)] = 1\n",
    "    return bitmap\n",
    "\n",
    "def getData(uid, mid):\n",
    "    mBitmap = getGenreBitmap(mid)\n",
    "    uBitmap = getUserBitmap(uid)\n",
    "    return mBitmap + uBitmap\n",
    "\n",
    "nn_training = {'in': [], 'out': []}\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    nn_training['in'].append(getData(uid, mid))\n",
    "    nn_training['out'].append(rating)\n",
    "\n",
    "nn_testing = {'in': [], 'out': []}\n",
    "for uid, mid, rating, _ in solution_data:\n",
    "    nn_testing['in'].append(getData(uid, mid))\n",
    "    nn_testing['out'].append(rating)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(nn_training['in']), np.array(nn_training['out']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb01d5b",
   "metadata": {
    "papermill": {
     "duration": 0.01509,
     "end_time": "2024-01-16T11:33:42.945995",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.930905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.2 Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974b46f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.978508Z",
     "iopub.status.busy": "2024-01-16T11:33:42.978082Z",
     "iopub.status.idle": "2024-01-16T11:33:42.985717Z",
     "shell.execute_reply": "2024-01-16T11:33:42.984561Z"
    },
    "papermill": {
     "duration": 0.026385,
     "end_time": "2024-01-16T11:33:42.988083",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.961698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\nmodel = tf.keras.Sequential([\\n    tf.keras.layers.Dense(300, activation='relu', input_shape=(len(nn_training['in'][0]),)),\\n    tf.keras.layers.Dense(200, activation='relu'),\\n    tf.keras.layers.Dense(50, activation='relu'),\\n    tf.keras.layers.Dense(1, activation='linear')\\n])\\n\\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\\n\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, activation='relu', input_shape=(len(nn_training['in'][0]),)),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72180d0",
   "metadata": {
    "papermill": {
     "duration": 0.014822,
     "end_time": "2024-01-16T11:33:43.019190",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.004368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.3 Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f0d9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.050653Z",
     "iopub.status.busy": "2024-01-16T11:33:43.050231Z",
     "iopub.status.idle": "2024-01-16T11:33:43.057732Z",
     "shell.execute_reply": "2024-01-16T11:33:43.056521Z"
    },
    "papermill": {
     "duration": 0.026193,
     "end_time": "2024-01-16T11:33:43.060261",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.034068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n# Neural Net Training\\n# TODO: do this in preprocessing and save the resulting network in a file\\nnum_epochs = 5\\nmodel.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\\nloss, mae = model.evaluate(X_test, y_test)\\nprint(f'Mean Absolute Error: {mae}')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# Neural Net Training\n",
    "# TODO: do this in preprocessing and save the resulting network in a file\n",
    "num_epochs = 5\n",
    "model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf57475",
   "metadata": {
    "papermill": {
     "duration": 0.015361,
     "end_time": "2024-01-16T11:33:43.091018",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.075657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.4 Use the Neural Network for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43910774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.123527Z",
     "iopub.status.busy": "2024-01-16T11:33:43.123104Z",
     "iopub.status.idle": "2024-01-16T11:33:43.130540Z",
     "shell.execute_reply": "2024-01-16T11:33:43.129356Z"
    },
    "papermill": {
     "duration": 0.026938,
     "end_time": "2024-01-16T11:33:43.133182",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.106244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\n# Test using sample solution\\ndef nn_predict(data):\\n    predictions_raw = model.predict(np.array(data))\\n    calculated = []\\n    for pred in predictions_raw:\\n        calculated.append(half_star(pred[0]))\\n    return calculated\\n\\ncalculated = nn_predict(nn_testing[\\'in\\'])\\nactual = nn_testing[\\'out\\']\\nrsme = RSME(calculated, actual)\\nprint(f\"RSME: {rsme}\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "# Test using sample solution\n",
    "def nn_predict(data):\n",
    "    predictions_raw = model.predict(np.array(data))\n",
    "    calculated = []\n",
    "    for pred in predictions_raw:\n",
    "        calculated.append(half_star(pred[0]))\n",
    "    return calculated\n",
    "\n",
    "calculated = nn_predict(nn_testing['in'])\n",
    "actual = nn_testing['out']\n",
    "rsme = RSME(calculated, actual)\n",
    "print(f\"RSME: {rsme}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898503d",
   "metadata": {
    "papermill": {
     "duration": 0.014836,
     "end_time": "2024-01-16T11:33:43.163280",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.148444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.5 Generate submission based on Neural Net predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6edc08f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.196698Z",
     "iopub.status.busy": "2024-01-16T11:33:43.196289Z",
     "iopub.status.idle": "2024-01-16T11:33:43.202192Z",
     "shell.execute_reply": "2024-01-16T11:33:43.201202Z"
    },
    "papermill": {
     "duration": 0.025543,
     "end_time": "2024-01-16T11:33:43.204459",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.178916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the submission\n",
    "def generate_nn_submission():\n",
    "    f = open(SUBMISSION, 'w')\n",
    "    f.write(\"Id,rating\\n\")\n",
    "    for i, rating in enumerate(calculated):\n",
    "        f.write(f\"{i},{rating}\\n\")\n",
    "    f.close()\n",
    "\n",
    "# generate_nn_submission()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e27251",
   "metadata": {
    "papermill": {
     "duration": 0.003997,
     "end_time": "2023-12-23T16:10:31.323297",
     "exception": false,
     "start_time": "2023-12-23T16:10:31.319300",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Named Entity Disambiguation\n",
    "## 1. Preparation\n",
    "First we import everything that we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "771a1f56",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2023-12-23T16:10:31.331626Z",
     "iopub.status.busy": "2023-12-23T16:10:31.331355Z",
     "iopub.status.idle": "2023-12-23T16:10:44.061857Z",
     "shell.execute_reply": "2023-12-23T16:10:44.061055Z"
    },
    "papermill": {
     "duration": 12.737109,
     "end_time": "2023-12-23T16:10:44.064178",
     "exception": false,
     "start_time": "2023-12-23T16:10:31.327069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/scipy/__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.3\n",
      "  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"
     ]
    }
   ],
   "source": [
    "# !pip install -U numpy\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import os\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a306d97",
   "metadata": {
    "papermill": {
     "duration": 0.003514,
     "end_time": "2023-12-23T16:10:44.071698",
     "exception": false,
     "start_time": "2023-12-23T16:10:44.068184",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "We then also define all file-names for input and output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89c2227c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:10:44.080770Z",
     "iopub.status.busy": "2023-12-23T16:10:44.080214Z",
     "iopub.status.idle": "2023-12-23T16:10:44.086942Z",
     "shell.execute_reply": "2023-12-23T16:10:44.086098Z"
    },
    "papermill": {
     "duration": 0.013585,
     "end_time": "2023-12-23T16:10:44.089014",
     "exception": false,
     "start_time": "2023-12-23T16:10:44.075429",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# directories\n",
    "MAIN_DIR = '/kaggle'\n",
    "INPUT_DIR = MAIN_DIR + '/input'\n",
    "WORKING_DIR = MAIN_DIR + '/working'\n",
    "DATA_DIR = INPUT_DIR + '/dis-project-3-named-entity-disambiguation'\n",
    "WIKI_LITE = DATA_DIR + '/wiki_lite'\n",
    "\n",
    "# general input files\n",
    "TEST_DATA = DATA_DIR + '/test.csv'\n",
    "TRAIN_DATA = DATA_DIR + '/train.csv'\n",
    "SAMPLE_SUBMISSION = DATA_DIR + '/sample_submission.csv'\n",
    "\n",
    "PREPROCESSED_LABELS = WORKING_DIR + '/preprocessed_labels.txt'\n",
    "\n",
    "# wiki-lite input files\n",
    "REDIRECTS = WIKI_LITE + '/enwiki_redirects.tsv'\n",
    "ALIASES = WIKI_LITE + '/item_aliases.csv'\n",
    "PROPERTIES = WIKI_LITE + '/property.csv'\n",
    "STATEMENTS = WIKI_LITE + '/statements.csv'\n",
    "ITEMS = WIKI_LITE + '/wiki_items.csv'\n",
    "\n",
    "# OUTPUT FILES\n",
    "EMBEDDINGS = WORKING_DIR + '/embeddings.csv'\n",
    "SUBMISSION = WORKING_DIR + '/submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "903b4052",
   "metadata": {
    "papermill": {
     "duration": 0.003452,
     "end_time": "2023-12-23T16:10:44.096316",
     "exception": false,
     "start_time": "2023-12-23T16:10:44.092864",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "Next, we read all data from the input files and parse it into a usable format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e383368",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:10:44.104743Z",
     "iopub.status.busy": "2023-12-23T16:10:44.104464Z",
     "iopub.status.idle": "2023-12-23T16:11:29.755774Z",
     "shell.execute_reply": "2023-12-23T16:11:29.754868Z"
    },
    "papermill": {
     "duration": 45.663017,
     "end_time": "2023-12-23T16:11:29.762960",
     "exception": false,
     "start_time": "2023-12-23T16:10:44.099943",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 28.8 s, sys: 2.73 s, total: 31.5 s\n",
      "Wall time: 45.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# read raw inputs\n",
    "testdata_raw = pd.read_csv(TEST_DATA)\n",
    "traindata_raw = pd.read_csv(TRAIN_DATA)\n",
    "samplesubmission_raw = pd.read_csv(SAMPLE_SUBMISSION)\n",
    "redirect_raw = pd.read_csv(REDIRECTS, sep='\\t')\n",
    "alias_raw = pd.read_csv(ALIASES)\n",
    "properties_raw = pd.read_csv(PROPERTIES)\n",
    "statements_raw = pd.read_csv(STATEMENTS)\n",
    "items_raw = pd.read_csv(ITEMS)\n",
    "\n",
    "# Note: takes around 55s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c7b7c14",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:11:29.774766Z",
     "iopub.status.busy": "2023-12-23T16:11:29.774460Z",
     "iopub.status.idle": "2023-12-23T16:12:15.065343Z",
     "shell.execute_reply": "2023-12-23T16:12:15.064411Z"
    },
    "papermill": {
     "duration": 45.303009,
     "end_time": "2023-12-23T16:12:15.071259",
     "exception": false,
     "start_time": "2023-12-23T16:11:29.768250",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.4 s, sys: 3 s, total: 45.4 s\n",
      "Wall time: 45.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# parse inputs into better formats\n",
    "redirect_data = dict()\n",
    "for k, v in redirect_raw.values.tolist():\n",
    "    redirect_data[k] = v\n",
    "\n",
    "alias_data = dict()\n",
    "for idx, name in alias_raw.values.tolist():\n",
    "    name = str(name).lower()\n",
    "    if name not in alias_data:\n",
    "        alias_data[name] = []\n",
    "    alias_data[name].append(idx)\n",
    "\n",
    "item_data = dict()\n",
    "for idx, label, desc, title in items_raw.values.tolist():\n",
    "    # add to item data\n",
    "    item_data[idx] = {'label': str(label), 'title': str(title), 'description': str(desc)}\n",
    "    \n",
    "    # add label alias\n",
    "    name = str(label).lower()\n",
    "    if name not in alias_data:\n",
    "        alias_data[name] = []\n",
    "    alias_data[name].append(idx)\n",
    "    \n",
    "    # add title alias\n",
    "    name = str(title).lower()\n",
    "    if name not in alias_data:\n",
    "        alias_data[name] = []\n",
    "    alias_data[name] = [idx] + alias_data[name]\n",
    "\n",
    "# Note: takes around 54s"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f48c983",
   "metadata": {
    "papermill": {
     "duration": 0.003631,
     "end_time": "2023-12-23T16:12:15.078754",
     "exception": false,
     "start_time": "2023-12-23T16:12:15.075123",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Testing & Creating Submission File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9c45ef9",
   "metadata": {
    "papermill": {
     "duration": 0.004171,
     "end_time": "2023-12-23T16:12:15.086905",
     "exception": false,
     "start_time": "2023-12-23T16:12:15.082734",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "---\n",
    "\n",
    "### Idea 2 - with Train Data as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d666b6ae",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:12:15.096577Z",
     "iopub.status.busy": "2023-12-23T16:12:15.096232Z",
     "iopub.status.idle": "2023-12-23T16:12:15.417712Z",
     "shell.execute_reply": "2023-12-23T16:12:15.416699Z"
    },
    "papermill": {
     "duration": 0.331152,
     "end_time": "2023-12-23T16:12:15.422179",
     "exception": false,
     "start_time": "2023-12-23T16:12:15.091027",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd4d644eeaf6433086c4732117dce3ec",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/218505 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7550\n",
      "CPU times: user 296 ms, sys: 21.1 ms, total: 317 ms\n",
      "Wall time: 314 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Aditionally reads and processes the train data\n",
    "# It is then used with a higher priority (ie. if a mention is in the train data, \n",
    "#  then choses it over a random Title\n",
    "\n",
    "from tqdm import tqdm\n",
    "from tqdm.auto import tqdm # For the progress bar\n",
    "\n",
    "mention_to_url = {}\n",
    "for _, __, ___, full_mention, wiki_url in tqdm(traindata_raw.values.tolist()):\n",
    "    if isinstance(full_mention, float) or isinstance(wiki_url, float):\n",
    "        continue\n",
    "    mention_to_url[full_mention.lower()] = wiki_url\n",
    "\n",
    "print(len(mention_to_url))\n",
    "# _ = [print(key, ':', value) for idx, (key, value) in enumerate(mention_to_url.items()) if idx < 100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b220c32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:12:15.432228Z",
     "iopub.status.busy": "2023-12-23T16:12:15.431932Z",
     "iopub.status.idle": "2023-12-23T16:12:15.576180Z",
     "shell.execute_reply": "2023-12-23T16:12:15.575084Z"
    },
    "papermill": {
     "duration": 0.151623,
     "end_time": "2023-12-23T16:12:15.578450",
     "exception": false,
     "start_time": "2023-12-23T16:12:15.426827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len(testdata_raw.values) = 104890\n",
      "CPU times: user 124 ms, sys: 11.9 ms, total: 136 ms\n",
      "Wall time: 135 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def redirect(s):\n",
    "    if s in redirect_data:\n",
    "        return redirect_data[s]\n",
    "    return s\n",
    "\n",
    "def wiki_url_from_title(s):\n",
    "    return 'http://en.wikipedia.org/wiki/' + s.replace(' ', '_')\n",
    "\n",
    "\n",
    "def getUrl(token, mention):\n",
    "\n",
    "    # Checks the train data\n",
    "    if mention.lower() in mention_to_url:\n",
    "        return mention_to_url[mention.lower()]\n",
    "    \n",
    "    possible_indices = []\n",
    "    if mention.lower() in alias_data:\n",
    "        possible_indices = alias_data[mention.lower()]\n",
    "\n",
    "    if len(possible_indices) == 0:\n",
    "        return \"NOT_FOUND\"\n",
    "\n",
    "    titles = sorted([item_data[idx]['title'] for idx in possible_indices], key=len)\n",
    "    \n",
    "    # TODO: which index is \"the best\"?\n",
    "    title = titles[0]\n",
    "    \n",
    "    title = redirect(title)\n",
    "    return wiki_url_from_title(title)\n",
    "\n",
    "submission = []\n",
    "for idx, token, tag, mention, url in testdata_raw.values.tolist():\n",
    "    if url == '?':\n",
    "        submission.append((idx, getUrl(token, mention)))\n",
    "    else:\n",
    "        submission.append((idx, \"NOT_FOUND\"))\n",
    "        \n",
    "print(f\"{len(testdata_raw.values) = }\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "17f31747",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-12-23T16:12:15.588605Z",
     "iopub.status.busy": "2023-12-23T16:12:15.588331Z",
     "iopub.status.idle": "2023-12-23T16:12:15.641443Z",
     "shell.execute_reply": "2023-12-23T16:12:15.640727Z"
    },
    "papermill": {
     "duration": 0.060552,
     "end_time": "2023-12-23T16:12:15.643410",
     "exception": false,
     "start_time": "2023-12-23T16:12:15.582858",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# create submission\n",
    "def generate_submission(submission_data) -> None:\n",
    "    f = open(SUBMISSION, 'w')\n",
    "    f.write(\"id,wiki_url\\n\")\n",
    "    for idx, url in submission_data:\n",
    "        f.write(f\"{idx},\\\"{url}\\\"\\n\")\n",
    "    f.close()\n",
    "generate_submission(submission)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6624299,
     "sourceId": 60797,
     "sourceType": "competition"
    },
    {
     "datasetId": 3780771,
     "sourceId": 6544699,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3859468,
     "sourceId": 6694027,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3887449,
     "sourceId": 6752857,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3887450,
     "sourceId": 6752863,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 674.884657,
   "end_time": "2023-12-15T16:36:39.429950",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-12-15T16:25:24.545293",
   "version": "2.4.0"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "028f1ead6f7a46ed9eec049ad81a92ac": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "05e88532fbf74626a0b5206b75e523b7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     },
     "180518e714af4ad6a25702bbb30e948a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "DescriptionStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "description_width": ""
      }
     },
     "19e6340acfa44a9188309d886611bc98": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "226ade2d9c9f4e1b80afba644fed3035": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3815d3902e864c179203a45e95f75230": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76cc2a90105048058b067e6164ff6f21": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_81f40096bc294a73bc15ad6c1ae55850",
       "max": 218505.0,
       "min": 0.0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_05e88532fbf74626a0b5206b75e523b7",
       "value": 218505.0
      }
     },
     "81f40096bc294a73bc15ad6c1ae55850": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "1.2.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "overflow_x": null,
       "overflow_y": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "bd4d644eeaf6433086c4732117dce3ec": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_d93c426a51494ff4aa69c9f92f86c220",
        "IPY_MODEL_76cc2a90105048058b067e6164ff6f21",
        "IPY_MODEL_e37f5778dfbc4c67995b25b79f9180a2"
       ],
       "layout": "IPY_MODEL_19e6340acfa44a9188309d886611bc98"
      }
     },
     "d93c426a51494ff4aa69c9f92f86c220": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_3815d3902e864c179203a45e95f75230",
       "placeholder": "​",
       "style": "IPY_MODEL_180518e714af4ad6a25702bbb30e948a",
       "value": "100%"
      }
     },
     "e37f5778dfbc4c67995b25b79f9180a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "1.5.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "1.5.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_tooltip": null,
       "layout": "IPY_MODEL_226ade2d9c9f4e1b80afba644fed3035",
       "placeholder": "​",
       "style": "IPY_MODEL_028f1ead6f7a46ed9eec049ad81a92ac",
       "value": " 218505/218505 [00:00&lt;00:00, 994644.03it/s]"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
