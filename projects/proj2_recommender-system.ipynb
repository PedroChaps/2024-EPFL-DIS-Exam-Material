{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ae8180b7",
   "metadata": {
    "papermill": {
     "duration": 0.01314,
     "end_time": "2024-01-16T11:32:17.308564",
     "exception": false,
     "start_time": "2024-01-16T11:32:17.295424",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Project 2, Recommender System\n",
    "## 1. Preparation\n",
    "#### First we import everything we need."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7b6b5225",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:17.336315Z",
     "iopub.status.busy": "2024-01-16T11:32:17.335869Z",
     "iopub.status.idle": "2024-01-16T11:32:30.958707Z",
     "shell.execute_reply": "2024-01-16T11:32:30.957487Z"
    },
    "papermill": {
     "duration": 13.640073,
     "end_time": "2024-01-16T11:32:30.961678",
     "exception": false,
     "start_time": "2024-01-16T11:32:17.321605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.62 s, sys: 1.6 s, total: 7.22 s\n",
      "Wall time: 13.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# IMPORT STUFF\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import math\n",
    "import itertools\n",
    "import json\n",
    "import nltk\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from typing import Callable\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3483b290",
   "metadata": {
    "papermill": {
     "duration": 0.014373,
     "end_time": "2024-01-16T11:32:30.990022",
     "exception": false,
     "start_time": "2024-01-16T11:32:30.975649",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Then we define the paths to the needed input- and output-files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c0555312",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:31.019068Z",
     "iopub.status.busy": "2024-01-16T11:32:31.017954Z",
     "iopub.status.idle": "2024-01-16T11:32:31.026702Z",
     "shell.execute_reply": "2024-01-16T11:32:31.025623Z"
    },
    "papermill": {
     "duration": 0.025994,
     "end_time": "2024-01-16T11:32:31.029514",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.003520",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8 µs, sys: 2 µs, total: 10 µs\n",
      "Wall time: 14.1 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# DIRECTORIES\n",
    "MAIN_DIR = '/kaggle'\n",
    "INPUT_DIR = MAIN_DIR + '/input'\n",
    "WORKING_DIR = MAIN_DIR + '/working'\n",
    "DATA_DIR = INPUT_DIR + '/dis-project-2-recommender-systems'\n",
    "\n",
    "# DATA FILES\n",
    "LINKS = DATA_DIR + '/links.csv'\n",
    "MOVIES = DATA_DIR + '/movies.csv'\n",
    "TAGS = DATA_DIR + '/tags.csv'\n",
    "TEST_DATA = DATA_DIR + '/test_set_no_ratings.csv'\n",
    "TRAIN_DATA = DATA_DIR + '/train_ratings.csv'\n",
    "\n",
    "# PREPROCESSED AND SCRAPED FILES\n",
    "PCC_INPUT = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/pcc.csv/pcc.csv'\n",
    "TMDB_DATA = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/scraped.txt/scraped.txt'\n",
    "\n",
    "# SAMPLE SOLUTION\n",
    "SOLUTIONS = INPUT_DIR + '/e7cc12ec0019932c50bc4eab7c9c16463efed46a091e2dacb9/solutions.xls'\n",
    "\n",
    "# OUTPUT FILES\n",
    "PCC = WORKING_DIR + '/pcc.csv'\n",
    "SUBMISSION = WORKING_DIR + '/submission.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c693e5",
   "metadata": {
    "papermill": {
     "duration": 0.012672,
     "end_time": "2024-01-16T11:32:31.055722",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.043050",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### In this section we load / read all the from the input files into variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a6974370",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:31.086102Z",
     "iopub.status.busy": "2024-01-16T11:32:31.085660Z",
     "iopub.status.idle": "2024-01-16T11:32:32.073068Z",
     "shell.execute_reply": "2024-01-16T11:32:32.071653Z"
    },
    "papermill": {
     "duration": 1.006494,
     "end_time": "2024-01-16T11:32:32.075929",
     "exception": false,
     "start_time": "2024-01-16T11:32:31.069435",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 605 ms, sys: 189 ms, total: 795 ms\n",
      "Wall time: 979 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# READ DATA FROM INPUT FILES\n",
    "link_data = pd.read_csv(LINKS)\n",
    "movie_raw = pd.read_csv(MOVIES)\n",
    "tag_data = pd.read_csv(TAGS)\n",
    "test_data = pd.read_csv(TEST_DATA)\n",
    "train_raw = pd.read_csv(TRAIN_DATA)\n",
    "pcc_data = pd.read_csv(PCC_INPUT)\n",
    "with open(TMDB_DATA, 'r') as tmdb_file:\n",
    "    tmdb_json = [json.loads(entry) for entry in tmdb_file.read().split('\\n')[:-1]]\n",
    "solution_raw = pd.read_csv(SOLUTIONS)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34252b87",
   "metadata": {
    "papermill": {
     "duration": 0.013689,
     "end_time": "2024-01-16T11:32:32.104247",
     "exception": false,
     "start_time": "2024-01-16T11:32:32.090558",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We then create different lists and dictionaries that will later be used for more efficient data-lookup."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9fa0c9a9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:32.133319Z",
     "iopub.status.busy": "2024-01-16T11:32:32.132617Z",
     "iopub.status.idle": "2024-01-16T11:32:45.834786Z",
     "shell.execute_reply": "2024-01-16T11:32:45.833009Z"
    },
    "papermill": {
     "duration": 13.719682,
     "end_time": "2024-01-16T11:32:45.837494",
     "exception": false,
     "start_time": "2024-01-16T11:32:32.117812",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.6 s, sys: 24.6 ms, total: 13.6 s\n",
      "Wall time: 13.7 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# CREATE DIFFERENT WAYS TO LOOK-UP DATA\n",
    "# train-data\n",
    "train_data = []\n",
    "for _, row in train_raw.iterrows():\n",
    "    train_data.append((int(row['userId']), int(row['movieId']), float(row['rating']), int(row['timestamp'])))\n",
    "\n",
    "# solution-data\n",
    "solution_data = []\n",
    "for _, row in solution_raw.iterrows():\n",
    "    solution_data.append((int(row['userId']), int(row['movieId']), float(row['rating']), -1))\n",
    "    \n",
    "# movie-data (title, year and genres) for each movie-id\n",
    "movie_data = dict()\n",
    "for _, movie in movie_raw.iterrows():\n",
    "    mid = int(movie['movieId'])\n",
    "    try:\n",
    "        year = int(movie['title'].split()[-1][1:-1])\n",
    "    except:\n",
    "        year = 1990 # This happens 13 times out of the 9742 movies. For those we just assume 1990\n",
    "    title = ' '.join(movie['title'].split()[:-1])\n",
    "    genres = movie['genres'].split('|')\n",
    "    movie_data[mid] = {'title': title, 'year': year, 'genres': genres}\n",
    "\n",
    "# rating loop-up for a specific movie-id and user-id\n",
    "# TODO: replace with \"user_rating_db\"\n",
    "ratings_per_mid_uid = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if mid not in ratings_per_mid_uid:\n",
    "        ratings_per_mid_uid[mid] = dict()\n",
    "    ratings_per_mid_uid[mid][uid] = rating\n",
    "\n",
    "# ratings-per-movie\n",
    "ratings_per_movie = dict()\n",
    "for _, mid, rating, _ in train_data:\n",
    "    if mid not in ratings_per_movie:\n",
    "        ratings_per_movie[mid] = []\n",
    "    ratings_per_movie[mid].append(rating)\n",
    "\n",
    "# average rating per movie\n",
    "avg_ratings = dict()\n",
    "for mid in ratings_per_movie:\n",
    "    avg_ratings[mid] = sum(ratings_per_movie[mid]) / len(ratings_per_movie[mid])\n",
    "\n",
    "# for each user and each genre a list of ratings he/she has given\n",
    "user_genre_ratings = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if uid not in user_genre_ratings:\n",
    "        user_genre_ratings[uid] = dict()\n",
    "\n",
    "    for genre in movie_data[mid]['genres']:\n",
    "        if genre not in user_genre_ratings[uid]:\n",
    "            user_genre_ratings[uid][genre] = []\n",
    "        user_genre_ratings[uid][genre].append(rating)\n",
    "\n",
    "# for each user the ratings he/she has given\n",
    "rat_per_user = dict()\n",
    "for uid, _, rating, _ in train_data:\n",
    "    if uid not in rat_per_user:\n",
    "        rat_per_user[uid] = []\n",
    "    rat_per_user[uid].append(rating)\n",
    "\n",
    "# for each user the average rating he/she has given\n",
    "avg_rat_per_user = dict()\n",
    "for uid in rat_per_user:\n",
    "    avg_rat_per_user[uid] = sum(rat_per_user[uid]) / len(rat_per_user[uid])\n",
    "\n",
    "# all existing ratings for users and movies\n",
    "user_rating_db = dict()\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    if uid not in user_rating_db:\n",
    "        user_rating_db[uid] = dict()\n",
    "    user_rating_db[uid][mid] = rating\n",
    "\n",
    "# all users\n",
    "users = set()\n",
    "for _, row in train_raw.iterrows():\n",
    "    users.add(int(row['userId']))\n",
    "users = list(users)\n",
    "\n",
    "# all movies\n",
    "movies = []\n",
    "for mid in movie_data:\n",
    "    movies.append(mid)\n",
    "\n",
    "# tags database\n",
    "tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    uid, mid, tag = int(row['userId']), int(row['movieId']), row['tag']\n",
    "    if uid not in tags:\n",
    "        tags[uid] = dict()\n",
    "    if mid not in tags[uid]:\n",
    "        tags[uid][mid] = \"\"\n",
    "    tags[uid][mid] += \" \" + tag\n",
    "\n",
    "# movie tags\n",
    "movie_tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    mid, tag = int(row['movieId']), row['tag']\n",
    "    if mid not in movie_tags:\n",
    "        movie_tags[mid] = \"\"\n",
    "    movie_tags[mid] += \" \" + tag\n",
    "\n",
    "# user tags\n",
    "user_tags = dict()\n",
    "for _, row in tag_data.iterrows():\n",
    "    uid, tag = int(row['userId']), row['tag']\n",
    "    if uid not in user_tags:\n",
    "        user_tags[uid] = \"\"\n",
    "    user_tags[uid] += \" \" + tag"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8bdaa491",
   "metadata": {
    "papermill": {
     "duration": 0.013697,
     "end_time": "2024-01-16T11:32:45.865178",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.851481",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Here we define general helper-methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2f947575",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:45.893627Z",
     "iopub.status.busy": "2024-01-16T11:32:45.893196Z",
     "iopub.status.idle": "2024-01-16T11:32:45.907586Z",
     "shell.execute_reply": "2024-01-16T11:32:45.906289Z"
    },
    "papermill": {
     "duration": 0.031569,
     "end_time": "2024-01-16T11:32:45.910040",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.878471",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 96 µs, sys: 0 ns, total: 96 µs\n",
      "Wall time: 101 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# round a float to the nearest half-star\n",
    "def half_star(x: float) -> float:\n",
    "    return round(x*2)/2\n",
    "\n",
    "# calculate the RSME between two lists\n",
    "def RSME(calculated: list[float], actual: list[float]):\n",
    "    assert len(calculated) == len(actual)\n",
    "    return math.sqrt(sum((c - a)**2 for c,a in zip(calculated, actual))/len(actual))\n",
    "\n",
    "# test a specific rate-function on some data\n",
    "def test_rate_on_data(rate: Callable[[int, int], float], data: list[int, int, float, int], max_iter: int) -> float:\n",
    "    if max_iter < 0:\n",
    "        max_iter = len(data)\n",
    "    calculated = []\n",
    "    actual = []\n",
    "    for i, (uid, mid, rating, _) in enumerate(data):\n",
    "        calculated.append(half_star(rate(uid, mid)))\n",
    "        actual.append(rating)\n",
    "        if i >= max_iter:\n",
    "            break\n",
    "    rsme = RSME(calculated, actual)\n",
    "    print(f\"RSME: {rsme}\")\n",
    "    return rsme\n",
    "\n",
    "# test a specific rate-function on the training data\n",
    "def test_rate_on_train_data(rate: Callable[[int, int], float], max_iter: int) -> float:\n",
    "    return test_rate_on_data(rate, train_data, max_iter)\n",
    "\n",
    "# test a specific rate-function on the sample solution\n",
    "def test_rate_on_solution(rate: Callable[[int, int], float], max_iter) -> float:\n",
    "    return test_rate_on_data(rate, solution_data, max_iter)\n",
    "\n",
    "# create a submission using a specific rate-function\n",
    "def generate_submission(rate: Callable[[int, int], float]) -> None:\n",
    "    f = open(SUBMISSION, 'w')\n",
    "    f.write(\"Id,rating\\n\")\n",
    "    for i, row in test_data.iterrows():\n",
    "        rating = half_star(rate(int(row['userId']), int(row['movieId'])))\n",
    "        f.write(f\"{row['Id']},{rating}\\n\")\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db383dfc",
   "metadata": {
    "papermill": {
     "duration": 0.01312,
     "end_time": "2024-01-16T11:32:45.936980",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.923860",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 2. Preprocessing\n",
    "#### First we compute the cosine-similarities between all user-tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a225be23",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:45.966928Z",
     "iopub.status.busy": "2024-01-16T11:32:45.966480Z",
     "iopub.status.idle": "2024-01-16T11:32:46.012135Z",
     "shell.execute_reply": "2024-01-16T11:32:46.010722Z"
    },
    "papermill": {
     "duration": 0.063487,
     "end_time": "2024-01-16T11:32:46.014647",
     "exception": false,
     "start_time": "2024-01-16T11:32:45.951160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.7 ms, sys: 0 ns, total: 26.7 ms\n",
      "Wall time: 36.9 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_user_tag_similarities():\n",
    "    # TF-IDF vectorization and cosine similarity calculation between all user-pairs (given their tags)\n",
    "    uid_list = dict()\n",
    "    documents = []\n",
    "    for i, uid in enumerate(user_tags):\n",
    "        documents.append(user_tags[uid])\n",
    "        uid_list[uid] = i\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), min_df = 1, stop_words = 'english')\n",
    "    features = tf.fit_transform(documents)\n",
    "\n",
    "    cosine_sims = linear_kernel(tf.transform(documents), features)\n",
    "    return uid_list, cosine_sims\n",
    "\n",
    "tag_uid_list, tag_cosine_sims = get_user_tag_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8a0992a",
   "metadata": {
    "papermill": {
     "duration": 0.013216,
     "end_time": "2024-01-16T11:32:46.041686",
     "exception": false,
     "start_time": "2024-01-16T11:32:46.028470",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Then we calculate the Pearson Correlation Coefficient between all users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c9750d4d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:32:46.073398Z",
     "iopub.status.busy": "2024-01-16T11:32:46.072673Z",
     "iopub.status.idle": "2024-01-16T11:33:10.669209Z",
     "shell.execute_reply": "2024-01-16T11:33:10.667596Z"
    },
    "papermill": {
     "duration": 24.616642,
     "end_time": "2024-01-16T11:33:10.672132",
     "exception": false,
     "start_time": "2024-01-16T11:32:46.055490",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 24.5 s, sys: 43.8 ms, total: 24.6 s\n",
      "Wall time: 24.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# pearson correlation coefficient between two users\n",
    "def pcc(u1, u2):\n",
    "    nominator = 0\n",
    "    denominator1 = 0\n",
    "    denominator2 = 0\n",
    "    for mid in ratings_per_movie:\n",
    "        if mid not in ratings_per_movie:\n",
    "            print(\"WHAT?\")\n",
    "            return 0\n",
    "        avg_rat1 = 2.5\n",
    "        if u1 in avg_rat_per_user:\n",
    "            avg_rat1 = avg_rat_per_user[u1]\n",
    "        avg_rat2 = 2.5\n",
    "        if u2 in avg_rat_per_user:\n",
    "            avg_rat2 = avg_rat_per_user[u2]\n",
    "\n",
    "        if u1 in ratings_per_movie[mid]:\n",
    "            diff1 = ratings_per_movie[mid][u1] - avg_rat1\n",
    "            denominator1 += diff1**2\n",
    "        if u2 in ratings_per_movie[mid]:\n",
    "            diff2 = ratings_per_movie[mid][u2] - avg_rat2\n",
    "            denominator2 += diff2**2\n",
    "        if u1 in ratings_per_movie[mid] and u2 in ratings_per_movie[mid]:\n",
    "            diff1 = ratings_per_movie[mid][u1] - avg_rat1\n",
    "            diff2 = ratings_per_movie[mid][u2] - avg_rat2\n",
    "            nominator += diff1 * diff2\n",
    "    denominator1 = math.sqrt(denominator1)\n",
    "    denominator2 = math.sqrt(denominator2)\n",
    "    if denominator1 == 0 or denominator2 == 0:\n",
    "        return 0\n",
    "    return nominator / (denominator1 * denominator2)\n",
    "\n",
    "def tagsim(u1, u2):\n",
    "    try:\n",
    "        idx1 = tag_uid_list[u1]\n",
    "        idx2 = tag_uid_list[u2]\n",
    "        return tag_cosine_sims[idx1][idx2]\n",
    "    except:\n",
    "        pass\n",
    "    return -1\n",
    "\n",
    "# calculate pcc for all user-user pairs\n",
    "def all_pccs(users):\n",
    "    pccs = dict()\n",
    "    for u in users:\n",
    "        pccs[u] = dict()\n",
    "    print(len(users))\n",
    "    for i, (u1, u2) in enumerate(itertools.product(users, repeat=2)):\n",
    "        if (i + 1) % 1000 == 0:\n",
    "            print(i)\n",
    "        sim = pcc(u1, u2)\n",
    "        #tsim = tagsim(u1, u2)\n",
    "        #if tsim != -1:\n",
    "        #    sim += tagsim(u1, u2)\n",
    "        #    sim /= 2\n",
    "        pccs[u1][u2] = sim\n",
    "        pccs[u2][u1] = sim\n",
    "    return pccs\n",
    "\n",
    "# load all user ids that appear in the train-data\n",
    "def get_all_users():\n",
    "    users = set()\n",
    "    for uid, _, _, _ in train_data:\n",
    "        users.add(uid)\n",
    "    return users \n",
    "\n",
    "# Calculate Pearson Correlation Coefficients and save them to a file\n",
    "# Note: this takes around 50min\n",
    "def calculate_pccs():\n",
    "    pccs = all_pccs(users)\n",
    "    \n",
    "    f = open(PCC, 'w')\n",
    "    for u1 in pccs:\n",
    "        for u2 in pccs[u1]:\n",
    "            f.write(f\"{u1},{u2},{pccs[u1][u2]}\\n\")\n",
    "    f.close()\n",
    "\n",
    "# Load Pearson Correlation Coefficients from file\n",
    "def load_pccs():\n",
    "    pcc_raw = pd.read_csv(PCC_INPUT)\n",
    "    pcc_data = dict()\n",
    "    for _, pcc in pcc_raw.iterrows():\n",
    "        u1, u2, sim = int(pcc['u1']), int(pcc['u2']), float(pcc['sim'])\n",
    "        if u1 not in pcc_data:\n",
    "            pcc_data[u1] = dict()\n",
    "        if u2 not in pcc_data:\n",
    "            pcc_data[u2] = dict()\n",
    "        pcc_data[u1][u2] = sim\n",
    "        pcc_data[u2][u1] = sim\n",
    "    return pcc_data\n",
    "\n",
    "def get_pccs():\n",
    "    if not os.path.exists(PCC_INPUT):\n",
    "        calculate_pccs()\n",
    "    return load_pccs()\n",
    "\n",
    "pcc_data = get_pccs()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e8f076",
   "metadata": {
    "papermill": {
     "duration": 0.013619,
     "end_time": "2024-01-16T11:33:10.699884",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.686265",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### We also tokenize and stemm the data scraped from TMDB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7ed9ed47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:10.730152Z",
     "iopub.status.busy": "2024-01-16T11:33:10.729699Z",
     "iopub.status.idle": "2024-01-16T11:33:10.738975Z",
     "shell.execute_reply": "2024-01-16T11:33:10.737695Z"
    },
    "papermill": {
     "duration": 0.027614,
     "end_time": "2024-01-16T11:33:10.741616",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.714002",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\ndef get_tmdb_data():\\n    stemmer = PorterStemmer() \\n    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\\n\\n    tmdb_data = dict()\\n    for i, jsn in enumerate(tmdb_json):\\n        if jsn != {} and \\'overview\\' in jsn:\\n            text = jsn[\\'overview\\'].strip().translate(trans)\\n            tokens = nltk.word_tokenize(text)\\n            stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words(\\'english\\')]        \\n            tmdb_data[jsn[\\'id\\']] = stemmed\\n    return tmdb_data\\n\\ntmdb_data = get_tmdb_data()'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TODO: remove this as it is currently not needed\n",
    "\"\"\"%%time\n",
    "def get_tmdb_data():\n",
    "    stemmer = PorterStemmer() \n",
    "    trans = str.maketrans(string.punctuation, \" \" * len(string.punctuation))\n",
    "\n",
    "    tmdb_data = dict()\n",
    "    for i, jsn in enumerate(tmdb_json):\n",
    "        if jsn != {} and 'overview' in jsn:\n",
    "            text = jsn['overview'].strip().translate(trans)\n",
    "            tokens = nltk.word_tokenize(text)\n",
    "            stemmed = [stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words('english')]        \n",
    "            tmdb_data[jsn['id']] = stemmed\n",
    "    return tmdb_data\n",
    "\n",
    "tmdb_data = get_tmdb_data()\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03c75961",
   "metadata": {
    "papermill": {
     "duration": 0.014045,
     "end_time": "2024-01-16T11:33:10.769976",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.755931",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### Lastly we compute the cosine-similarities between all movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "54b990ff",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:10.800879Z",
     "iopub.status.busy": "2024-01-16T11:33:10.800082Z",
     "iopub.status.idle": "2024-01-16T11:33:22.578983Z",
     "shell.execute_reply": "2024-01-16T11:33:22.576641Z"
    },
    "papermill": {
     "duration": 11.797614,
     "end_time": "2024-01-16T11:33:22.581898",
     "exception": false,
     "start_time": "2024-01-16T11:33:10.784284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 10.4 s, sys: 1.35 s, total: 11.8 s\n",
      "Wall time: 11.8 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def get_movie_similarities():\n",
    "    # TF-IDF vectorization and cosine similarity calculation between all document pairs\n",
    "    raw_overviews = dict()\n",
    "    for i, jsn in enumerate(tmdb_json):\n",
    "        if jsn != {} and 'overview' in jsn:      \n",
    "            raw_overviews[jsn['id']] = jsn['overview']        \n",
    "\n",
    "    mid_list = dict()\n",
    "    documents = []\n",
    "    for i, row in link_data.iterrows():\n",
    "        mid = int(row['movieId'])\n",
    "        overview = \"\"\n",
    "        try:\n",
    "            overview = raw_overviews[int(row['tmdbId'])]\n",
    "        except:\n",
    "            pass\n",
    "        # add all tags associated to this movie\n",
    "        if mid in movie_tags:\n",
    "            overview += \" \" + movie_tags[mid]\n",
    "        documents.append(overview)\n",
    "        mid_list[mid] = i\n",
    "\n",
    "    tf = TfidfVectorizer(analyzer='word', ngram_range=(1,5), min_df = 1, stop_words = 'english')\n",
    "    features = tf.fit_transform(documents)\n",
    "\n",
    "    cosine_sims = linear_kernel(tf.transform(documents), features)\n",
    "    return mid_list, cosine_sims\n",
    "\n",
    "mid_list, cosine_sims = get_movie_similarities()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20d836b7",
   "metadata": {
    "papermill": {
     "duration": 0.014132,
     "end_time": "2024-01-16T11:33:22.610753",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.596621",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## 3. Define Different Rating Methods\n",
    "### 3.1 Rate everything 3.5 Stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e7120782",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.712010Z",
     "iopub.status.busy": "2024-01-16T11:33:22.711365Z",
     "iopub.status.idle": "2024-01-16T11:33:22.716886Z",
     "shell.execute_reply": "2024-01-16T11:33:22.716091Z"
    },
    "papermill": {
     "duration": 0.025032,
     "end_time": "2024-01-16T11:33:22.719144",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.694112",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 1 µs, total: 6 µs\n",
      "Wall time: 9.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return 3.5 stars, no matter what\n",
    "def rate_35(uid, mid):\n",
    "    return 3.5\n",
    "\n",
    "# test_rate_on_train_data(rate_35, 1000)\n",
    "# test_rate_on_solution(rate_35, -1)\n",
    "#generate_submission(rate_35)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722a4ba9",
   "metadata": {
    "papermill": {
     "duration": 0.014228,
     "end_time": "2024-01-16T11:33:22.748371",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.734143",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.2 Movie average-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c522321a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.779472Z",
     "iopub.status.busy": "2024-01-16T11:33:22.778695Z",
     "iopub.status.idle": "2024-01-16T11:33:22.784980Z",
     "shell.execute_reply": "2024-01-16T11:33:22.784122Z"
    },
    "papermill": {
     "duration": 0.024714,
     "end_time": "2024-01-16T11:33:22.787374",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.762660",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return the average rating given to a specific movie\n",
    "def rate_movie_average(uid, mid):\n",
    "    if mid not in avg_ratings:\n",
    "        return 3.5\n",
    "    return avg_ratings[mid]\n",
    "\n",
    "# test_rate_on_train_data(rate_movie_average, 1000)\n",
    "# test_rate_on_solution(rate_movie_average, -1)\n",
    "#generate_submission(rate_movie_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3537ca24",
   "metadata": {
    "papermill": {
     "duration": 0.01368,
     "end_time": "2024-01-16T11:33:22.815114",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.801434",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.3 User average-rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "72ef0711",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.845525Z",
     "iopub.status.busy": "2024-01-16T11:33:22.844446Z",
     "iopub.status.idle": "2024-01-16T11:33:22.851339Z",
     "shell.execute_reply": "2024-01-16T11:33:22.850152Z"
    },
    "papermill": {
     "duration": 0.024811,
     "end_time": "2024-01-16T11:33:22.853938",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.829127",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 µs, sys: 0 ns, total: 4 µs\n",
      "Wall time: 9.78 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we simply return the average rating a user has given in the past\n",
    "def rate_user_average(uid, mid):\n",
    "    return avg_rat_per_user[uid]\n",
    "\n",
    "# test_rate_on_train_data(rate_user_average, 1000)\n",
    "# test_rate_on_solution(rate_user_average, -1)\n",
    "# generate_submission(rate_user_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e4195b1",
   "metadata": {
    "papermill": {
     "duration": 0.013943,
     "end_time": "2024-01-16T11:33:22.883108",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.869165",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.4 Average between 3.2 and 3.3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba2fd74a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.914540Z",
     "iopub.status.busy": "2024-01-16T11:33:22.913675Z",
     "iopub.status.idle": "2024-01-16T11:33:22.921597Z",
     "shell.execute_reply": "2024-01-16T11:33:22.920021Z"
    },
    "papermill": {
     "duration": 0.026395,
     "end_time": "2024-01-16T11:33:22.924032",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.897637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 34.8 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Here we return the average between the average rating for the movie and the average rating given by the user\n",
    "def rate_average_movie_and_user(uid, mid):\n",
    "    return (rate_movie_average(uid, mid) + rate_user_average(uid, mid)) / 2\n",
    "\n",
    "#test_rate_on_train_data(rate_average_movie_and_user, 1000)\n",
    "# test_rate_on_solution(rate_average_movie_and_user, -1)\n",
    "# generate_submission(rate_average_movie_and_user)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc733c37",
   "metadata": {
    "papermill": {
     "duration": 0.014547,
     "end_time": "2024-01-16T11:33:22.952751",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.938204",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.5 User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "036d1087",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:22.985723Z",
     "iopub.status.busy": "2024-01-16T11:33:22.985285Z",
     "iopub.status.idle": "2024-01-16T11:33:22.994033Z",
     "shell.execute_reply": "2024-01-16T11:33:22.992737Z"
    },
    "papermill": {
     "duration": 0.028385,
     "end_time": "2024-01-16T11:33:22.996916",
     "exception": false,
     "start_time": "2024-01-16T11:33:22.968531",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6 µs, sys: 0 ns, total: 6 µs\n",
      "Wall time: 11 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_user_based(uid, mid):\n",
    "    nom, denom = 0, 0\n",
    "    if mid in ratings_per_mid_uid:\n",
    "        for u2 in ratings_per_mid_uid[mid]:\n",
    "            sim = pcc_data[uid][u2]\n",
    "            nom += sim * (ratings_per_mid_uid[mid][u2] - avg_rat_per_user[u2])\n",
    "            denom += abs(sim)\n",
    "    \n",
    "    avg = avg_rat_per_user[uid]\n",
    "    frac = 0\n",
    "    if denom != 0:\n",
    "        frac = nom / denom # TODO: why is denom sometimes 0?\n",
    "    return avg + frac\n",
    "\n",
    "# test_rate_on_train_data(rate_user_based, 1000)\n",
    "# test_rate_on_solution(rate_user_based, -1)\n",
    "# generate_submission(rate_user_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718f2e8a",
   "metadata": {
    "papermill": {
     "duration": 0.014166,
     "end_time": "2024-01-16T11:33:23.025432",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.011266",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.6 Item-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b9bbfdac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:23.055935Z",
     "iopub.status.busy": "2024-01-16T11:33:23.055471Z",
     "iopub.status.idle": "2024-01-16T11:33:23.064240Z",
     "shell.execute_reply": "2024-01-16T11:33:23.063007Z"
    },
    "papermill": {
     "duration": 0.02727,
     "end_time": "2024-01-16T11:33:23.066960",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.039690",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 10.3 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_item_based(uid, mid):\n",
    "    nom = 0\n",
    "    denom = 0\n",
    "    for mid2 in user_rating_db[uid]:\n",
    "        idx1 = mid_list[mid]\n",
    "        idx2 = mid_list[mid2]\n",
    "        \n",
    "        sim = cosine_sims[idx1][idx2]\n",
    "        nom += sim * user_rating_db[uid][mid2]\n",
    "        denom += abs(sim)\n",
    "    \n",
    "    if denom == 0:\n",
    "        return 3.5 # this happens if the scraped data didn't contain an overview for the filem with id \"mid\"\n",
    "    rating = nom / denom\n",
    "    return rating\n",
    "\n",
    "# test_rate_on_train_data(rate_item_based, 1000)\n",
    "# test_rate_on_solution(rate_item_based, -1)\n",
    "# generate_submission(rate_item_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd776f5",
   "metadata": {
    "papermill": {
     "duration": 0.014147,
     "end_time": "2024-01-16T11:33:23.096255",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.082108",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.7 Average Item-based User-based Collaborative Filtering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b8372aac",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:23.128526Z",
     "iopub.status.busy": "2024-01-16T11:33:23.128132Z",
     "iopub.status.idle": "2024-01-16T11:33:42.769958Z",
     "shell.execute_reply": "2024-01-16T11:33:42.768451Z"
    },
    "papermill": {
     "duration": 19.661151,
     "end_time": "2024-01-16T11:33:42.772747",
     "exception": false,
     "start_time": "2024-01-16T11:33:23.111596",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 19.6 s, sys: 4.21 ms, total: 19.6 s\n",
      "Wall time: 19.6 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_item_user_based(uid, mid):\n",
    "    return (rate_user_based(uid, mid) + rate_item_based(uid, mid)) / 2\n",
    "\n",
    "# test_rate_on_train_data(rate_item_user_based, 1000)\n",
    "# test_rate_on_solution(rate_item_user_based, -1)\n",
    "generate_submission(rate_item_user_based)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1daacec7",
   "metadata": {
    "papermill": {
     "duration": 0.014022,
     "end_time": "2024-01-16T11:33:42.801481",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.787459",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.8 Average over all previous methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f3ba8b31",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.833763Z",
     "iopub.status.busy": "2024-01-16T11:33:42.833351Z",
     "iopub.status.idle": "2024-01-16T11:33:42.841169Z",
     "shell.execute_reply": "2024-01-16T11:33:42.839873Z"
    },
    "papermill": {
     "duration": 0.027321,
     "end_time": "2024-01-16T11:33:42.843539",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.816218",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5 µs, sys: 0 ns, total: 5 µs\n",
      "Wall time: 9.54 µs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def rate_all_average(uid, mid):\n",
    "    rat = (rate_movie_average(uid, mid) + rate_user_average(uid, mid)\n",
    "            + rate_user_based(uid, mid) + rate_item_based(uid, mid)) / 4.\n",
    "    return rat\n",
    "\n",
    "# test_rate_on_train_data(rate_all_average, 1000)\n",
    "# test_rate_on_solution(rate_all_average, -1)\n",
    "# generate_submission(rate_all_average)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9622221a",
   "metadata": {
    "papermill": {
     "duration": 0.01412,
     "end_time": "2024-01-16T11:33:42.872584",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.858464",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### 3.9 Neural Network using Tensorflow\n",
    "#### 3.9.1 Generating Inputs and Outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed4ed5e0",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.904269Z",
     "iopub.status.busy": "2024-01-16T11:33:42.903828Z",
     "iopub.status.idle": "2024-01-16T11:33:42.911967Z",
     "shell.execute_reply": "2024-01-16T11:33:42.910994Z"
    },
    "papermill": {
     "duration": 0.027059,
     "end_time": "2024-01-16T11:33:42.914696",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.887637",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n%%time\\n# Neural Net Inputs and Outputs\\ndef getGenreBitmap(mid):\\n    bitmap = []\\n    genres = [\\'Action\\', \\'Adventure\\', \\'Animation\\', \"Children\\'s Comedy\", \\'Crime\\', \\'Documentary\\', \\'Drama\\', \\'Fantasy\\', \\'Film-Noir\\', \\'Horror\\', \\'Musical\\', \\'Mystery\\', \\'Romance\\', \\'Sci-Fi\\', \\'Thriller\\', \\'War\\', \\'Western\\', \\'(no genres listed)\\']\\n    for genre in genres:\\n        bitmap.append((0,1)[genre in movie_data[mid][\\'genres\\']])\\n    return bitmap\\n\\ndef getUserBitmap(uid):\\n    bitmap = len(users) * [0]\\n    bitmap[users.index(uid)] = 1\\n    return bitmap\\n\\ndef getMovieBitmap(mid):\\n    bitmap = len(movies) * [0]\\n    bitmap[movies.index(mid)] = 1\\n    return bitmap\\n\\ndef getData(uid, mid):\\n    mBitmap = getGenreBitmap(mid)\\n    uBitmap = getUserBitmap(uid)\\n    return mBitmap + uBitmap\\n\\nnn_training = {\\'in\\': [], \\'out\\': []}\\nfor uid, mid, rating, _ in train_data:\\n    nn_training[\\'in\\'].append(getData(uid, mid))\\n    nn_training[\\'out\\'].append(rating)\\n\\nnn_testing = {\\'in\\': [], \\'out\\': []}\\nfor uid, mid, rating, _ in solution_data:\\n    nn_testing[\\'in\\'].append(getData(uid, mid))\\n    nn_testing[\\'out\\'].append(rating)\\n\\nX_train, X_test, y_train, y_test = train_test_split(np.array(nn_training[\\'in\\']), np.array(nn_training[\\'out\\']))\\n'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# Neural Net Inputs and Outputs\n",
    "def getGenreBitmap(mid):\n",
    "    bitmap = []\n",
    "    genres = ['Action', 'Adventure', 'Animation', \"Children's Comedy\", 'Crime', 'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical', 'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western', '(no genres listed)']\n",
    "    for genre in genres:\n",
    "        bitmap.append((0,1)[genre in movie_data[mid]['genres']])\n",
    "    return bitmap\n",
    "\n",
    "def getUserBitmap(uid):\n",
    "    bitmap = len(users) * [0]\n",
    "    bitmap[users.index(uid)] = 1\n",
    "    return bitmap\n",
    "\n",
    "def getMovieBitmap(mid):\n",
    "    bitmap = len(movies) * [0]\n",
    "    bitmap[movies.index(mid)] = 1\n",
    "    return bitmap\n",
    "\n",
    "def getData(uid, mid):\n",
    "    mBitmap = getGenreBitmap(mid)\n",
    "    uBitmap = getUserBitmap(uid)\n",
    "    return mBitmap + uBitmap\n",
    "\n",
    "nn_training = {'in': [], 'out': []}\n",
    "for uid, mid, rating, _ in train_data:\n",
    "    nn_training['in'].append(getData(uid, mid))\n",
    "    nn_training['out'].append(rating)\n",
    "\n",
    "nn_testing = {'in': [], 'out': []}\n",
    "for uid, mid, rating, _ in solution_data:\n",
    "    nn_testing['in'].append(getData(uid, mid))\n",
    "    nn_testing['out'].append(rating)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(np.array(nn_training['in']), np.array(nn_training['out']))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cb01d5b",
   "metadata": {
    "papermill": {
     "duration": 0.01509,
     "end_time": "2024-01-16T11:33:42.945995",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.930905",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.2 Neural Network Definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "974b46f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:42.978508Z",
     "iopub.status.busy": "2024-01-16T11:33:42.978082Z",
     "iopub.status.idle": "2024-01-16T11:33:42.985717Z",
     "shell.execute_reply": "2024-01-16T11:33:42.984561Z"
    },
    "papermill": {
     "duration": 0.026385,
     "end_time": "2024-01-16T11:33:42.988083",
     "exception": false,
     "start_time": "2024-01-16T11:33:42.961698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\nmodel = tf.keras.Sequential([\\n    tf.keras.layers.Dense(300, activation='relu', input_shape=(len(nn_training['in'][0]),)),\\n    tf.keras.layers.Dense(200, activation='relu'),\\n    tf.keras.layers.Dense(50, activation='relu'),\\n    tf.keras.layers.Dense(1, activation='linear')\\n])\\n\\nmodel.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\\n\\nmodel.summary()\\n\""
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(300, activation='relu', input_shape=(len(nn_training['in'][0]),)),\n",
    "    tf.keras.layers.Dense(200, activation='relu'),\n",
    "    tf.keras.layers.Dense(50, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='linear')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "\n",
    "model.summary()\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e72180d0",
   "metadata": {
    "papermill": {
     "duration": 0.014822,
     "end_time": "2024-01-16T11:33:43.019190",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.004368",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.3 Train Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "21f0d9f9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.050653Z",
     "iopub.status.busy": "2024-01-16T11:33:43.050231Z",
     "iopub.status.idle": "2024-01-16T11:33:43.057732Z",
     "shell.execute_reply": "2024-01-16T11:33:43.056521Z"
    },
    "papermill": {
     "duration": 0.026193,
     "end_time": "2024-01-16T11:33:43.060261",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.034068",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\n%%time\\n# Neural Net Training\\n# TODO: do this in preprocessing and save the resulting network in a file\\nnum_epochs = 5\\nmodel.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\\nloss, mae = model.evaluate(X_test, y_test)\\nprint(f'Mean Absolute Error: {mae}')\\n\""
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "%%time\n",
    "# Neural Net Training\n",
    "# TODO: do this in preprocessing and save the resulting network in a file\n",
    "num_epochs = 5\n",
    "model.fit(X_train, y_train, epochs=num_epochs, validation_data=(X_test, y_test))\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Absolute Error: {mae}')\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf57475",
   "metadata": {
    "papermill": {
     "duration": 0.015361,
     "end_time": "2024-01-16T11:33:43.091018",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.075657",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.4 Use the Neural Network for predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "43910774",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.123527Z",
     "iopub.status.busy": "2024-01-16T11:33:43.123104Z",
     "iopub.status.idle": "2024-01-16T11:33:43.130540Z",
     "shell.execute_reply": "2024-01-16T11:33:43.129356Z"
    },
    "papermill": {
     "duration": 0.026938,
     "end_time": "2024-01-16T11:33:43.133182",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.106244",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'%%time\\n# Test using sample solution\\ndef nn_predict(data):\\n    predictions_raw = model.predict(np.array(data))\\n    calculated = []\\n    for pred in predictions_raw:\\n        calculated.append(half_star(pred[0]))\\n    return calculated\\n\\ncalculated = nn_predict(nn_testing[\\'in\\'])\\nactual = nn_testing[\\'out\\']\\nrsme = RSME(calculated, actual)\\nprint(f\"RSME: {rsme}\")\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"%%time\n",
    "# Test using sample solution\n",
    "def nn_predict(data):\n",
    "    predictions_raw = model.predict(np.array(data))\n",
    "    calculated = []\n",
    "    for pred in predictions_raw:\n",
    "        calculated.append(half_star(pred[0]))\n",
    "    return calculated\n",
    "\n",
    "calculated = nn_predict(nn_testing['in'])\n",
    "actual = nn_testing['out']\n",
    "rsme = RSME(calculated, actual)\n",
    "print(f\"RSME: {rsme}\")\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0898503d",
   "metadata": {
    "papermill": {
     "duration": 0.014836,
     "end_time": "2024-01-16T11:33:43.163280",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.148444",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "#### 3.9.5 Generate submission based on Neural Net predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6edc08f4",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-01-16T11:33:43.196698Z",
     "iopub.status.busy": "2024-01-16T11:33:43.196289Z",
     "iopub.status.idle": "2024-01-16T11:33:43.202192Z",
     "shell.execute_reply": "2024-01-16T11:33:43.201202Z"
    },
    "papermill": {
     "duration": 0.025543,
     "end_time": "2024-01-16T11:33:43.204459",
     "exception": false,
     "start_time": "2024-01-16T11:33:43.178916",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Generate the submission\n",
    "def generate_nn_submission():\n",
    "    f = open(SUBMISSION, 'w')\n",
    "    f.write(\"Id,rating\\n\")\n",
    "    for i, rating in enumerate(calculated):\n",
    "        f.write(f\"{i},{rating}\\n\")\n",
    "    f.close()\n",
    "\n",
    "# generate_nn_submission()"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "databundleVersionId": 6793654,
     "sourceId": 62199,
     "sourceType": "competition"
    },
    {
     "datasetId": 3907093,
     "sourceId": 6791701,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3909523,
     "sourceId": 6795472,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 3914000,
     "sourceId": 6802485,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 4013371,
     "sourceId": 6983232,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30558,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 93.162522,
   "end_time": "2024-01-16T11:33:45.990592",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-01-16T11:32:12.828070",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
