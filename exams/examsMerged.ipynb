{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "### Prof. Karl Aberer <br> Final Exam, Spring Semester 2018\n",
    "\n",
    "The following materials are allowed: exercise sheets\n",
    "and solutions, past exams with your own solution, personally written notes and personally collected documentation.\n",
    "  \n",
    "The exam will be held on your computer, but digital communication by any means is strictly prohibited. You are not allowed to use any form of Web browsing, except to connect to Moodle and to download and upload the exam. By participating to this exam you agree to these conditions.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "1. You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "* We will publish 15 minutes before the end of the exam a password for uploading your solutions on Moodle.\n",
    "* It is not recommended to leave the exam before the password is published. If you need to leave earlier contact us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Multiple Choice Questions\n",
    "\n",
    "Answer the [multiple choice questions in Moodle](https://moodle.epfl.ch/mod/quiz/view.php?id=988129) as in the quizzes.\n",
    "\n",
    "The password for answering the quiz is: **wBHNcJZd**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: User Classification in Social Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume we would like to identify Twitter user accounts $T$ that have interest in Swiss universities.\n",
    "\n",
    "Given that we have no training data, we analyse the social relationships of those users.\n",
    "\n",
    "More specifically, we consider that users that follow an Twitter account $S$ related to a Swiss University (e.g. @EPFL, @EPFL\\_en, @ETHZ etc.) show interest for Swiss universities. We assume that $S$ and $T$ are disjoint. We capture the follower relationship in a matrix $F$, where an entry $f_{ij} = 1$ indicates a follower link from user account $i\\in T$ to university account $j\\in S$. Otherwise the entry is zero.\n",
    "\n",
    "We would like to assess the level of interest of users into Swiss universities by using two methods:\n",
    "1. The HITS algorithm, where we consider the Swiss university accounts as authorities and the users we intend to classify as hubs. A high hub value $t_i$ for user $i\\in T$ should indicate a high level of interest in Swiss universities, a high authority value $s_j$ indicates that university account $j\\in S$ is a good indicator for interest in Swiss universities.\n",
    "2. The EM algorithm, where we consider the existence of a follower link from a user to a Swiss university account as a positive feedback given that university account on the interest of the user , and the absence of such a link as negative feedback (i.e. we consider the university accounts like experts and the users like the item to be evaluated). A high level of positive feedback $t_i$ for user $i\\in T$ indicates interest in Swiss universities, and a high expertise value $s_j$ indicates that university account $j\\in S$ is a good indicator for interest in Swiss universities.\n",
    "\n",
    "### Questions\n",
    "\n",
    "1) Formulate the two algorithms (HITS and EM) using the following patterns for a recursive computation of $t$ and $s$\n",
    "\n",
    "HITS:  $\\vec{t}_{k+1} = r_1  M_1. \\vec{v_1},\\ \\vec{s}_{k+1} = r_2  M_2 . \\vec{v_2}$\n",
    "\n",
    "EM:    $\\vec{t}_{k+1} = r_3  M_3 . \\vec{v_3},\\ \\vec{s}_{k+1} = r_4 (M_4.\\vec{v_4} + M_5.\\vec{v_5})$\n",
    "\n",
    "$\\vec{t}=(t_1,\\ldots,t_n)$ and $\\vec{s}=(s_1,\\ldots,s_m)$ are the vectors ranking interest and expertise of users and universities. Your task is to express $r_p$, $\\vec{v_p}$ and $M_p$, $p=1,\\ldots,5$ in terms of $\\vec{t}_{k}$, $\\vec{s}_{k}$ and $F$, where $r_p$ are scalars, $\\vec{v_p}$ are vectors and $M_p$ are matrices.\n",
    "\n",
    "You can use also the following functions:\n",
    "\n",
    "$|\\vec{v}|_2$ for the 2-norm\n",
    "\n",
    "$|\\vec{v}|_1$ for the 1-norm\n",
    "\n",
    "$M^t$ for the matrix transpose\n",
    "\n",
    "$round(\\vec{v})$ for rounding the values of a vector in $[0,1]$ to $0$ and $1$\n",
    " \n",
    "2) For HITS: in which sense is the input to the algorithm a special case of the most general possible inputs? Which additional constraints does the formulation of the problem satisfy?\n",
    "\n",
    "3) Assume after applying HITS or EM you perform a binary classification of the accounts by setting a threshold on the values in $\\vec{t}$, i.e., all accounts with a authority/interest value above the threshold are considered as accounts interested in Swiss universities. Identify and shortly describe a simple, standard classification algorithm that uses the accounts with binary labels as training data to classify new accounts and that does not require training (and does not rely on recomputing HITS or EM).\n",
    "  \n",
    "Please provide your answers in the cell below:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3:  Betweenness Centrality in Social Networks\n",
    "  \n",
    "  \n",
    "\"Les mis√©rables\" is a novel written by Victor Hugo and is considered as one of the greatest novels of the 19th century. In this question, you will analyze the social network composed by the protagonists of the novel. The character network represents the interactions among character and has been created, by hand, by Donald E. Knuth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import pandas as pd\n",
    "import operator\n",
    "import networkx as nx\n",
    "import matplotlib.pylab as plt\n",
    "import matplotlib.colors as mcolors\n",
    "from dis_helpers import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "G = ex1_load_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "ex1_draw(G, nx.betweenness_centrality(G))\n",
    "centr = nx.betweenness_centrality(G,normalized=False)\n",
    "\n",
    "ex1_print_topn(centr,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definition\n",
    "\n",
    "In this problem, you will have to implement node betweeness centrality, a measure that provide a score for every node $n$ of a graph $G$.  \n",
    "  \n",
    "Betweenness centrality $c_B(n)$ of a node $n$ is the sum of the fraction of all-pairs shortest paths that pass through $n$:  \n",
    "  \n",
    "$\\Large c_B(n) =\\sum_{s,t \\in N} \\frac{\\sigma(s, t|n)}{\\sigma(s, t)}$\n",
    "  \n",
    "where $N$ is the set of nodes, $\\sigma(s, t)$ is the number of shortest paths connecting $s$ and $t$, and $\\sigma(s, t|n)$ is the number of paths passing through node $n$, provided $n$ is different from $s$ and $t$. For the other cases $\\sigma(s, t|n)$ is defined as follows: \n",
    "* If $s = t$: $\\sigma(s, t) = 1$\n",
    "* If $n \\in \\{s, t\\}$: $\\sigma(s, t|n) = 0$\n",
    "\n",
    "Note that this definition of node betweenness employs no normalization.\n",
    "  \n",
    "### Code Cheat Sheet\n",
    "\n",
    "Here we provide a few explainations about some of the functions you might need.\n",
    "\n",
    "The function ``enumerate(['a','b','c'])`` provides a convenient way to create an index while iterating over a list. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i,n in enumerate(['Napoleon','Myriel','Mlle.Baptistine','Mme.Magloire']):\n",
    "    print(i,n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function ``nx.all_shortest_paths(G,s,t)`` returns a list of all the shortest paths between nodes $s$ and $t$, given the graph $G$. Note that you can directly use node labels to specify the nodes, such as in the example below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "for i in nx.all_shortest_paths(G,'Tholomyes','Mme.Magloire'):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Questions\n",
    "1) Fill the code skeleton below to compute the betweenness centrality for every node of the graph.   \n",
    "\n",
    "2) The proposed code skeleton has an unnecessary high time complexity. Can you propose a solution to decrease it? Please answer in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) Does the PageRank algorithm always produce the same values as node betweenness, after normalizing the node betweenness values to the interval [0,1]? For PageRank, consider that every edge of the undirected graph is replaced by two directed edges going in both directions. Provide an answer and an argument to support your answer in the cell below. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "characters = list(G.nodes())\n",
    "result   = {}\n",
    "\n",
    "# compute a score fo every character\n",
    "for n in characters:\n",
    "\n",
    "    # accumulator for the score of the current character\n",
    "    accum = 0\n",
    "\n",
    "    # shortest path FROM every character...\n",
    "    for i,s in enumerate(characters):\n",
    "        # ..TO every character\n",
    "        for j,t in enumerate(characters):\n",
    "            # we do not consider the same path twice\n",
    "            if j > i:\n",
    "                continue\n",
    "            \n",
    "            try:  \n",
    "                all_short = nx.all_shortest_paths(G,s,t)\n",
    "                \n",
    "                ### SOLUTION ####################################\n",
    "                num   = 0\n",
    "                denum = 0\n",
    "                for p in all_short:\n",
    "\n",
    "                    px = set(p)\n",
    "                    px = px - set([s])\n",
    "                    px = px - set([t])\n",
    "                    if n in px:\n",
    "                        num += 1\n",
    "                    denum += 1\n",
    "                    \n",
    "                if s==t:\n",
    "                    denum = 1\n",
    "\n",
    "                if n==s or n==t:\n",
    "                    num = 0\n",
    "                \n",
    "                accum += float(num)/float(denum)\n",
    "                ### END SOLUTION ################################\n",
    "                \n",
    "            except nx.NetworkXNoPath:\n",
    "                continue\n",
    "                \n",
    "    result[n] = accum\n",
    "    \n",
    "ex1_print_topn(result,10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 4: Sentiment Classification of Movie Reviews\n",
    "The goal of this problem is to build an end-to-end _Sentiment Classification_ pipeline. In order to achieve this, you will have to go through the subtasks that are indicated below and fill in the code in the respective placeholders. Notice that you are not allowed to use external libraries other than the ones that are already imported in the project.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "#Required libraries.\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    neg_reviews = []\n",
    "    pos_reviews = []\n",
    "    DIR = 'movie_reviews/'\n",
    "\n",
    "    for l, sent in [(neg_reviews, 'neg'), (pos_reviews, 'pos')]:\n",
    "        for file in os.listdir(DIR+sent):\n",
    "            with open(os.path.join(DIR+sent, file)) as f:\n",
    "                text = f.read()\n",
    "            # split into words\n",
    "            tokens = word_tokenize(text)\n",
    "            # convert to lower case\n",
    "            tokens = [w.lower() for w in tokens]\n",
    "            # remove punctuation from each word\n",
    "            table = str.maketrans('', '', string.punctuation)\n",
    "            stripped = [w.translate(table) for w in tokens]\n",
    "            # remove remaining tokens that are not alphabetic\n",
    "            words = [word for word in stripped if word.isalpha()]\n",
    "            # filter out stop words\n",
    "            words = [w for w in words if not w in stop_words]\n",
    "\n",
    "            l.append(' '.join(words))\n",
    "    return neg_reviews, pos_reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1\n",
    "Split your corpus into a training and a test set with ratio 9:1. \n",
    "* _Hint: Make sure that both sets are equally populated w.r.t. the two sentiments._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "neg_reviews, pos_reviews = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############### ADD YOUR CODE HERE ###############\n",
    "neg_reviews_train = []\n",
    "pos_reviews_train = []\n",
    "\n",
    "neg_reviews_test = []\n",
    "pos_reviews_test = []\n",
    "\n",
    "reviews_train = []\n",
    "reviews_test = []\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "# ############### SOLUTION ###############\n",
    "# neg_reviews_train = neg_reviews[:int(len(neg_reviews)*0.9)]\n",
    "# pos_reviews_train = pos_reviews[:int(len(pos_reviews)*0.9)]\n",
    "\n",
    "# neg_reviews_test = neg_reviews[int(len(neg_reviews)*0.9):]\n",
    "# pos_reviews_test = pos_reviews[int(len(pos_reviews)*0.9):]\n",
    "\n",
    "# reviews_train = neg_reviews_train + pos_reviews_train\n",
    "# reviews_test = neg_reviews_test + pos_reviews_test\n",
    "# ############### SOLUTION ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2\n",
    "Transform the reviews of the training set into vectors using the Bag-Of-Words model. Each dimension of a vector must count the number of occurences of a word in the review.\n",
    "* _Hint 1: Make sure that all the vectors belong to the same space._\n",
    "* _Hint 2: For this task you can reuse code from the first exercise of DIS2018 (Vector Space Retrieval)._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def create_vocabulary(corpus, min_tf):\n",
    "    '''Creates the vocabulary (set of distinct words) that appear more than $min_tf$ times in the corpus.'''\n",
    "    \n",
    "    count = {}\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 0\n",
    "    \n",
    "    vocabulary = []\n",
    "    for w, c in count.items():\n",
    "        if c > min_tf:\n",
    "            vocabulary.append(w)\n",
    "    \n",
    "    return vocabulary\n",
    "    \n",
    "vocabulary = create_vocabulary(reviews_train, len(reviews_train)*0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def transform_to_vector(reviews):\n",
    "    '''Transforms a list of reviews to a list of vectors.'''\n",
    "    \n",
    "    reviews_vec = []\n",
    "\n",
    "    for review in reviews:\n",
    "        \n",
    "        \n",
    "        ############### ADD YOUR CODE HERE ###############\n",
    "        vector = []\n",
    "        ############### ADD YOUR CODE HERE ###############\n",
    "        \n",
    "#         ############### SOLUTION ###############\n",
    "#         count = {}\n",
    "#         for word in review.split():\n",
    "#             if word in count:\n",
    "#                 count[word] += 1\n",
    "#             else:\n",
    "#                 count[word] = 0\n",
    "\n",
    "#         #move to vocabulary space\n",
    "#         vector = [0]*len(vocabulary)\n",
    "#         for i,term in enumerate(vocabulary):\n",
    "#             if term in count:\n",
    "#                 vector[i] = count[term]\n",
    "        \n",
    "#         ############### SOLUTION ###############\n",
    "\n",
    "        reviews_vec.append(vector)\n",
    "\n",
    "    return reviews_vec\n",
    "\n",
    "neg_reviews_train_vec = transform_to_vector(neg_reviews_train)\n",
    "pos_reviews_train_vec = transform_to_vector(pos_reviews_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 \n",
    "Aggregate the vectors of the positive and negative reviews of the training set into a single vector. This vector will be the representative vector of each of the two sentiments. Which aggregation function did you choose and why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def aggregate_vector_list(vlist, aggfunc):\n",
    "    if aggfunc == 'max':\n",
    "        return np.array(neg_reviews_train_vec).max(axis=0)\n",
    "    elif aggfunc == 'min':\n",
    "        return np.array(neg_reviews_train_vec).min(axis=0)\n",
    "    elif aggfunc == 'mean':\n",
    "        return np.array(neg_reviews_train_vec).mean(axis=0)\n",
    "    else:\n",
    "        return np.zeros(np.array(neg_reviews_train_vec).shape[1])\n",
    "\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "neg_reviews_repr = []\n",
    "pos_reviews_repr = []\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "# ############### SOLUTION ###############\n",
    "# neg_reviews_repr = aggregate_vector_list(neg_reviews_train_vec, 'mean')\n",
    "# pos_reviews_repr = aggregate_vector_list(pos_reviews_train_vec, 'mean')\n",
    "# ############### SOLUTION ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4\n",
    "Transform the reviews of the movies in the test set into vectors. \n",
    "* _Hint: Make sure that all the vectors belong to the same space as the ones from the training set._\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############### ADD YOUR CODE HERE ###############\n",
    "neg_reviews_test_vec = []\n",
    "pos_reviews_test_vec = []\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "# ############### SOLUTION ###############\n",
    "# neg_reviews_test_vec = transform_to_vector(neg_reviews_test)\n",
    "# pos_reviews_test_vec = transform_to_vector(pos_reviews_test)\n",
    "# ############### SOLUTION ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 5\n",
    "Consider the following Naive Bayes sentiment classifier:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(sentiment | review)   = \\frac{P(review | sentiment) * P(sentiment)}{P(review)}\n",
    "\\end{equation*}\n",
    "\n",
    "Assume that you can estimate the likelihood probability as follows:\n",
    "\n",
    "\\begin{equation*}\n",
    "P(review | sentiment) = cosine\\_similarity(review\\_vec, sentiment\\_representative\\_vec)\n",
    "\\end{equation*}\n",
    "\n",
    "1) How do you take into account the probabilities: $P(sentiment)$ and $P(review)$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Answer:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) Implement the classifier and compute its performance in terms of false negatives, true negatives, falsepositives and true positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "fn = 0\n",
    "tn = 0\n",
    "fp = 0\n",
    "tp = 0\n",
    "\n",
    "def cosine_similarity(a,b):\n",
    "    '''Computes the cosine similarity of $a$ and $b$.'''\n",
    "    dot_product = np.dot(a, b)\n",
    "    norm_a = np.linalg.norm(a)\n",
    "    norm_b = np.linalg.norm(b)\n",
    "    return dot_product / (norm_a * norm_b)\n",
    "    \n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "# ############### SOLUTION ###############\n",
    "# def naive_bayes(review_vec):\n",
    "#     if  cosine_similarity(np.array(review_vec), neg_reviews_repr) > cosine_similarity(np.array(review_vec), pos_reviews_repr):\n",
    "#         return 'neg'\n",
    "#     else:\n",
    "#         return 'pos'\n",
    "\n",
    "# for review_vec in neg_reviews_test_vec:\n",
    "#     if naive_bayes(review_vec) == 'neg':\n",
    "#         tn +=1\n",
    "#     else:\n",
    "#         fp +=1\n",
    "\n",
    "# for review_vec in pos_reviews_test_vec:\n",
    "#     if naive_bayes(review_vec) == 'neg':\n",
    "#         fn +=1\n",
    "#     else:\n",
    "#         tp +=1\n",
    "# ############### SOLUTION ###############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 6\n",
    "Compute the _F-measure_ to evaluate your classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "############### ADD YOUR CODE HERE ###############\n",
    "precision = 0\n",
    "recall = 0\n",
    "f_measure = 0\n",
    "print('F-measure: ', f_measure)\n",
    "############### ADD YOUR CODE HERE ###############\n",
    "\n",
    "# ############### SOLUTION ###############\n",
    "# precision = tp/(tp+fp)\n",
    "# recall = tp/(tp+fn)\n",
    "# f_measure = 2*precision*recall/(precision+recall)\n",
    "# print('F-measure: ', f_measure)\n",
    "# ############### SOLUTION ###############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "\n",
    "***Final Exam, Spring Semester, 2019***\n",
    "\n",
    "The exam will be held on your computer, but digital communication by any means is **strictly prohibited**. You are allowed, though, to use *StackOverflow* or similar websites to resolve syntax-related Python errors. \n",
    "The following materials are also allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation.\n",
    "By participating in this exam you **agree to these conditions**.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "\n",
    "- You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "- The quiz will remain open **only for the first 2 hours** of the exam to avoid network congestion.\n",
    "- **30 minutes** before the end of the exam we will announce a password to upload your jupyter notebook on Moodle.\n",
    "- It is not recommended to leave the exam before the password is published. If you need to leave earlier, contact us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#0-Rename-your-notebook\" data-toc-modified-id=\"0-Rename-your-notebook-0\">0 Rename your notebook</a></span></li><li><span><a href=\"#1-Multiple-Choice-Questions\" data-toc-modified-id=\"1-Multiple-Choice-Questions-1\">1 <a href=\"https://moodle.epfl.ch/mod/quiz/view.php?id=1026316\" target=\"_blank\">Multiple Choice Questions</a></a></span></li><li><span><a href=\"#2-Implementing-a-Rule-Based-Approach-for-Entity-Disambiguation\" data-toc-modified-id=\"2-Implementing-a-Rule-Based-Approach-for-Entity-Disambiguation-2\">2 Implementing a Rule-Based Approach for Entity Disambiguation</a></span><ul class=\"toc-item\"><li><span><a href=\"#2.1-Learning-rules\" data-toc-modified-id=\"2.1-Learning-rules-2.1\">2.1 Learning rules</a></span></li><li><span><a href=\"#2.2-Finding-new-rules-using-bootstrapping\" data-toc-modified-id=\"2.2-Finding-new-rules-using-bootstrapping-2.2\">2.2 Finding new rules using bootstrapping</a></span></li></ul></li><li><span><a href=\"#3-Academic-Communities\" data-toc-modified-id=\"3-Academic-Communities-3\">3 Academic Communities</a></span><ul class=\"toc-item\"><li><span><a href=\"#3.1-Modularity\" data-toc-modified-id=\"3.1-Modularity-3.1\">3.1 Modularity</a></span></li><li><span><a href=\"#3.2-Community-Detection\" data-toc-modified-id=\"3.2-Community-Detection-3.2\">3.2 Community Detection</a></span></li><li><span><a href=\"#3.3-Community-Influencers\" data-toc-modified-id=\"3.3-Community-Influencers-3.3\">3.3 Community Influencers</a></span></li><li><span><a href=\"#3.4-Connectivity-Based-Community-Ranking\" data-toc-modified-id=\"3.4-Connectivity-Based-Community-Ranking-3.4\">3.4 Connectivity-Based Community Ranking</a></span></li><li><span><a href=\"#3.5-Personalized-Community-Ranking\" data-toc-modified-id=\"3.5-Personalized-Community-Ranking-3.5\">3.5 Personalized Community Ranking</a></span></li><li><span><a href=\"#3.6-TF-IDF-Community-Ranking\" data-toc-modified-id=\"3.6-TF-IDF-Community-Ranking-3.6\">3.6 TF-IDF Community Ranking</a></span></li><li><span><a href=\"#3.7-Rankings-Correlation\" data-toc-modified-id=\"3.7-Rankings-Correlation-3.7\">3.7 Rankings Correlation</a></span></li></ul></li><li><span><a href=\"#Removed\" data-toc-modified-id=\"Removed-4\">Removed</a></span><ul class=\"toc-item\"><li><span><a href=\"#What-is-a-profile-based-recommendation-ranking-for-a-user?\" data-toc-modified-id=\"What-is-a-profile-based-recommendation-ranking-for-a-user?-4.1\">What is a profile-based recommendation ranking for a user?</a></span></li><li><span><a href=\"#What-is-the-ranking-of-the-communities-based-on-the-importance-of-their-nodes?\" data-toc-modified-id=\"What-is-the-ranking-of-the-communities-based-on-the-importance-of-their-nodes?-4.2\">What is the ranking of the communities based on the importance of their nodes?</a></span></li><li><span><a href=\"#What-is-the-ranking-of-the-communities-based-on-their-intra-connectivity?\" data-toc-modified-id=\"What-is-the-ranking-of-the-communities-based-on-their-intra-connectivity?-4.3\">What is the ranking of the communities based on their intra-connectivity?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Rename your notebook\n",
    "Replace SciperNo with your **personal SCIPER Number**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 [Multiple Choice Questions](https://moodle.epfl.ch/mod/quiz/view.php?id=1026316)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Implementing a Rule-Based Approach for Entity Disambiguation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Learning rules\n",
    "\n",
    "We would like to develop a rule-based approach to disambiguate the meaning of the term \"Apple\" in sentences into the two possible meanings **Tech** and **Fruit**. The rules use keyphrases i.e., n-grams of words, as features in their conditions. In the approach **only the top-k keyphrases** are considered. Before forming keyphrases, the words are stemmed, stopwords are not considered and uppercase words are converted to lowercase.\n",
    "\n",
    "An example of a possible rule would be:\n",
    "\n",
    "\tif \"fruit\" and \"facebook\" then \"Tech\"\n",
    "\n",
    "meaning that if a sentence that contains the term \"Apple\" also contains the unigrams \"fruit\" and \"facebook\" then the meaning of \"Apple\" should be the Apple technology company (**Tech**).\n",
    "\n",
    "More generally we write such rules as:\n",
    "\n",
    "\t{k1,...,kn} -> Tech or {k1,...,kn} -> Fruit\n",
    "    \n",
    "where k1,..,kn are arbitrary word n-grams and a set {k1,...,kn} is considered as an item set.\n",
    "\n",
    "As **training data** we obtain 10 sentences containing \"Apple\" that have been labelled by their meaning as T(ech) or F(ruit).\n",
    "\n",
    "    An apple is a fruit and good for health. (F)\n",
    "    Apple is a tech company. (T)\n",
    "    Tech companies like Apple and Facebook have big data centers (T)\n",
    "    For maintaining health eat one apple a day. (F)\n",
    "    A new Apple data center has been opened next to the one of Facebook. (T)\n",
    "    Apple has sold 1 million units in one day. (T)\n",
    "    Fruits, like apples and pears, are contaminated with pesticides.  (F)\n",
    "    A fruit salad contains apples, bananas and pears.  (F)\n",
    "    I saw a new apple recipe on Facebook.  (F)\n",
    "    Apple is increasingly processing health data. (T)\n",
    "\n",
    "**Stopwords** are: an, is, a, and, for, like, and, have, has, been, in, are, with, on, by, as, may, one, to, the, of.\n",
    "\n",
    "We define the **confidence** of a rule {k1,...,kn} -> T as the fraction between the number of sentences that contain all keyphrases k1,...,kn with label T over the number of sentences with all keyphrases k1,...,kn. Similar definition for {k1,...,kn} -> F.\n",
    "\n",
    "We define the **support** of an itemset as the number of sentences that contain all the n-grams in the itemset.\n",
    "\n",
    "**Questions:** \n",
    "1. Without considering the word \"apple\", determine the keyphrases with minimum document frequency of 2.\n",
    "2. Determine all itemsets of keyphrases with a minimum support of 2.\n",
    "3. Determine all rules that have a minimum support of 2 and a minimum confidence of 70%. Provide for each rule its support and confidence values. \n",
    "4. Explain how the apriori property could be exploited in optimizing the computation of those itemsets for composite keyphrases.\n",
    "\n",
    "Hint: the following are the top-10 document frequencies of terms.\n",
    "\n",
    "| Term        | Frequency           | \n",
    "| ------------- |:-------------:| \n",
    "|fruit | 3|\n",
    "|health | 3|\n",
    "|data | 3|\n",
    "|facebook | 3|\n",
    "|tech | 2|\n",
    "|compani | 2|\n",
    "|center | 2|\n",
    "|day | 2|\n",
    "|new | 2|\n",
    "|pear |2|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2 Finding new rules using bootstrapping\n",
    "\n",
    "We are using the rules we have learnt now to find new sentences on Apple (e.g. using Google search) to increase our training data and thus learning new rules.\n",
    "\n",
    "Performing this approach we found 10 more sentences:\n",
    "\n",
    "    Apple and Facebook data center filed plans to expand data center operations in Prineville (T) \n",
    "    Apple, Facebook, Google Asked to Pay for Wind Parks in Denmark (T) \n",
    "    Google, Facebook and Apple lead on green data centers (T)\n",
    "    Apple to contest patent filed by Google. (T) \n",
    "    Green data centers are the new priority for Apple and Google. (T)\n",
    "    Green apples are an ideal ingredient for fruit salad. (F)\n",
    "    Apple Pears have been described as the hottest new item since the Kiwi (F)\n",
    "    Join Facebook to connect with Apples Pear and others you may know (F)\n",
    "    An apple is a sweet, edible fruit produced by an apple tree (F)\n",
    "    An apple a day keeps the doctor away (F)\n",
    "\n",
    "**Questions:** \n",
    "\n",
    "1. Given that the size of the training set has increased, should confidence and/or support threshold be adapted and how?\n",
    "2. Identify all new rules with adapted confidence and support threshold that can be derived from the training set that has been enlarged by the examples that have been retrieved using a bootstrapping approach.\n",
    "3. Once you found a new rule, explain how you would proceed to verify that the new rule does not introduce semantic shift."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Academic Communities\n",
    "The dataset you are about to explore is a snapshot of the **retweet network** among official accounts of universities and academic institutes. The **nodes** of the network are twitter handles (usernames), while the **edges** are attributed with a **label**, which was extracted from the topic of the tweet, and a **weight**, which depicts the popularity of the original tweet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from networkx.algorithms import community\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "G = nx.from_pandas_edgelist(pd.read_csv('uni_network.csv'), 'Source', 'Target', edge_attr=['Label', 'Weight'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Modularity\n",
    "- Implement the modularity metric for communities.\n",
    "- Use the toy example and the assertion below to validate your results.\n",
    "- Hint: You can reuse code from the exercise sessions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def communities_modularity(G, nodes_community):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "       output: Q (modularity metric)\n",
    "    '''\n",
    "    Q = 0\n",
    "    \n",
    "    # Add your code here\n",
    "    m = len(G.edges)\n",
    "    for node_i in G.nodes:\n",
    "        for node_j in G.nodes:\n",
    "            if nodes_community[node_i] == nodes_community[node_j]:\n",
    "                Q += G.number_of_edges(node_i, node_j) - G.degree[node_i]*G.degree[node_j]/(2*m)\n",
    "    Q = Q/(2*m)\n",
    "    # Add your code here\n",
    "\n",
    "    return Q \n",
    "\n",
    "Q = communities_modularity(nx.Graph([(1, 2), (2, 3), (3, 1)]), {1:'a', 2:'a', 3:'a'})\n",
    "assert (round(Q, 4) == 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Community Detection\n",
    "\n",
    "- In the following cells you are given two snippets of code for community detection:\n",
    "    - The first approach (`network_structure_communities`) computes communities based on the **network structure**. The algorithm that is used is the *Clauset-Newman-Moore greedy modularity maximization* and is similar to the *Louvain modularity maximization*.\n",
    "    - The second approach (`nodes_label_communities`) computes communities based on the **labels of the graph nodes**. The label of a node is determined by the dominant label of its edges. All nodes with the same label belong to the same community.\n",
    "\n",
    "- Based on the statistics that we present below, discuss what are the **pros and cons** of each approach.\n",
    "- Note: You don't have to code for this task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def network_structure_communities(G):\n",
    "    nodes_community = community.greedy_modularity_communities(G, weight='Weight')\n",
    "    nodes_community = {i:indx for indx, c in enumerate(nodes_community) for i in c}\n",
    "    nodes_community = {n:nodes_community[n] for n in G.nodes}\n",
    "    return nodes_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nodes_label_communities(G):\n",
    "    nodes_community = {}\n",
    "    for n in G.nodes():\n",
    "        labels = [[e[2]['Label']]*e[2]['Weight'] for e in G.edges(n, data=True)]\n",
    "        labels = [item for l in labels for item in l]\n",
    "        nodes_community[n] = max(set(labels), key = labels.count)\n",
    "    return nodes_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Average Community Size</th>\n",
       "      <th>Communities Count</th>\n",
       "      <th>Modularity</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1st approach</th>\n",
       "      <td>3.192053</td>\n",
       "      <td>453</td>\n",
       "      <td>0.919974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2nd approach</th>\n",
       "      <td>48.200000</td>\n",
       "      <td>30</td>\n",
       "      <td>0.688264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              Average Community Size  Communities Count  Modularity\n",
       "                                                                   \n",
       "1st approach                3.192053                453    0.919974\n",
       "2nd approach               48.200000                 30    0.688264"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compare_approaches(G):\n",
    "    nodes_community_1 = network_structure_communities(G)\n",
    "    nodes_community_2 = nodes_label_communities(G)\n",
    "    communities_count_1 = len(set(nodes_community_1.values()))\n",
    "    communities_count_2 = len(set(nodes_community_2.values()))\n",
    "\n",
    "    return pd.DataFrame.from_dict([{'':'1st approach', 'Communities Count':communities_count_1, 'Average Community Size':len(G.nodes())/communities_count_1, 'Modularity':communities_modularity(G, nodes_community_1)},\\\n",
    "                                   {'':'2nd approach', 'Communities Count':communities_count_2, 'Average Community Size':len(G.nodes())/communities_count_2, 'Modularity':communities_modularity(G, nodes_community_2)}]).set_index('')\n",
    "\n",
    "compare_approaches(G)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following tasks we will use the communities that are detected by the **second approach**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_community = nodes_label_communities(G)\n",
    "communities = list(set(nodes_community.values()))\n",
    "communities_count = len(communities)\n",
    "default_ranking = {c:0.0 for c in communities}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Community Influencers\n",
    "- Isolate each community from the graph. \n",
    "- Select the node with the **maximum pagerank** within each community as the **influencer** of that community.\n",
    "- Break ties arbitrarily.\n",
    "- Hint: Useful functions: `nx.pagerank()`, `G.subgraph()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('architecture', 'UniofGreenwich'),\n",
       " ('artificial intelligence', 'HECParis'),\n",
       " ('astronomy', 'HistAstro'),\n",
       " ('biological', 'thatsfarming'),\n",
       " ('cancer', 'IrishCancerSoc'),\n",
       " ('cell', 'GilesYeo'),\n",
       " ('chemistry', 'UniofNottingham'),\n",
       " ('climate change', 'meganrowling'),\n",
       " ('computer science', 'UniofHerts'),\n",
       " ('criminology', 'ARUEngagement'),\n",
       " ('cyber security', 'eevriviades'),\n",
       " ('diabetes', 'UoMNews'),\n",
       " ('drones', 'HarperAdamsUni'),\n",
       " ('economics', 'EmPoints'),\n",
       " ('entrepreneurship', 'RoyalAgUni'),\n",
       " ('geography', 'drheatherprice'),\n",
       " ('healthcare', 'VoiceofNursing_'),\n",
       " ('infection', 'UofGMVLS'),\n",
       " ('innovation', 'tcddublin'),\n",
       " ('medicine', 'learnhospice'),\n",
       " ('neuroscience', 'ArtScienceDoc'),\n",
       " ('pathways', 'RyanAcademy'),\n",
       " ('patients', 'WPXI'),\n",
       " ('physicist', 'royalsociety'),\n",
       " ('physics', 'SymeonDagkas'),\n",
       " ('psychology', 'BPSOfficial'),\n",
       " ('robotics', 'Phil_Baty'),\n",
       " ('social media', 'NYDailyNews'),\n",
       " ('sustainability', 'UniversityLeeds'),\n",
       " ('therapy', 'UBICBrighton')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def community_influencers(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: influencers:{community_id:node_id}\n",
    "    '''\n",
    "    influencers = {}\n",
    "    \n",
    "    # Add your code here\n",
    "    \n",
    "    for c in communities:\n",
    "        nodes = [n for n in G.nodes if nodes_community[n]==c]\n",
    "        pr = nx.pagerank(G.subgraph(nodes))\n",
    "        influencers[c] = max(pr, key=pr.get)\n",
    "\n",
    "    # Add your code here\n",
    "    \n",
    "    return influencers\n",
    "\n",
    "influencers = community_influencers(G, nodes_community, communities, communities_count)\n",
    "sorted(influencers.items(), key=lambda x: x[0]) if influencers != {} else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Connectivity-Based Community Ranking\n",
    "- Compute a meta graph where nodes are communities and edges denote inter-connections across communities. \n",
    "- Add the weights of the inter-connections as weights to the edges.\n",
    "- Compute `pagerank` on the meta graph.\n",
    "- Hint: `w_matrix` is the confusion matrix of the weights among the communities. `w_matrix` is not symmetric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('innovation', 0.1175316220359166),\n",
       " ('artificial intelligence', 0.1157057509495049),\n",
       " ('psychology', 0.07266281991431879),\n",
       " ('entrepreneurship', 0.0565836336445204),\n",
       " ('sustainability', 0.05043936029740328),\n",
       " ('computer science', 0.044925965192617864),\n",
       " ('physics', 0.04192640288042445),\n",
       " ('climate change', 0.03774773967426391),\n",
       " ('chemistry', 0.036150780561586215),\n",
       " ('architecture', 0.03318939114735931),\n",
       " ('economics', 0.02994993856239657),\n",
       " ('social media', 0.029270293765880844),\n",
       " ('patients', 0.02668015432185533),\n",
       " ('cyber security', 0.026417237694418127),\n",
       " ('biological', 0.025453215452582906),\n",
       " ('healthcare', 0.024964310859068403),\n",
       " ('robotics', 0.023854191645331445),\n",
       " ('medicine', 0.022594739356807246),\n",
       " ('drones', 0.02209027906346713),\n",
       " ('geography', 0.020717966222541007),\n",
       " ('therapy', 0.020215995737512066),\n",
       " ('criminology', 0.018981304860549143),\n",
       " ('diabetes', 0.01828139923522191),\n",
       " ('pathways', 0.017711351235234492),\n",
       " ('cell', 0.016672897412689864),\n",
       " ('cancer', 0.013771402929793076),\n",
       " ('physicist', 0.010622217148478514),\n",
       " ('astronomy', 0.009921512456962477),\n",
       " ('neuroscience', 0.00829679545549693),\n",
       " ('infection', 0.006669330285796837)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def connectivity_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "    \n",
    "    meta_G = nx.Graph()\n",
    "    w_matrix = {c2:{c1:0 for c1 in communities} for c2 in communities}\n",
    "    for (n1, n2, weight) in G.edges(data='Weight'):\n",
    "        w_matrix[nodes_community[n1]][nodes_community[n2]] += weight\n",
    "\n",
    "    # Add your code here\n",
    "    \n",
    "    for c1 in communities:\n",
    "        for c2 in communities:\n",
    "            if (c1 < c2):\n",
    "                weight = w_matrix[c1][c2] + w_matrix[c2][c1]\n",
    "                meta_G.add_edge(c1, c2, weight=weight)\n",
    "\n",
    "    communities_ranking = nx.pagerank(meta_G)\n",
    "    \n",
    "    # Add your code here\n",
    "    \n",
    "    return communities_ranking\n",
    "\n",
    "connectivity_ranking = connectivity_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(connectivity_ranking.items(), key=lambda x: x[1], reverse=True) if connectivity_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Personalized Community Ranking\n",
    "- Compute, for each community, the **personalized pagerank** of their **influencers**, where the source nodes belong to the community **artificial intelligence**.\n",
    "- Hint: Useful function: `nx.pagerank()`; `personalization` parameter defines the probability of random jumping to a source node.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artificial intelligence', 0.011076392257409935),\n",
       " ('computer science', 0.005304729258854428),\n",
       " ('drones', 0.002652884097355944),\n",
       " ('psychology', 0.00038444405302006843),\n",
       " ('innovation', 1.8889741877389747e-06),\n",
       " ('physicist', 1.7810328800477428e-06),\n",
       " ('physics', 1.5584037860454496e-06),\n",
       " ('architecture', 1.0389358574629546e-06),\n",
       " ('pathways', 1.0389358574629546e-06),\n",
       " ('economics', 1.0389358574629546e-06),\n",
       " ('climate change', 1.0389358574629546e-06),\n",
       " ('astronomy', 1.0389358574629546e-06),\n",
       " ('medicine', 1.0389358574629546e-06),\n",
       " ('biological', 1.0389358574629546e-06),\n",
       " ('chemistry', 1.0389358574629546e-06),\n",
       " ('geography', 1.0389358574629546e-06),\n",
       " ('entrepreneurship', 1.0389358574629546e-06),\n",
       " ('patients', 1.0389358574629546e-06),\n",
       " ('neuroscience', 1.0389358574629546e-06),\n",
       " ('cancer', 1.0389358574629546e-06),\n",
       " ('therapy', 1.0389358574629546e-06),\n",
       " ('cyber security', 1.0389358574629546e-06),\n",
       " ('diabetes', 1.0389358574629546e-06),\n",
       " ('robotics', 1.0389358574629546e-06),\n",
       " ('infection', 1.038935857462954e-06),\n",
       " ('cell', 1.0389358574629538e-06),\n",
       " ('healthcare', 1.0389358574629533e-06),\n",
       " ('sustainability', 1.0389358574629533e-06),\n",
       " ('social media', 1.038935857462952e-06),\n",
       " ('criminology', 8.31148686598775e-07)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def personalized_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "    influencers = community_influencers(G, nodes_community, communities, communities_count)\n",
    "\n",
    "    # Add your code here\n",
    "    \n",
    "    def personalization(nodes_community, community):\n",
    "        count = list(nodes_community.values()).count(community)\n",
    "        return {n:1/count if nodes_community[n] == community else 0 for n in nodes_community.keys()}\n",
    "\n",
    "    personalization = personalization(nodes_community, 'artificial intelligence')\n",
    "    for c in communities:\n",
    "        ppr = nx.pagerank(G, personalization=personalization)\n",
    "        communities_ranking[c] = ppr[influencers[c]]\n",
    "\n",
    "    # Add your code here\n",
    "\n",
    "    return communities_ranking\n",
    " \n",
    "personalized_ranking = personalized_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(personalized_ranking.items(), key=lambda x: x[1], reverse=True) if personalized_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 TF-IDF Community Ranking\n",
    "- Treat each community as a document.\n",
    "- Treat **artificial intelligence** as a query.\n",
    "- Rank the documents (communities) based on their similarity to the query.\n",
    "- Hint: Useful function: `cosine_similarity()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('artificial intelligence', 0.7068180786730306),\n",
       " ('computer science', 0.1363312004264351),\n",
       " ('drones', 0.0736540162872044),\n",
       " ('diabetes', 0.039546236270366075),\n",
       " ('psychology', 0.026595405327496296),\n",
       " ('physics', 0.025330985903952923),\n",
       " ('entrepreneurship', 0.024021069069528018),\n",
       " ('innovation', 0.023216563644012467),\n",
       " ('chemistry', 0.017660462096875655),\n",
       " ('architecture', 0.015594934503474007),\n",
       " ('cell', 0.00959421139643584),\n",
       " ('climate change', 0.009562666055153999),\n",
       " ('social media', 0.0008954193092398574),\n",
       " ('healthcare', 0.0),\n",
       " ('pathways', 0.0),\n",
       " ('sustainability', 0.0),\n",
       " ('economics', 0.0),\n",
       " ('astronomy', 0.0),\n",
       " ('medicine', 0.0),\n",
       " ('criminology', 0.0),\n",
       " ('biological', 0.0),\n",
       " ('geography', 0.0),\n",
       " ('patients', 0.0),\n",
       " ('infection', 0.0),\n",
       " ('neuroscience', 0.0),\n",
       " ('cancer', 0.0),\n",
       " ('therapy', 0.0),\n",
       " ('physicist', 0.0),\n",
       " ('cyber security', 0.0),\n",
       " ('robotics', 0.0)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tfidf_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = default_ranking.copy()\n",
    "\n",
    "    documents = [''] * communities_count\n",
    "    query = ['artificial inteligence']\n",
    "    \n",
    "    for n in nodes_community:\n",
    "        labels = ''.join([str(e[2]['Label'] + ' ')*e[2]['Weight'] for e in G.edges(n, data=True)])\n",
    "        documents[communities.index(nodes_community[n])] += labels\n",
    "\n",
    "    # Add your code here\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    D = vectorizer.fit_transform(documents)\n",
    "    Q = vectorizer.transform(query)\n",
    "    \n",
    "    sim = cosine_similarity(D, Q)\n",
    "    for i, c in enumerate(communities):\n",
    "        communities_ranking[c] = sim[i][0]\n",
    "\n",
    "    # Add your code here\n",
    "    \n",
    "    return communities_ranking\n",
    "\n",
    "tfidf_ranking = tfidf_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(tfidf_ranking.items(), key=lambda x: x[1], reverse=True) if tfidf_ranking != default_ranking else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.7 Rankings Correlation\n",
    "- Consider `personalized_ranking`, `tfidf_ranking` and `AVG(connectivity_ranking, tfidf_ranking)`.\n",
    "- Compute the `3x3` correlation matrix.\n",
    "- Discuss which rankings correlate more and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.95496264, 0.9381539 ],\n",
       "       [0.95496264, 1.        , 0.9894849 ],\n",
       "       [0.9381539 , 0.9894849 , 1.        ]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def compute_correlation(connectivity_ranking, personalized_ranking, tfidf_ranking):    \n",
    "    correlation = np.zeros([3,3])\n",
    "    \n",
    "    connectivity_ranking = [r[1] for r in sorted(connectivity_ranking.items(), key=lambda x: x[0])]\n",
    "    personalized_ranking = [r[1] for r in sorted(personalized_ranking.items(), key=lambda x: x[0])]\n",
    "    tfidf_ranking = [r[1] for r in sorted(tfidf_ranking.items(), key=lambda x: x[0])]\n",
    "    avg_connectivity_tfidf_ranking = [sum(x)/2 for x in zip(connectivity_ranking, tfidf_ranking)]\n",
    "    \n",
    "    # Add your code here    \n",
    "    \n",
    "    correlation = np.corrcoef(np.array([personalized_ranking, tfidf_ranking, avg_connectivity_tfidf_ranking]))\n",
    "    \n",
    "    # Add your code here    \n",
    "\n",
    "    return correlation\n",
    "\n",
    "compute_correlation(connectivity_ranking, personalized_ranking, tfidf_ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***ANSWER:***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a profile-based recommendation ranking for a user?\n",
    "- Consider the user with the label **artificial intelligence**.\n",
    "- Recommend users that have similar labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('CyclingSurgeon', 0.7071067811865476),\n",
       " ('ManiraAhmad', 0.7071067811865476),\n",
       " ('DigiCatapult', 0.7071067811865476),\n",
       " ('StuffandStories', 0.7071067811865476),\n",
       " ('victoria_holt', 0.7071067811865476)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def profile_based_recommendation(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: users_ranking:{user_id:ranking}\n",
    "\n",
    "    '''\n",
    "    users_ranking = {n:0.0 for n in nodes_community.keys()}\n",
    "\n",
    "    # Add your code here\n",
    "    \n",
    "    documents = [''] * len(users_ranking)\n",
    "    query = ['artificial inteligence']\n",
    "    \n",
    "    for i, n in enumerate(nodes_community):\n",
    "        labels = ''.join([str(e[2]['Label'] + ' ')*e[2]['Weight'] for e in G.edges(n, data=True)])\n",
    "        documents[i] += labels\n",
    "\n",
    "    vectorizer = TfidfVectorizer()\n",
    "    D = vectorizer.fit_transform(documents)\n",
    "    Q = vectorizer.transform(query)\n",
    "    \n",
    "    sim = cosine_similarity(D, Q)\n",
    "    for i, n in enumerate(users_ranking.keys()):\n",
    "        users_ranking[n] = sim[i][0]\n",
    "    \n",
    "    # Add your code here\n",
    "    \n",
    "    return users_ranking\n",
    " \n",
    "profile_based_recommendation = profile_based_recommendation(G, nodes_community, communities, communities_count)\n",
    "sorted(profile_based_recommendation.items(), key=lambda x: x[1], reverse=True)[:5] if profile_based_recommendation != {n:0.0 for n in nodes_community.keys()} else None # prints sorted results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the ranking of the communities based on the importance of their nodes?\n",
    "- Compute a node-importance metric on the full graph. \n",
    "- Compute, for each community, the average of its nodes' importance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('computer science', 0.001074198483014965),\n",
       " ('chemistry', 0.0007865879573917386),\n",
       " ('drones', 0.0007752379929126834),\n",
       " ('physicist', 0.0007371595247005386),\n",
       " ('pathways', 0.0007265159950794386),\n",
       " ('criminology', 0.0007248280212682204),\n",
       " ('cell', 0.000724781302183321),\n",
       " ('architecture', 0.0007096220351582247),\n",
       " ('patients', 0.000704826493460207),\n",
       " ('innovation', 0.0007036868991029613)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def node_importance_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = {c:0.0 for c in communities}\n",
    "\n",
    "    # Add your code here\n",
    "    pr = nx.pagerank(G)\n",
    "    for n in pr:\n",
    "        communities_ranking[nodes_community[n]] += pr[n]\n",
    "\n",
    "    for c in communities:\n",
    "        communities_ranking[c] /= list(nodes_community.values()).count(c)\n",
    "    \n",
    "    return communities_ranking\n",
    "\n",
    "ranking = node_importance_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(ranking.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the ranking of the communities based on their intra-connectivity?\n",
    "- Compute, for each community, the ratio of its actual edges to the edges of a clique with the same number of nodes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('physicist', 0.19444444444444445),\n",
       " ('computer science', 0.14285714285714285),\n",
       " ('drones', 0.09090909090909091),\n",
       " ('infection', 0.0784313725490196),\n",
       " ('astronomy', 0.06666666666666667),\n",
       " ('neuroscience', 0.06666666666666667),\n",
       " ('diabetes', 0.0641025641025641),\n",
       " ('criminology', 0.058823529411764705),\n",
       " ('pathways', 0.058333333333333334),\n",
       " ('chemistry', 0.05263157894736842)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def intra_connectivity_ranking(G, nodes_community, communities, communities_count):\n",
    "    ''' input: G:nx.Graph \n",
    "               nodes_community:{node_id:community_id}\n",
    "               communities:[community_ids]\n",
    "               community_count:int\n",
    "       output: communities_ranking:{community_id:ranking}\n",
    "\n",
    "    '''\n",
    "    communities_ranking = {c:0.0 for c in communities}\n",
    "    \n",
    "    # Add your code here\n",
    "    for c in communities:\n",
    "        nodes = [n for n in G.nodes if nodes_community[n]==c]\n",
    "        graph = G.subgraph(nodes)\n",
    "        if len(nodes) > 1:\n",
    "            communities_ranking[c] = len(graph.edges()) / (len(graph.nodes()) * (len(graph.nodes())-1) / 2)\n",
    "        else:\n",
    "            communities_ranking[c] = 0.0\n",
    "    \n",
    "    return communities_ranking\n",
    "\n",
    "ranking = intra_connectivity_ranking(G, nodes_community, communities, communities_count)\n",
    "sorted(ranking.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/duong/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /Users/duong/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Required libraries.\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "import math\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "from nltk.tokenize import word_tokenize, TweetTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "import nltk\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    documents = []\n",
    "    orig_docs = []\n",
    "    DIR = './'\n",
    "    tknzr = TweetTokenizer()\n",
    "    with open(\"epfldocs.txt\", encoding = \"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for text in content:\n",
    "        orig_docs.append(text)\n",
    "        # split into words\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        documents.append(' '.join(words))\n",
    "    return documents, orig_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "documents, orig_docs = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1075"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 1: Latent semantic indexing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.1: Build the vocabulary by selecting top-k frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_vocabulary_frequency(corpus, vocab_len):\n",
    "    '''Select top-k (k = vocab_len) words in term of frequencies as vocabulary'''\n",
    "    \n",
    "    count = {}\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "            if word in count:\n",
    "                count[word] += 1\n",
    "            else:\n",
    "                count[word] = 1\n",
    "    \n",
    "    sorted_count_by_freq = sorted(count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    vocabulary = [x[0] for x in sorted_count_by_freq[:vocab_len]]\n",
    "    return vocabulary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "vocab_freq = create_vocabulary_frequency(documents, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['epfl',\n",
       " 'epflen',\n",
       " 'via',\n",
       " 'les',\n",
       " 'new',\n",
       " 'lausanne',\n",
       " 'switzerland',\n",
       " 'vdtech',\n",
       " 'research',\n",
       " 'swiss',\n",
       " 'science',\n",
       " 'students',\n",
       " 'innovation',\n",
       " 'first',\n",
       " 'martinvetterli',\n",
       " 'day',\n",
       " 'solar',\n",
       " 'great',\n",
       " 'open',\n",
       " 'unil',\n",
       " 'data',\n",
       " 'technology',\n",
       " 'learning',\n",
       " 'thanks',\n",
       " 'ethen',\n",
       " 'work',\n",
       " 'prof',\n",
       " 'today',\n",
       " 'startup',\n",
       " 'talk',\n",
       " 'see',\n",
       " 'days',\n",
       " 'next',\n",
       " 'congrats',\n",
       " 'one',\n",
       " 'good',\n",
       " 'suisse',\n",
       " 'researchers',\n",
       " 'campus',\n",
       " 'center',\n",
       " 'time',\n",
       " 'eth',\n",
       " 'energy',\n",
       " 'robots',\n",
       " 'join',\n",
       " 'us',\n",
       " 'epflcampus',\n",
       " 'cc',\n",
       " 'made',\n",
       " 'lab',\n",
       " 'dgtswitzerland',\n",
       " 'world',\n",
       " 'brain',\n",
       " 'robot',\n",
       " 'looking',\n",
       " 'meeting',\n",
       " 'people',\n",
       " 'drone',\n",
       " 'get',\n",
       " 'future',\n",
       " 'human',\n",
       " 'mooc',\n",
       " 'perovskite',\n",
       " 'could',\n",
       " 'epflenac',\n",
       " 'free',\n",
       " 'robotics',\n",
       " 'event',\n",
       " 'marcelsalathe',\n",
       " 'conference',\n",
       " 'proud',\n",
       " 'light',\n",
       " 'workshop',\n",
       " 'forward',\n",
       " 'week',\n",
       " 'school',\n",
       " 'der',\n",
       " 'president',\n",
       " 'universities',\n",
       " 'design',\n",
       " 'read',\n",
       " 'im',\n",
       " 'university',\n",
       " 'scientists',\n",
       " 'watch',\n",
       " 'cours',\n",
       " 'team',\n",
       " 'article',\n",
       " 'last',\n",
       " 'top',\n",
       " 'take',\n",
       " 'exciting',\n",
       " 'machine',\n",
       " 'best',\n",
       " 'start',\n",
       " 'excited',\n",
       " 'tomorrow',\n",
       " 'even',\n",
       " 'international',\n",
       " 'find',\n",
       " 'machinelearning',\n",
       " 'tech',\n",
       " 'epflevents',\n",
       " 'place',\n",
       " 'merci',\n",
       " 'working',\n",
       " 'oscience',\n",
       " 'f√ºr',\n",
       " 'cells',\n",
       " 'w',\n",
       " 'come',\n",
       " 'digital',\n",
       " 'award',\n",
       " 'datascience',\n",
       " 'part',\n",
       " 'architecture',\n",
       " 'paper',\n",
       " 'available',\n",
       " '√©tudiants',\n",
       " 'video',\n",
       " 'years',\n",
       " 'und',\n",
       " 'congratulations',\n",
       " 'latest',\n",
       " 'cancer',\n",
       " 'projet',\n",
       " 'possible',\n",
       " 'two',\n",
       " 'mars',\n",
       " 'also',\n",
       " 'appliedmldays',\n",
       " 'smart',\n",
       " 'unigenews',\n",
       " 'quantum',\n",
       " 'drones',\n",
       " 'von',\n",
       " 'participants',\n",
       " 'really',\n",
       " 'help',\n",
       " 'professor',\n",
       " 'walk',\n",
       " 'happy',\n",
       " 'water',\n",
       " 'meet',\n",
       " 'swisscytometry',\n",
       " 'way',\n",
       " 'system',\n",
       " 'many',\n",
       " 'says',\n",
       " 'education',\n",
       " 'jacques',\n",
       " 'using',\n",
       " 'understand',\n",
       " 'zu',\n",
       " 'go',\n",
       " 'opportunity',\n",
       " 'activity',\n",
       " 'conf√©rence',\n",
       " 'youtube',\n",
       " 'bien',\n",
       " 'global',\n",
       " 'study',\n",
       " 'show',\n",
       " 'formation',\n",
       " 'trust',\n",
       " 'nice',\n",
       " 'group',\n",
       " 'lecture',\n",
       " 'applied',\n",
       " 'ml',\n",
       " 'cseminfo',\n",
       " 'faire',\n",
       " 'fa√ßade',\n",
       " 'programme',\n",
       " 'program',\n",
       " 'think',\n",
       " 'need',\n",
       " 'artificial',\n",
       " 'engineering',\n",
       " 'like',\n",
       " 'unifr',\n",
       " 'cool',\n",
       " 'tool',\n",
       " 'want',\n",
       " 'vr',\n",
       " 'director',\n",
       " 'zurich',\n",
       " 'public',\n",
       " 'developed',\n",
       " 'topic',\n",
       " 'space',\n",
       " 'eucommission',\n",
       " 'impact',\n",
       " 'french',\n",
       " 'largest',\n",
       " 'clean',\n",
       " 'presenting',\n",
       " '√©tudiant',\n",
       " 'cest',\n",
       " 'night',\n",
       " 'apply',\n",
       " 'startups',\n",
       " 'look',\n",
       " 'sdscdatascience',\n",
       " 'internet',\n",
       " 'year',\n",
       " 'cell',\n",
       " 'virtual',\n",
       " 'mieux',\n",
       " 'improve',\n",
       " 'rolex',\n",
       " 'comment',\n",
       " 'epflpark',\n",
       " 'deadline',\n",
       " 'recherche',\n",
       " 'fantastic',\n",
       " 'guide',\n",
       " 'aihealth',\n",
       " 'march',\n",
       " 'sv',\n",
       " 'disease',\n",
       " 'epflsv',\n",
       " 'phd',\n",
       " 'biology',\n",
       " 'development',\n",
       " 'house',\n",
       " 'dubochet',\n",
       " 'france',\n",
       " 'launch',\n",
       " 'less',\n",
       " 'discussion',\n",
       " 'potential',\n",
       " 'interview',\n",
       " 'plus',\n",
       " 'make',\n",
       " 'openscience',\n",
       " 'online',\n",
       " 'edtech',\n",
       " 'rolexlearningcenter',\n",
       " 'access',\n",
       " 'dark',\n",
       " 'venturelabch',\n",
       " 'library',\n",
       " 'dont',\n",
       " 'register',\n",
       " 'lead',\n",
       " 'neige',\n",
       " 'copenhagen',\n",
       " 'green',\n",
       " 'novel',\n",
       " 'das',\n",
       " 'weekend',\n",
       " 'single',\n",
       " 'noir',\n",
       " 'ever',\n",
       " 'master',\n",
       " 'num√©rique',\n",
       " 'learn',\n",
       " 'real',\n",
       " 'gen√®ve',\n",
       " 'robotic',\n",
       " 'young',\n",
       " 'model',\n",
       " 'dun',\n",
       " 'chuvlausanne',\n",
       " 'apr√®s',\n",
       " 'based',\n",
       " 'present',\n",
       " 'airbnb',\n",
       " '√ßa',\n",
       " 'experience',\n",
       " 'competition',\n",
       " 'efficiency',\n",
       " 'thesis',\n",
       " 'high',\n",
       " 'blue',\n",
       " 'business',\n",
       " 'funding',\n",
       " 'hesso',\n",
       " 'jai',\n",
       " 'brjsa',\n",
       " 'centre',\n",
       " 'nouveau',\n",
       " 'thymioii',\n",
       " 'would',\n",
       " 'agepoly',\n",
       " 'million',\n",
       " 'inside',\n",
       " 'sciences',\n",
       " 'final',\n",
       " 'materials',\n",
       " 'deeplearning',\n",
       " 'nobelprize',\n",
       " 'winner',\n",
       " 'valais',\n",
       " 'film',\n",
       " 'nature',\n",
       " 'uzhnews',\n",
       " 'sxswiss',\n",
       " 'federal',\n",
       " 'institutes',\n",
       " 'welcome',\n",
       " 'forumepfl',\n",
       " 'support',\n",
       " 'zotero',\n",
       " 'intelligence',\n",
       " 'livre',\n",
       " 'towards',\n",
       " 'society',\n",
       " 'rt',\n",
       " 'offers',\n",
       " 'understanding',\n",
       " 'poster',\n",
       " 'workshops',\n",
       " 'luck',\n",
       " 'neuroscience',\n",
       " 'quality',\n",
       " 'successful',\n",
       " 'cytometry',\n",
       " 'polytechnique',\n",
       " 'systems',\n",
       " 'strong',\n",
       " 'among',\n",
       " 'still',\n",
       " 'security',\n",
       " 'information',\n",
       " 'matter',\n",
       " 'generation',\n",
       " 'apprendre',\n",
       " 'champsnight',\n",
       " 'police',\n",
       " 'love',\n",
       " 'technologies',\n",
       " 'hessovalais',\n",
       " 'stop',\n",
       " 'alzheimers',\n",
       " 'ceremony',\n",
       " 'mission',\n",
       " 'become',\n",
       " 'innovaud',\n",
       " 'sant√©',\n",
       " 'avalanche',\n",
       " 'full',\n",
       " 'snow',\n",
       " 'danish',\n",
       " 'installs',\n",
       " 'food',\n",
       " 'course',\n",
       " 'bigdata',\n",
       " 'level',\n",
       " 'chemistry',\n",
       " 'collaboration',\n",
       " 'frederickaplan',\n",
       " 'die',\n",
       " 'ready',\n",
       " 'colleagues',\n",
       " 'art',\n",
       " 'swissnexsf',\n",
       " 'session',\n",
       " 'tour',\n",
       " 'code',\n",
       " 'analysis',\n",
       " 'leurs',\n",
       " 'thank',\n",
       " 'mobility',\n",
       " 'cybersecurityday',\n",
       " 'impressive',\n",
       " 'well',\n",
       " 'immune',\n",
       " 'excellent',\n",
       " 'back',\n",
       " 'visit',\n",
       " '√©tudes',\n",
       " 'making',\n",
       " 'projets',\n",
       " 'sure',\n",
       " 'applications',\n",
       " 'villes',\n",
       " 'epfllibrary',\n",
       " 'save',\n",
       " 'date',\n",
       " 'site',\n",
       " 'monde',\n",
       " 'reality',\n",
       " 'venture',\n",
       " 'former',\n",
       " 'power',\n",
       " 'market',\n",
       " 'nrel',\n",
       " 'record',\n",
       " 'hackathon',\n",
       " 'sign',\n",
       " 'projects',\n",
       " 'talking',\n",
       " 'old',\n",
       " 'done',\n",
       " 'al',\n",
       " 'develop',\n",
       " 'control',\n",
       " 'openfood',\n",
       " 'uzhnewsen',\n",
       " 'discover',\n",
       " 'edacyhq',\n",
       " 'invest',\n",
       " 'important',\n",
       " 'travail',\n",
       " 'si',\n",
       " 'quand',\n",
       " 'wef',\n",
       " 'attend',\n",
       " 'laboratory',\n",
       " 'fmondada',\n",
       " 'swsx',\n",
       " 'moocs',\n",
       " 'traces',\n",
       " 'martian',\n",
       " 'biological',\n",
       " 'meteorite',\n",
       " 'bravo',\n",
       " 'long',\n",
       " 'geneva',\n",
       " 'takes',\n",
       " 'health',\n",
       " 'life',\n",
       " 'early',\n",
       " 'april',\n",
       " 'main',\n",
       " 'city',\n",
       " 'aujourdhui',\n",
       " 'demain',\n",
       " 'epfls',\n",
       " 'areas',\n",
       " 'vaud',\n",
       " 'mechanics',\n",
       " 'wave',\n",
       " 'particle',\n",
       " 'lepfl',\n",
       " 'sich',\n",
       " 'chf',\n",
       " 'interaction',\n",
       " 'highlights',\n",
       " 'student',\n",
       " 'rlerignier',\n",
       " 'norme',\n",
       " 'tous',\n",
       " 'indeed',\n",
       " 'tumuenchen',\n",
       " 'hand',\n",
       " 'tuned',\n",
       " 'speakers',\n",
       " 'deep',\n",
       " 'psf',\n",
       " 'algorithms',\n",
       " 'digitalhealth',\n",
       " 'exposition',\n",
       " 'play',\n",
       " 'spinoff',\n",
       " 'know',\n",
       " 'rrl',\n",
       " 'dr',\n",
       " 'michael',\n",
       " 'panel',\n",
       " 'point',\n",
       " 'solutions',\n",
       " 'without',\n",
       " 'nanostructures',\n",
       " 'use',\n",
       " 'timeshighered',\n",
       " 'opportunities',\n",
       " 'inspired',\n",
       " 'wikipedia',\n",
       " 'studies',\n",
       " 'danger',\n",
       " 'slf',\n",
       " 'innovative',\n",
       " 'challenge',\n",
       " 'ia',\n",
       " 'eawagresearch',\n",
       " 'bibliotheque',\n",
       " 'tr√®s',\n",
       " 'aging',\n",
       " 'mit',\n",
       " 'alumni',\n",
       " 'unigeen',\n",
       " 'stem',\n",
       " 'much',\n",
       " 'sneedition',\n",
       " 'iso',\n",
       " 'february',\n",
       " 'cern',\n",
       " 'eurekalert',\n",
       " 'music',\n",
       " 'call',\n",
       " 'starts',\n",
       " 'intel',\n",
       " 'lets',\n",
       " 'privacy',\n",
       " 'lieu',\n",
       " 'info',\n",
       " 'page',\n",
       " 'fish',\n",
       " 'optical',\n",
       " 'may',\n",
       " 'amazing',\n",
       " 'europe',\n",
       " 'prize',\n",
       " 'bacterial',\n",
       " 'around',\n",
       " 'social',\n",
       " 'nberpubs',\n",
       " 'letemps',\n",
       " 'check',\n",
       " 'lesoepfl',\n",
       " 'club',\n",
       " 'scicomm',\n",
       " 'entre',\n",
       " 'happening',\n",
       " 'give',\n",
       " 'software',\n",
       " 'big',\n",
       " 'building',\n",
       " 'going',\n",
       " 'modeling',\n",
       " 'method',\n",
       " 'cet',\n",
       " 'january',\n",
       " 'soft',\n",
       " 'lake',\n",
       " 'dna',\n",
       " 'nccrrobotics',\n",
       " 'premier',\n",
       " 'network',\n",
       " 'achieve',\n",
       " 'sustainability',\n",
       " 'exosquelette',\n",
       " 'created',\n",
       " 'published',\n",
       " 'swisstechepfl',\n",
       " 'tonight',\n",
       " 'host',\n",
       " 'book',\n",
       " 'question',\n",
       " 'nexus',\n",
       " 'opensource',\n",
       " 'datadriven',\n",
       " 'girls',\n",
       " 'wslresearch',\n",
       " 'entrepreneurship',\n",
       " 'jobs',\n",
       " 'ask',\n",
       " 'speaking',\n",
       " 'silicon',\n",
       " 'prix',\n",
       " 'heart',\n",
       " 'epflartlab',\n",
       " 'man',\n",
       " 'opendata',\n",
       " 'computer',\n",
       " 'edacy',\n",
       " 'digitaltrust',\n",
       " 'ethrat',\n",
       " 'atelier',\n",
       " 'etc',\n",
       " 'ligne',\n",
       " 'keep',\n",
       " 'hosted',\n",
       " 'live',\n",
       " 'engineers',\n",
       " 'interesting',\n",
       " 'blockchain',\n",
       " 'fintech',\n",
       " 'robotique',\n",
       " 'humans',\n",
       " 'media',\n",
       " 'experts',\n",
       " 'mind',\n",
       " 'institute',\n",
       " 'symposium',\n",
       " 'summer',\n",
       " 'complexes',\n",
       " 'computational',\n",
       " 'presents',\n",
       " 'plenty',\n",
       " 'presented',\n",
       " 'missing',\n",
       " 'mobile',\n",
       " 'window',\n",
       " 'monitoring',\n",
       " 'process',\n",
       " 'd√©but',\n",
       " 'septembre',\n",
       " 'ein',\n",
       " 'effyvayena',\n",
       " 'sxsw',\n",
       " 'aussi',\n",
       " 'solaire',\n",
       " 'thing',\n",
       " 'another',\n",
       " 'else',\n",
       " 'offer',\n",
       " 'pratique',\n",
       " 'csl',\n",
       " 'enjeux',\n",
       " 'artificielle',\n",
       " 'iot',\n",
       " 'd√©couvrez',\n",
       " 'industrial',\n",
       " 'davos',\n",
       " 'interactions',\n",
       " 'transportation',\n",
       " 'alahi',\n",
       " 'travers',\n",
       " 'sans',\n",
       " 'policy',\n",
       " 'according',\n",
       " 'tueindhoven',\n",
       " 'used',\n",
       " 'naturecomms',\n",
       " 'super',\n",
       " 'stay',\n",
       " 'violainesee',\n",
       " 'cciliv',\n",
       " 'images',\n",
       " 'test',\n",
       " 's√©curit√©',\n",
       " 'able',\n",
       " 'medtech',\n",
       " 'p',\n",
       " 'measuring',\n",
       " 'swissedtechcollider',\n",
       " 'line',\n",
       " 'lives',\n",
       " 'mal',\n",
       " 'ecole',\n",
       " 'f√©d√©rale',\n",
       " 'feb',\n",
       " 'operations',\n",
       " 'size',\n",
       " 'virtualreality',\n",
       " 'environments',\n",
       " 'natural',\n",
       " 'bad',\n",
       " 'ist',\n",
       " 'partners',\n",
       " 'yunus',\n",
       " 'makes',\n",
       " 'darker',\n",
       " 'thought',\n",
       " 'darkmatter',\n",
       " 'hubble',\n",
       " 'astronomy',\n",
       " 'presentation',\n",
       " 'hopitauxunige',\n",
       " 'training',\n",
       " 'storage',\n",
       " 'professeur',\n",
       " 'besoin',\n",
       " 'population',\n",
       " 'uefa',\n",
       " 'healthy',\n",
       " 'mitochondria',\n",
       " 'someone',\n",
       " 'concept',\n",
       " 'travel',\n",
       " 'thomas',\n",
       " 'claude',\n",
       " 'nicollier',\n",
       " 'european',\n",
       " 'dsmeu',\n",
       " 'factory',\n",
       " 'masschallengech',\n",
       " 'japan',\n",
       " 'rts',\n",
       " 'envirobot',\n",
       " 'ainsi',\n",
       " 'caution',\n",
       " 'snowscience',\n",
       " 'sensors',\n",
       " 'medicine',\n",
       " 'proteins',\n",
       " 'series',\n",
       " 'waste',\n",
       " 'encore',\n",
       " 'alpine',\n",
       " 'extreme',\n",
       " 'portable',\n",
       " 'artlab',\n",
       " 'pierresoulages',\n",
       " 'points',\n",
       " 'different',\n",
       " 'bci',\n",
       " 'awards',\n",
       " 'champions',\n",
       " 'directeur',\n",
       " 'dune',\n",
       " 'humaines',\n",
       " 'measurements',\n",
       " 'tip',\n",
       " 'imaging',\n",
       " 'espace',\n",
       " 'avant',\n",
       " '√©dition',\n",
       " 'avril',\n",
       " 'comes',\n",
       " 'travaux',\n",
       " 'stanford',\n",
       " 'spy',\n",
       " 'bbc',\n",
       " 'technologisteu',\n",
       " 'dhums',\n",
       " 'carlo',\n",
       " 'sept',\n",
       " 'review',\n",
       " 'sustainable',\n",
       " 'fast',\n",
       " 'espdakar',\n",
       " 'verge',\n",
       " 'datajamdays',\n",
       " 'ar',\n",
       " 'venez',\n",
       " 'patrimoine',\n",
       " 'reportage',\n",
       " 'fran√ßais',\n",
       " 'months',\n",
       " 'techcrunch',\n",
       " 'lereseau',\n",
       " 'try',\n",
       " 'propos√©',\n",
       " 'field',\n",
       " 'oui',\n",
       " 'chimie',\n",
       " 'isbsib',\n",
       " 'thursday',\n",
       " 'inscription',\n",
       " 'temps',\n",
       " 'resistance',\n",
       " 'microscopy',\n",
       " 'startuptickerch',\n",
       " 'discuss',\n",
       " 'artificialintelligence',\n",
       " 'itfaconference',\n",
       " 'v',\n",
       " 'behind',\n",
       " 'approach',\n",
       " 'matin',\n",
       " 'currently',\n",
       " 'wish',\n",
       " '√ºber',\n",
       " 'sharing',\n",
       " 'scala',\n",
       " 'gr√§tzel',\n",
       " 'practical',\n",
       " 'specialist',\n",
       " 'academia',\n",
       " 'three',\n",
       " 'times',\n",
       " 'behavior',\n",
       " 'concours',\n",
       " 'epflmaurice',\n",
       " 'mauricelibrarysecurity',\n",
       " 'additive',\n",
       " 'photograph',\n",
       " 'birthday',\n",
       " 'vusurlecampus',\n",
       " 'active',\n",
       " 'shared',\n",
       " 'abstract',\n",
       " 'submission',\n",
       " 'touch',\n",
       " 'jmlattes',\n",
       " 'regisgodec',\n",
       " 'autatetoulouse',\n",
       " 'type',\n",
       " 'probably',\n",
       " 'harvardmed',\n",
       " 'museomix',\n",
       " 'candidatures',\n",
       " 'winter',\n",
       " 'improves',\n",
       " 'chromatin',\n",
       " 'digitalday',\n",
       " 'programmation',\n",
       " 'classe',\n",
       " 'drivers',\n",
       " 'kickoff',\n",
       " 'pm',\n",
       " 'graphene',\n",
       " 'create',\n",
       " 'truly',\n",
       " 'anton',\n",
       " 'schleiss',\n",
       " 'jours',\n",
       " 'deux',\n",
       " 'promising',\n",
       " 'modular',\n",
       " 'origami',\n",
       " 'ieee',\n",
       " 'received',\n",
       " 'suivre',\n",
       " 'looks',\n",
       " 'awesome',\n",
       " 'places',\n",
       " 'reconstruction',\n",
       " 'juridiques',\n",
       " 'rehabilitation',\n",
       " 'registration',\n",
       " 'built',\n",
       " 'species',\n",
       " 'ones',\n",
       " 'paris',\n",
       " 'set',\n",
       " 'aceexpedition',\n",
       " 'ethz',\n",
       " 'weeks',\n",
       " 'seed',\n",
       " 'industry',\n",
       " 'opening',\n",
       " 'job',\n",
       " 'stratocore',\n",
       " 'geomechaepfl',\n",
       " 'geteschool',\n",
       " 'management',\n",
       " 'cloud',\n",
       " 'lors',\n",
       " 'opticalfiber',\n",
       " 'succ√®s',\n",
       " 'martin',\n",
       " 'vetterli',\n",
       " 'app',\n",
       " 'aus',\n",
       " 'opendatach',\n",
       " 'christmas',\n",
       " 'together',\n",
       " 'featuring',\n",
       " 'value',\n",
       " 'camp',\n",
       " 'bring',\n",
       " 'case',\n",
       " 'skills',\n",
       " 'e',\n",
       " 'swissedtech',\n",
       " 'feedback',\n",
       " 'enhances',\n",
       " 'brainwave',\n",
       " 'handexoskeleton',\n",
       " 'september',\n",
       " 'assist',\n",
       " 'patrick',\n",
       " 'aebischer',\n",
       " 'soir',\n",
       " 'repair',\n",
       " 'tissue',\n",
       " 'pain',\n",
       " 'gamayanews',\n",
       " 'break',\n",
       " 'pump',\n",
       " 'r√©f√©rences',\n",
       " 'filles',\n",
       " 'highway',\n",
       " 'dindin',\n",
       " 'starting',\n",
       " 'unique',\n",
       " 'humanitarian',\n",
       " 'progress',\n",
       " 'getting',\n",
       " 'soon',\n",
       " 'jchenal',\n",
       " 'tdgch',\n",
       " 'focusonline',\n",
       " 'bild',\n",
       " 'regierungbw',\n",
       " 'cdu',\n",
       " 'gruenebundestag',\n",
       " 'thomasoppermann',\n",
       " 'gruenebw',\n",
       " 'europarlen',\n",
       " 'thats',\n",
       " 'pitch',\n",
       " 'news',\n",
       " 'patterns',\n",
       " 'transform',\n",
       " 'furniture',\n",
       " 'kamiahok',\n",
       " 'microsoft',\n",
       " 'bradsmi',\n",
       " 'ebugnion',\n",
       " 'geneve',\n",
       " 'donc',\n",
       " 'cette',\n",
       " 'archives',\n",
       " 'members',\n",
       " 'including',\n",
       " 'scientific',\n",
       " 'reveals',\n",
       " 'aviation',\n",
       " 'zhaw',\n",
       " 'facebook',\n",
       " 'versatile',\n",
       " 'countries',\n",
       " 'cltucci',\n",
       " 'pr√©sentation',\n",
       " 'registered',\n",
       " 'mati√®re',\n",
       " 'stress',\n",
       " 'cyclometalated',\n",
       " 'ruthenium',\n",
       " 'directly',\n",
       " 'leader',\n",
       " 'giving',\n",
       " 'kicking',\n",
       " 'tutorial',\n",
       " 'timeseries',\n",
       " 'identified',\n",
       " 'gene',\n",
       " 'heclausanne',\n",
       " 'trois',\n",
       " '√©tudier',\n",
       " 'observed',\n",
       " 'weather',\n",
       " 'antarctica',\n",
       " 'ict',\n",
       " 'conf',\n",
       " 'platforms',\n",
       " 'capitale',\n",
       " 'kuka',\n",
       " 'setzt',\n",
       " 'trusting',\n",
       " 'asks',\n",
       " 'sait',\n",
       " 'etatdevaud',\n",
       " 'national',\n",
       " 'dynamics',\n",
       " 'mechanisms',\n",
       " 'transformtech',\n",
       " 'imd',\n",
       " 'mrhiura',\n",
       " 'avoid',\n",
       " 'everyone',\n",
       " 'board',\n",
       " 'gender',\n",
       " 'strategy',\n",
       " 'childcare',\n",
       " 'trekkinglemon',\n",
       " 'lextensoetudian',\n",
       " 'fait',\n",
       " 'swisscom',\n",
       " 'd√©fis',\n",
       " 'tout',\n",
       " 'citation',\n",
       " 'produce',\n",
       " 'dtsbourg',\n",
       " 'informed',\n",
       " 'nucleosomes',\n",
       " 'micro',\n",
       " 'histone',\n",
       " 'dynamic',\n",
       " 'jan',\n",
       " 'talks',\n",
       " 'small',\n",
       " 'existing',\n",
       " 'revolutionize',\n",
       " 'lire',\n",
       " 'louvrir',\n",
       " 'secret',\n",
       " 'archimagredac',\n",
       " 'challenges',\n",
       " 'r',\n",
       " 'dtutweet',\n",
       " 'leukemia',\n",
       " 'clearer',\n",
       " 'woop',\n",
       " 'covestrogroup',\n",
       " 'imdeanano',\n",
       " 'ujinoticias',\n",
       " 'imperialcollege',\n",
       " 'irem',\n",
       " 'winning',\n",
       " 'hot',\n",
       " 'geothermal',\n",
       " 'scireports',\n",
       " 'chance',\n",
       " 'deconvolution',\n",
       " 'deconvolutionlab',\n",
       " 'results',\n",
       " 'act',\n",
       " 'selfsufficient',\n",
       " 'home',\n",
       " 'panels',\n",
       " 'solardecathlon',\n",
       " 'advanced',\n",
       " 'ht',\n",
       " 'surface',\n",
       " 'nano',\n",
       " 'ex',\n",
       " 'member',\n",
       " 'discovery',\n",
       " 'century',\n",
       " 'jet',\n",
       " 'lag',\n",
       " 'chiccommunity']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.2: Construct the term document matrix\n",
    "Construct the term document matrix given the vocabulary and the set of documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_term_document_matrix(vocabulary, documents):\n",
    "    # Construct term-doc matrix\n",
    "    matrix = np.zeros((len(vocabulary), len(documents)))\n",
    "    for j, document in enumerate(documents):\n",
    "        counter = Counter(document.split())\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in counter:\n",
    "                matrix[i,j] = counter[word]\n",
    "    return matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_doc_matrix_freq = construct_term_document_matrix(vocab_freq, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.3: Perform latent semantic indexing by selecting the first 100 largest singular values of the term document matrix  \n",
    "Hint 1: np.linalg.svd(M, full_matrices=False) performs SVD on the matrix $\\mathbf{M}$ and returns $\\mathbf{K}, \\mathbf{S}, \\mathbf{D}^T$\n",
    "\n",
    " -  $\\mathbf{K}, \\mathbf{D}^T$ are matrices with orthonormal columns\n",
    " -  $\\mathbf{S}$ is a **vector** of singular values in a **descending** order\n",
    " \n",
    "Hint 2: np.diag(V) converts a vector to a diagonal matrix\n",
    "\n",
    "Hint 3: To select \n",
    " - The first k rows of a matrix A, use A[0:k, :]\n",
    " - The first k columns of a matrix A, use A[:, 0:k]\n",
    " - The submatrix from first k rows and k columns: use A[0:k, 0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def truncated_svd(term_doc_matrix, num_val):\n",
    "    K, S, Dt = np.linalg.svd(term_doc_matrix, full_matrices=False)\n",
    "    K_sel = K[:,0:num_val]\n",
    "    S_sel = np.diag(S)[0:num_val,0:num_val]\n",
    "    Dt_sel = Dt[0:num_val,:]\n",
    "    return K_sel, S_sel, Dt_sel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K_freq, S_freq, Dt_freq = truncated_svd(term_doc_matrix_freq,100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.4: Transform the query "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a vector representation for the following query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = ['epfl']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def query_to_document_vector(query, vocabulary):\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    for word in query:\n",
    "        try:\n",
    "            vector[vocabulary.index(word)] += 1\n",
    "        except: # if query word is not in vocabulary\n",
    "            # ignore it\n",
    "            pass\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: \n",
    " -  To compute inverse of a matrix M, use np.linalg.inv(M)\n",
    " -  To compute the dot product of A, B, use np.dot(A,B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_query_vector(query, vocabulary, K_sel, S_sel):\n",
    "    q = query_to_document_vector(query, vocabulary)\n",
    "    mapper = np.dot(K_sel, np.linalg.inv(S_sel))\n",
    "    q_trans =  np.dot( q, mapper)\n",
    "    return q_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "query_vector_freq = construct_query_vector(query, vocab_freq, K_freq, S_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1.5: Retrieve top-10 relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy*1.0/math.sqrt(sumxx*sumyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve_documents(query_vector, top_k, Dt_sel):\n",
    "    scores = [[cosine_similarity(query_vector, Dt_sel[:,d]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    retrieved = []\n",
    "    for i in range(top_k):\n",
    "        doc_ids.append(scores[i][1])\n",
    "        retrieved.append(orig_docs[scores[i][1]])\n",
    "    return doc_ids, retrieved\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/duong/miniconda3/lib/python3.6/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "retrieved_ids_freq, retrieved_docs_freq = retrieve_documents(query_vector_freq, 10, Dt_freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Environnement, un march√© en pleine croissance https://t.co/ThTcYLrMtn Avec '\n",
      " 'Philippe Thalmann @EPFL\\n',\n",
      " \"Belle le√ßon de technologie dans @RTScqfd avec l'exosquelette \"\n",
      " '@twiice_official test√© par Silke Pan. https://t.co/4uIdXckvaq #RTScqfd '\n",
      " '#EPFL\\n',\n",
      " 'Chocolate &amp; berries #vegan cheesecake for my @EPFL coworkers! ‚úåüèΩüå± '\n",
      " '#veganfood #EPFLfood https://t.co/wPlLsIt0KD\\n',\n",
      " 'sign√© @EPFL https://t.co/sRldB2O7PM\\n',\n",
      " '#ff @Kikohs and his beautiful artworks. Some of them are displayed at @EPFL '\n",
      " 'and featured on ZettaBytes! https://t.co/8F4BNL7aAs\\n',\n",
      " 'Ca court, ca court √† #carandache #epfl #wwim15 #wwim15_igerslausanne '\n",
      " 'https://t.co/0bNMBPx50k\\n',\n",
      " 'Le camion Cargo Congo du @theatredevidy est sur la #PlaceCosandey- ne '\n",
      " 'manquez pas de venir d√©couvrir ce spectacle de 10 mins jusqu‚Äô√† 14h puis √† '\n",
      " '16h @EPFL https://t.co/D2JZztA3Ca\\n',\n",
      " \"Bras de fer autour de la taxe d‚Äô√©tudes de l'#EPFL https://t.co/pr7GBU3f04\\n\",\n",
      " '@nathan_quint You guys rock! @OpendataCH @EPFL\\n',\n",
      " '#Patients coach√©s sur le stand @rts :essayez-vous √† la profession de '\n",
      " '#m√©decin &amp; au #diagnostic ! #pslive2016 #consultation #sant√© #rts #epfl '\n",
      " 'https://t.co/ym6u32Ngfp\\n']\n"
     ]
    }
   ],
   "source": [
    "pprint(retrieved_docs_freq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 2: Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval oracle \n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), vocabulary=vocab_freq, min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(documents)\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.3):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1), \n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "gt_ids = search_vec_sklearn(\" \".join(query), features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@EPFL Retrouvez votre 1er tweet s√©lectionn√© par L'important https://t.co/B2tCt924Cp\n",
      "Environnement, un march√© en pleine croissance https://t.co/ThTcYLrMtn Avec Philippe Thalmann @EPFL\n",
      "Belle le√ßon de technologie dans @RTScqfd avec l'exosquelette @twiice_official test√© par Silke Pan. https://t.co/4uIdXckvaq #RTScqfd #EPFL\n",
      "Chocolate &amp; berries #vegan cheesecake for my @EPFL coworkers! ‚úåüèΩüå± #veganfood #EPFLfood https://t.co/wPlLsIt0KD\n",
      "I see you @EPFL ! https://t.co/BxrHPaMqlX\n",
      "#Walking on two #legs isn‚Äôt as easy as it seems... @EPFL  https://t.co/Af6Shy2CvV https://t.co/ecz2M8Znl4\n",
      "sign√© @EPFL https://t.co/sRldB2O7PM\n",
      "#ff @Kikohs and his beautiful artworks. Some of them are displayed at @EPFL and featured on ZettaBytes! https://t.co/8F4BNL7aAs\n",
      "Ca court, ca court √† #carandache #epfl #wwim15 #wwim15_igerslausanne https://t.co/0bNMBPx50k\n",
      "Le camion Cargo Congo du @theatredevidy est sur la #PlaceCosandey- ne manquez pas de venir d√©couvrir ce spectacle de 10 mins jusqu‚Äô√† 14h puis √† 16h @EPFL https://t.co/D2JZztA3Ca\n",
      "Un Plan de mobilit√© ¬´ Made in EPFL ¬ª https://t.co/efcVQ215Nh #epfl\n",
      "Attention aux emails frauduleux https://t.co/Mjlq4D3RWM #epfl\n",
      "#Melenchon passe 2eme dans l'outils d'analyse des #reseauxsociaux de @SwissquoteNews @EPFL  https://t.co/gQk1H9bPlR #Presidentielle2017 https://t.co/qFNRPQE4t2\n",
      "But what a woman! @samsam_86 #EPFL   https://t.co/hM1ccY2plN\n",
      "L'histoire de l'Acad√©mie racont√©e par #Jean-ClaudeBadoux, seul pr√©sident romand de la SATW jusqu'√† pr√©sent: https://t.co/yRkOycBSle @EPFL https://t.co/ZZXZHasdjN\n",
      "Que reste-t-il de l πesprit des squats des ann√©es 1980?  https://t.co/m80VlQSkfQ Avec Luca Pattaroni @EPFL\n",
      "EPFL morning #epfl #lausanne #photography https://t.co/6IXddicblu\n",
      "PostCarWorld | EPFL https://t.co/KfFQRJrQVb #epfl #epflcampus\n",
      "Bluebrain | EPFL https://t.co/Y2S3hz1817 #epfl #epflcampus\n",
      "L'app pour ¬´liker¬ª en direct les transports publics https://t.co/3HbkTnIE3Q #epfl\n",
      "L'√©lectrochimie d√©busque les prot√©ines r√©sistantes aux antibiotiques https://t.co/BHlj5WHMbC Avec Hubert Girault @EPFL\n",
      "Femmes en politique, pour en finir avec les seconds r√¥les https://t.co/IgIkg8yrxy #epfl\n",
      "Des #microchips optimisent les ¬´codes polaires¬ª essentiels √† la #5G https://t.co/FS7tDPBFsP @epfl\n",
      "Des nichoirs digitaux pour observer les chouettes https://t.co/iPc3bFDrsL Avec Marion Curdy @EPFL\n",
      "Les #GAFA sont-ils devenus trop puissants? https://t.co/9F9q98oXPE Avec Charles Wyplosz @IHEID et Denis Gillet @EPFL\n",
      "Six EPFL startups are among the Swiss top 10 https://t.co/Re0xB2VBZ0 #epfl\n",
      "EPFL students get hands-on experience with ‚ÄúMade in China‚Äù https://t.co/DKgMXia7tQ #epfl\n",
      "Spaceship #epfl #lausanne https://t.co/Lb223yT804\n",
      "Waiting for the ceremony to start! #epflalumnigala #epfl  @epfl https://t.co/ucZjZmNfYF\n",
      "Deprivation: a decisive factor in genetic predisposition to #obesity a study @EPFL @CHUVLausanne https://t.co/epvU8vlA0c #epfl #publichealth https://t.co/jW8sWVTLTQ\n",
      "Nicolas Mounet from EPFL @EPFL talking about two-dimensional materials and high-throughput calculations at #MaXConf2018 in Trieste @aiidateam @nccr_marvel https://t.co/qGyOt0yVZn\n",
      "Drone Days | EPFL https://t.co/ZdNwhb0EzL #epfl #epflcampus\n",
      "Le myst√®re Soulages √©blouit la science @EPFL  https://t.co/u3uNICyAdi\n",
      "Functional programming in @scala_lang @epfl first day https://t.co/HTryOqhYq7\n"
     ]
    }
   ],
   "source": [
    "for i in gt_ids:\n",
    "    print(orig_docs[i].strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2.1: Compute F1-score at 10 between oracle and the above result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_recall_at_k(predict, gt, k):\n",
    "    correct_recall = set(predict[:k]).intersection(set(gt))\n",
    "    return len(correct_recall)/len(gt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(predict, gt, k):\n",
    "    correct_predict = set(predict[:k]).intersection(set(gt))\n",
    "    return len(correct_predict)/k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def f1score(predict, gt, k):\n",
    "    prec = compute_precision_at_k(predict, gt, k)\n",
    "    rec = compute_recall_at_k(predict, gt, k)\n",
    "    print(prec, rec)\n",
    "    return 2*prec*rec/(prec+rec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7 0.20588235294117646\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.3181818181818182"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1score(retrieved_ids_freq, gt_ids, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Question 3: Plot the terms using two principal concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.1: Compute term vectors using two principal concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_vecs_freq, _, _ = truncated_svd(term_doc_matrix_freq,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 2)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "term_vecs_freq.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the term vectors using two principal concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from pylab import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hint: You can use plt.scatter(x, y) for a scatter plot. x is a vector of x-axis value and y is a vector of y-axis value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(term_vecs_freq[:, 0], term_vecs_freq[:, 1])\n",
    "for i, t in enumerate(vocab_freq):\n",
    "    plt.annotate(t, (term_vecs_freq[i, 0], term_vecs_freq[i, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3.2: Explain the scatter plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "epfl and epflen are two Twitter handles of EPFL which explains why the two principal concepts are mainly made up of these terms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "\n",
    "***Final Exam, Fall Semester, 2021***\n",
    "\n",
    "The exam will be held on your computer, but digital communication with other persons by any means is **strictly prohibited**.\n",
    "The following materials are also allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation. You may also use Stackoverflow and Python documentation for questions related to Python programming.\n",
    "By participating in this exam you **agree to these conditions**.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "\n",
    "- You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "- The quiz will remain open **only for the first 2 hours** of the exam to avoid network congestion.\n",
    "- **30 minutes** before the end of the exam we will announce a password to upload your jupyter notebook on **Moodle**.\n",
    "- It is not recommended to leave the exam before the password is published. If you need to leave earlier, contact us.\n",
    "- **You must follow the EPFL guidelines and wear your mask when you enter, leave, and move around the exam room.**\n",
    "- **You have to wear the bracelet for COVID certification at all times.**\n",
    "- **We would also like to kindly ask you to wear your mask when you ask questions and when we check your camipro card.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0 Rename your Notebook\n",
    "Replace SciperNo with your **personal SCIPER Number**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1 [Multiple Choice Questions]()\n",
    "**Password**: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2 Theory Question\n",
    "\n",
    "*(5 sub-questions)*"
   ]
  },
  {
   "attachments": {
    "graph.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![graph.png](attachment:graph.png)\n",
    "\n",
    "Answer the questions regarding the graph above. You can do the computations either by hand or by using computer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **1. You are going to run Pagerank on this graph. What is the link matrix? What does it become after normalizing by the node degrees? (Please explicitly state what do the rows and the columns indicate.)**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2. Run Pagerank without teleporting for two iterations. What are the final pagerank scores and the ranking? Show your work. You can assume all pages initially have a pagerank score of 1. Hint: Do not forget to normalize pagerank scores so that they will add up to 1 after each iteration.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3. Suppose that the edge (E, C) did not exist. What would be the final ranking?** "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **4. Run Personalized Pagerank with teleporting probability of 1/5. Random jumps are always to node A. Iterate only once. What are the final scores and the ranking?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **5. Imagine a new node is connected to the network by a single edge directed to A. How this would affect the result of 2 and 4?**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 News recommendation\n",
    "\n",
    "You will create news recommendations for the small news portal aggregator, \"*allabouthealthcare.com*\", regarding news about healthcare. In this website users can read various news articles regarding healthcare collected from popular healthcare media. \n",
    "\n",
    "The developers of the website collect analytics regarding which user has read what article. You are hired to create a recommendation engine that will provide news recommendations to users.\n",
    "\n",
    "You will first explore the dataset by providing dataset descriptive statistics, and then you will implement various methods for news recommendation.\n",
    "\n",
    "#### DATASET\n",
    "You are given two files regarding the news articles consumption of this news portal. \n",
    "\n",
    "> 1. **News articles** (*news_articles.txt*): \n",
    ">\n",
    "> This dataset contains information about the news articles collected by the portal.\n",
    "> The information stored for each article is the following:\n",
    ">\n",
    "> - **article id**: The id of the article.\n",
    "> - **title**: The title of the article.\n",
    "- **medium**: The news portal the the article was originally published.\n",
    "- **publish date**: The date of publication of the article.\n",
    "- **authors**: The names and surnames of authors seperated with comma.\n",
    "- **corpus**: The main text of the article without any identation.\n",
    "- **url**: The url of the article.\n",
    "\n",
    "> 2. **User log** (*user_log.txt*)\n",
    ">\n",
    "> This dataset contains the user log of *allabouthealthcare.com*. \n",
    "> The information stored for each row is the following:\n",
    ">\n",
    "> - **user id**: The id of the user.\n",
    "- **article id**: The id of the article the user read.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Understanding the dataset\n",
    "*(5 sub-questions)*\n",
    "\n",
    "You need to compute the following descriptive statistics for the aforementioned dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# read the dataset\n",
    "articles = pd.read_csv('data/news_articles.txt', sep='|').fillna('')\n",
    "log = pd.read_csv('data/user_log.txt', sep='|')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>medium</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>corpus</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>how address inequity healthcare ai hire divers...</td>\n",
       "      <td>www.healthcareitnews.com</td>\n",
       "      <td>2022-01-13T09:05:39-05:00</td>\n",
       "      <td>Kat Jercich</td>\n",
       "      <td>even artificial intelligence become thoroughly...</td>\n",
       "      <td>https://www.healthcareitnews.com/news/how-addr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>cyberattack red cross endangers confidential i...</td>\n",
       "      <td>www.healthcareitnews.com</td>\n",
       "      <td>2022-01-21T12:06:48-05:00</td>\n",
       "      <td>Kat Jercich</td>\n",
       "      <td>the red cross reported week cyberattack contra...</td>\n",
       "      <td>https://www.healthcareitnews.com/news/cyber-at...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>like banks healthcare become zoom healthcare l...</td>\n",
       "      <td>www.healthcareitnews.com</td>\n",
       "      <td>2022-01-20T12:43:10-05:00</td>\n",
       "      <td>Bill Siwicki</td>\n",
       "      <td>digital transformation topic jour healthcare t...</td>\n",
       "      <td>https://www.healthcareitnews.com/news/banks-he...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>why voice recognition new competitive battlegr...</td>\n",
       "      <td>www.healthcareitnews.com</td>\n",
       "      <td>2022-01-20T12:24:54-05:00</td>\n",
       "      <td>Paddy Padmanabhan</td>\n",
       "      <td>for watching based artificial intelligence too...</td>\n",
       "      <td>https://www.healthcareitnews.com/blog/why-voic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>biden team regroups court loss covid</td>\n",
       "      <td>www.modernhealthcare.com</td>\n",
       "      <td>2022-01-14T17:30:38-05:00</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>concerned giving president joe biden anxiously...</td>\n",
       "      <td>https://www.modernhealthcare.com/politics-poli...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article_id                                              title  \\\n",
       "0           0  how address inequity healthcare ai hire divers...   \n",
       "1           1  cyberattack red cross endangers confidential i...   \n",
       "2           2  like banks healthcare become zoom healthcare l...   \n",
       "3           3  why voice recognition new competitive battlegr...   \n",
       "4           4               biden team regroups court loss covid   \n",
       "\n",
       "                     medium               publish_date            authors  \\\n",
       "0  www.healthcareitnews.com  2022-01-13T09:05:39-05:00        Kat Jercich   \n",
       "1  www.healthcareitnews.com  2022-01-21T12:06:48-05:00        Kat Jercich   \n",
       "2  www.healthcareitnews.com  2022-01-20T12:43:10-05:00       Bill Siwicki   \n",
       "3  www.healthcareitnews.com  2022-01-20T12:24:54-05:00  Paddy Padmanabhan   \n",
       "4  www.modernhealthcare.com  2022-01-14T17:30:38-05:00   Associated Press   \n",
       "\n",
       "                                              corpus  \\\n",
       "0  even artificial intelligence become thoroughly...   \n",
       "1  the red cross reported week cyberattack contra...   \n",
       "2  digital transformation topic jour healthcare t...   \n",
       "3  for watching based artificial intelligence too...   \n",
       "4  concerned giving president joe biden anxiously...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.healthcareitnews.com/news/how-addr...  \n",
       "1  https://www.healthcareitnews.com/news/cyber-at...  \n",
       "2  https://www.healthcareitnews.com/news/banks-he...  \n",
       "3  https://www.healthcareitnews.com/blog/why-voic...  \n",
       "4  https://www.modernhealthcare.com/politics-poli...  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>article_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user_id  article_id\n",
       "0        0           0\n",
       "1        0           1\n",
       "2        0           2\n",
       "3        0           4\n",
       "4        0          13"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.1.1. Compute the top 20 word occurencies from the corpora of all the articles (provide the result sorted)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>health</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>patients</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>people</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>new</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>covid</td>\n",
       "      <td>42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>data</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>it</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>ibm</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>company</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>we</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>medical</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>hospitals</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>watson</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>in</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>clinical</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>patient</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>need</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          word  counts\n",
       "0         said     131\n",
       "1       health     118\n",
       "2   healthcare     105\n",
       "3          the      96\n",
       "4     patients      59\n",
       "5       people      49\n",
       "6          new      43\n",
       "7        covid      42\n",
       "8         data      41\n",
       "9           it      41\n",
       "10         ibm      40\n",
       "11     company      37\n",
       "12          we      35\n",
       "13     medical      31\n",
       "14   hospitals      29\n",
       "15      watson      26\n",
       "16          in      24\n",
       "17    clinical      24\n",
       "18     patient      24\n",
       "19        need      23"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "articles['corpus'].str.split(expand=True).stack().value_counts().rename_axis('word').reset_index(name='counts')[:20]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.1.2. Compute the top 3 most published media (provide the result sorted)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>medium</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>www.bbc.com</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>www.fiercehealthcare.com</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>www.modernhealthcare.com</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>www.healthcareitnews.com</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     medium  counts\n",
       "0               www.bbc.com      13\n",
       "1  www.fiercehealthcare.com       8\n",
       "2  www.modernhealthcare.com       5\n",
       "3  www.healthcareitnews.com       4"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "articles['medium'].value_counts().rename_axis('medium').reset_index(name='counts')\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.1.3. Compute the percentage of articles that are writen by only one author**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "articles['authors'].apply(lambda x: 1 if len(x.split(','))==1 else 0).sum()/ articles['authors'].count()\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.1.4. Compute the top 3 most active users**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   user id  counts\n",
       "0        2      12\n",
       "1        0      12\n",
       "2        1      11"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "log['user_id'].value_counts().rename_axis('user id').reset_index(name='counts')[:3]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.1.5. Compute the top 5 most read news articles**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article id</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   article id  counts\n",
       "0           4       4\n",
       "1           6       3\n",
       "2           7       3\n",
       "3           8       3\n",
       "4           9       3"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "log['article_id'].value_counts().rename_axis('article id').reset_index(name='counts')[:5]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Item-based collaborative filtering\n",
    "*(3 sub-questions)*\n",
    "\n",
    "Now that we have prepared the data, our next mission is to create a recommender system following the paradigm of Item-based Collaborative Filtering. In this case, this is translated into \"Users who read this news article also read ‚Ä¶\".\n",
    "\n",
    "\n",
    "In order to make predictions, we will apply the following formula, where \n",
    "$N_I(a)$ is the set of neighbors of article $a_1$, and $a_2$ is an article viewed by user $x$.\n",
    "\n",
    "\n",
    "\\begin{equation}\n",
    "{r}_{x}(a_1) =  \\frac{\\sum\\limits_{a_2 \\in N_{I}(a_1)} sim(a_1, a_2) r_{x}(a_2)}{\\sum\\limits_{a_2 \\in N_{I}(a_1)}|sim(a_1, a_2)|}\n",
    "\\end{equation}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.2.1 Compute the user-article matrix which should be a 2D numpy array, with each row corresponding to a user and each column to an article. The value of its cell indicates whether the user has read the corresponding article.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1.,\n",
       "        0., 0., 0., 0., 0., 1., 1., 1., 1., 0., 0., 1., 1., 0.],\n",
       "       [1., 1., 1., 1., 0., 1., 0., 0., 0., 0., 0., 1., 1., 1., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 1., 0., 1., 1., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 1., 0.,\n",
       "        1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
       "       [0., 0., 0., 0., 1., 0., 1., 1., 1., 1., 1., 0., 0., 0., 0., 0.,\n",
       "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_users = len(log['user_id'].unique())\n",
    "n_items= len(articles)\n",
    "\n",
    "user_article = np.zeros((n_users, n_items))\n",
    "\n",
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# add 1 in data_matrix for each article a user has read\n",
    "for ui, user_id in enumerate(user_article):\n",
    "    for ai, article_id in enumerate(user_id):\n",
    "        if len(log[(log['user_id']==ui) & (log['article_id']==ai)]):\n",
    "            user_article[ui][ai] = 1\n",
    "# ---------------------------------------------------\n",
    "\n",
    "user_article"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.2.2 Compute the similarity matrix using cosine similarity metric**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>27</th>\n",
       "      <th>28</th>\n",
       "      <th>29</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.301511</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>...</td>\n",
       "      <td>0.288675</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>0.408248</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows √ó 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         0         1         2         3         4         5         6   \\\n",
       "0  0.288675  0.288675  0.288675  0.000000  0.288675  0.000000  0.000000   \n",
       "1  0.301511  0.301511  0.301511  0.301511  0.000000  0.301511  0.000000   \n",
       "2  0.000000  0.000000  0.000000  0.000000  0.288675  0.000000  0.288675   \n",
       "3  0.000000  0.000000  0.000000  0.000000  0.333333  0.000000  0.333333   \n",
       "4  0.000000  0.000000  0.000000  0.000000  0.408248  0.000000  0.408248   \n",
       "\n",
       "         7         8         9   ...        20        21        22        23  \\\n",
       "0  0.000000  0.000000  0.000000  ...  0.000000  0.288675  0.288675  0.288675   \n",
       "1  0.000000  0.000000  0.000000  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "2  0.288675  0.288675  0.288675  ...  0.288675  0.000000  0.000000  0.000000   \n",
       "3  0.333333  0.333333  0.333333  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "4  0.408248  0.408248  0.408248  ...  0.000000  0.000000  0.000000  0.000000   \n",
       "\n",
       "         24        25   26        27        28   29  \n",
       "0  0.288675  0.000000  0.0  0.288675  0.288675  0.0  \n",
       "1  0.000000  0.301511  0.0  0.301511  0.301511  0.0  \n",
       "2  0.000000  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "3  0.000000  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "4  0.000000  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# magnitude = sqrt(x2 + y2 + z2 + ...)\n",
    "user_article_df = pd.DataFrame(user_article)\n",
    "magnitude = np.sqrt(np.square(user_article_df).sum(axis=1))\n",
    "\n",
    "# unitvector = (x / magnitude, y / magnitude, z / magnitude, ...)\n",
    "user_article_df = user_article_df.divide(magnitude, axis='index')\n",
    "user_article_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5, 30)\n",
      "(5, 30)\n",
      "(30, 30)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "4    1.000000\n",
       "6    0.901388\n",
       "7    0.901388\n",
       "8    0.901388\n",
       "9    0.901388\n",
       "Name: 4, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def calculate_similarity(data_items):\n",
    "    \"\"\"\n",
    "    Calculate the column-wise cosine similarity for a sparse\n",
    "    matrix.\n",
    "    Return a new dataframe matrix with similarities.\n",
    "    \"\"\"\n",
    "    # PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "    from scipy import sparse\n",
    "    \n",
    "    data_sparse = sparse.csr_matrix(data_items)\n",
    "    print(data_items.shape)\n",
    "    print(data_sparse.shape)\n",
    "    similarities = cosine_similarity(data_sparse.transpose())\n",
    "    print(similarities.shape)\n",
    "    sim = pd.DataFrame(data=similarities, index= data_items.columns, columns= data_items.columns)\n",
    "    return sim\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "# Build the similarity matrix\n",
    "similarity_matrix = calculate_similarity(user_article_df)\n",
    "\n",
    "# Lets get the top 5 similar articles for article with id 4\n",
    "similarity_matrix.iloc[4].nlargest(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.2.3 Predict the top 5 recommendations for the user with id 4 using item-based collaborative filtering**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4, 6, 7, 8, 9, 10]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_id = 4 # The id of the user for whom we want to generate recommendations\n",
    "\n",
    "# Get the articles the user has read.\n",
    "user_articles = list(log[log['user_id']==user_id]['article_id'].unique())\n",
    "\n",
    "# User article log\n",
    "user_article_log_vector = user_article_df.iloc[user_id]\n",
    "user_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     0.009145\n",
       "1     0.009145\n",
       "2     0.009145\n",
       "3     0.000000\n",
       "5     0.000000\n",
       "11    0.000000\n",
       "12    0.000000\n",
       "13    0.009145\n",
       "14    0.190211\n",
       "15    0.018448\n",
       "16    0.190211\n",
       "17    0.190211\n",
       "18    0.148400\n",
       "19    0.148400\n",
       "20    0.148400\n",
       "21    0.018448\n",
       "22    0.018448\n",
       "23    0.018448\n",
       "24    0.018448\n",
       "25    0.000000\n",
       "26         NaN\n",
       "27    0.009145\n",
       "28    0.009145\n",
       "29         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# Calculate the score.\n",
    "score = similarity_matrix.dot(user_article_log_vector).div(similarity_matrix.sum(axis=1))\n",
    "\n",
    "# Remove the known likes from the recommendation.\n",
    "score = score.drop(user_articles)\n",
    "score\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n"
     ]
    }
   ],
   "source": [
    "print(type(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14    0.190211\n",
       "16    0.190211\n",
       "17    0.190211\n",
       "18    0.148400\n",
       "19    0.148400\n",
       "20    0.148400\n",
       "15    0.018448\n",
       "21    0.018448\n",
       "22    0.018448\n",
       "23    0.018448\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print the known likes and the top 5 recommendations.\n",
    "score.nlargest(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.3 Content-based recommendations\n",
    "*(6 sub-questions)*\n",
    "\n",
    "The next mission we have is to create a recommender system following the paradigm of the Content-based recommendation approach. In this case, we will also exploit information related to the content of the articles.\n",
    "\n",
    "As a first step, we will compute the tf-idf weights of the articles.\n",
    "\n",
    "\\begin{equation}\n",
    "w(t, a) = tf(t, a) \\cdot idf(t) = \\frac{freq(t, a)}{\\max_{s\\in T} freq(s, a)} \\cdot log(\\frac{N}{n(t)})\n",
    "\\end{equation}\n",
    "\n",
    "Then in order to do predictions, we need to estimate the probability of article $a$ not yet seen by user $x$. To do so, we find the nearest neighbours of $a$ in the subset of articles that have been already seen by the user $x$.\n",
    "\n",
    "\\begin{equation}\n",
    "r_x(a_1) = \\frac{\\sum_{a_2\\in N_I(a_1)} sim(a_1, a_2) \\cdot r_x(a_2)}{\\sum_{a_2\\in N_I(a_1)} |sim(a_1, a_2)|}\n",
    "\\end{equation}\n",
    "\n",
    "\n",
    "Find the articles with the most Knn's that are present in the history of the user, aka find the articles that are most similar to the articles that the user has already seen.\n",
    "- for articles not read by user\n",
    "- get recommendations\n",
    "- rank the articles based on the amount of articles present in the \"already seen\" list of the user\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.1 Compute tf-idf values for the main corpus of the articles and print the shape of the final matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 945)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(analyzer='word', ngram_range=(1, 1), min_df=2, stop_words='english')\n",
    "# vectorizer = TfidfVectorizer()\n",
    "tf_idf = vectorizer.fit_transform(articles['corpus'])\n",
    "tf_idf_matrix = tf_idf.toarray()\n",
    "tf_idf_matrix.shape\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.2 Create the vocabulary of all the articles (as a list) and print the 5 most common words**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>word</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>said</td>\n",
       "      <td>131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>health</td>\n",
       "      <td>118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>healthcare</td>\n",
       "      <td>105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>the</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>patients</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         word  counts\n",
       "0        said     131\n",
       "1      health     118\n",
       "2  healthcare     105\n",
       "3         the      96\n",
       "4    patients      59"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "vocabulary_df = articles['corpus'].str.split(expand=True).stack().value_counts().rename_axis('word').reset_index(name='counts')\n",
    "vocabulary = vocabulary_df['word'].tolist()\n",
    "vocabulary.sort()\n",
    "vocabulary_df[:5]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.3 Find the term with highest TF-IDF value for the article with id 4.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'capacity'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "max_tf = 0\n",
    "max_id = None\n",
    "for i, word_tf in enumerate(tf_idf_matrix[5]):\n",
    "    if word_tf > max_tf:\n",
    "        max_tf = word_tf\n",
    "        max_id = i\n",
    "\n",
    "vocabulary[max_id]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.4 Create a function that finds the best 5 recommendations for any given article and print the best 5 recommendations for article with id 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>title</th>\n",
       "      <th>medium</th>\n",
       "      <th>publish_date</th>\n",
       "      <th>authors</th>\n",
       "      <th>corpus</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>covid surge undermining health problems</td>\n",
       "      <td>www.modernhealthcare.com</td>\n",
       "      <td>2022-01-21T11:35:21-05:00</td>\n",
       "      <td>Associated Press</td>\n",
       "      <td>he told later i assumed forgot said gleason wo...</td>\n",
       "      <td>https://www.modernhealthcare.com/safety-qualit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>patient beware some states still pushing ineff...</td>\n",
       "      <td>www.modernhealthcare.com</td>\n",
       "      <td>2022-01-21T09:18:29-05:00</td>\n",
       "      <td>JoNel Aleccia, Kaiser Health News</td>\n",
       "      <td>as covid variant completes sweep across states...</td>\n",
       "      <td>https://www.modernhealthcare.com/safety-qualit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>us supreme court blocks biden workplace vaccin...</td>\n",
       "      <td>www.bbc.com</td>\n",
       "      <td>2022-01-14T03:31:15.000Z</td>\n",
       "      <td>Natalie Sherman</td>\n",
       "      <td>he added i call business leaders immediately j...</td>\n",
       "      <td>https://www.bbc.com/news/world-us-canada-59989476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>covid austrian parliament approves mandatory v...</td>\n",
       "      <td>www.bbc.com</td>\n",
       "      <td>2022-01-20T22:52:08.000Z</td>\n",
       "      <td></td>\n",
       "      <td>the law due effect february would make austria...</td>\n",
       "      <td>https://www.bbc.com/news/world-europe-60077767</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>29</td>\n",
       "      <td>29</td>\n",
       "      <td>fierce jpm week cityblock ajayi build covid sp...</td>\n",
       "      <td>www.fiercehealthcare.com</td>\n",
       "      <td>Jan 20, 2022 4:30pm</td>\n",
       "      <td>Paige Minemyer</td>\n",
       "      <td>one major lessons pandemic we interconnected i...</td>\n",
       "      <td>https://www.fiercehealthcare.com/practices/fie...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id                                              title  \\\n",
       "7            7            covid surge undermining health problems   \n",
       "8            8  patient beware some states still pushing ineff...   \n",
       "15          15  us supreme court blocks biden workplace vaccin...   \n",
       "20          20  covid austrian parliament approves mandatory v...   \n",
       "29          29  fierce jpm week cityblock ajayi build covid sp...   \n",
       "\n",
       "                      medium               publish_date  \\\n",
       "7   www.modernhealthcare.com  2022-01-21T11:35:21-05:00   \n",
       "8   www.modernhealthcare.com  2022-01-21T09:18:29-05:00   \n",
       "15               www.bbc.com   2022-01-14T03:31:15.000Z   \n",
       "20               www.bbc.com   2022-01-20T22:52:08.000Z   \n",
       "29  www.fiercehealthcare.com        Jan 20, 2022 4:30pm   \n",
       "\n",
       "                              authors  \\\n",
       "7                    Associated Press   \n",
       "8   JoNel Aleccia, Kaiser Health News   \n",
       "15                    Natalie Sherman   \n",
       "20                                      \n",
       "29                     Paige Minemyer   \n",
       "\n",
       "                                               corpus  \\\n",
       "7   he told later i assumed forgot said gleason wo...   \n",
       "8   as covid variant completes sweep across states...   \n",
       "15  he added i call business leaders immediately j...   \n",
       "20  the law due effect february would make austria...   \n",
       "29  one major lessons pandemic we interconnected i...   \n",
       "\n",
       "                                                  url  \n",
       "7   https://www.modernhealthcare.com/safety-qualit...  \n",
       "8   https://www.modernhealthcare.com/safety-qualit...  \n",
       "15  https://www.bbc.com/news/world-us-canada-59989476  \n",
       "20     https://www.bbc.com/news/world-europe-60077767  \n",
       "29  https://www.fiercehealthcare.com/practices/fie...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_recommendations(i, similarities, k=5):\n",
    "    \"\"\"\n",
    "    Recommends articles based on a similarity dataframe\n",
    "    Parameters\n",
    "    ----------\n",
    "    i : int\n",
    "        Article index of the similarity dataframe\n",
    "    similarities : pd.DataFrame\n",
    "        Similarity dataframe, symmetric, with articles as indices and columns\n",
    "    k : int\n",
    "        Amount of recommendations to return\n",
    "    Returns\n",
    "    -------\n",
    "    pd.DataFrame with the top k recommendations\n",
    "    \"\"\"\n",
    "    # PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "    ix = similarities.loc[:,i].to_numpy().argpartition(range(-1,-k,-1))\n",
    "    closest = similarities.columns[ix[-1:-(k+2):-1]]\n",
    "    closest = list(closest.drop(i, errors='ignore'))\n",
    "    return articles[articles['article_id'].isin(list(closest))]\n",
    "    # ---------------------------------------------------\n",
    "\n",
    "# create similarity\n",
    "cosine_sim = cosine_similarity(tf_idf_matrix)\n",
    "\n",
    "# get recommendations for article with id 4\n",
    "corpus_id_4 = articles[articles['article_id']==4]['corpus'].values[0]\n",
    "get_recommendations(4, pd.DataFrame(cosine_sim))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.5 Find the articles that user with id 4 has NOT yet read and print the count of them**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "article_to_recommend = articles[~articles['article_id'].isin(list(log[log['user_id']==4]['article_id'].unique()))]\n",
    "len(article_to_recommend)\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.3.6 Predict top 5 recommendations for user with id 4**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>18</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>22</td>\n",
       "      <td>28</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>21</td>\n",
       "      <td>27</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>20</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    article_id  score\n",
       "12          18      4\n",
       "7           13      3\n",
       "22          28      3\n",
       "21          27      3\n",
       "14          20      3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "user_articles = articles[articles['article_id'].isin(list(log[log['user_id']==4]['article_id'].unique()))]\n",
    "\n",
    "# get recommendations\n",
    "article_ids_to_recommend = article_to_recommend.index.to_list()\n",
    "user_articles_ids = user_articles.index.to_list()\n",
    "\n",
    "scores = list()\n",
    "for i in article_ids_to_recommend:\n",
    "    # get predictions for this article\n",
    "    recommendations = get_recommendations(i, pd.DataFrame(cosine_sim)).index.to_list()\n",
    "    common_elements = len(set(user_articles_ids).intersection(recommendations))\n",
    "    scores.append((i, common_elements))\n",
    "\n",
    "pd.DataFrame(scores, columns=['article_id', 'score']).sort_values(by=['score'], ascending=False).iloc[:5]\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Association rules\n",
    "*(3 sub-questions)*\n",
    "\n",
    "Now we would like to identify frequent rules that govern how words appear together in the news article **titles**.\n",
    "\n",
    "We provide every observed pair of words containing \"covid\" (we only consider rules of size 2).\n",
    "\n",
    "* Compute **support** and **confidence** for the rules X -> covid, where X is a word appearing with covid in the given set of pairs.\n",
    "* From the confidence of the rules you obtained, compute **lift**.\n",
    "* Show the 5 rules with **highest confidence** and the 5 rules with **highest lift** with the provided code. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "titles = articles['title'].apply(lambda x: x.lower().split(' '))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.4.1 Compute support and confidence for the rules X -> covid, where X is a word appearing with covid in an article.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# support    = {# your code here}\n",
    "# confidence = {# your code here}\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "count = vectorizer.fit_transform(articles['title'])\n",
    "titles_voc = vectorizer.get_feature_names()\n",
    "titles_voc.remove('covid')\n",
    "\n",
    "support    = dict()\n",
    "confidence = dict()\n",
    "\n",
    "for word in titles_voc:\n",
    "    articles_with_both = 0\n",
    "    articles_with_word = 0\n",
    "    for title in titles:\n",
    "        if word in title:\n",
    "            articles_with_word +=1\n",
    "            if 'covid' in title:\n",
    "                articles_with_both +=1\n",
    "    support[word] = articles_with_both/ len(titles)\n",
    "    confidence[word] = articles_with_both / articles_with_word\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.4.2 From the confidence of the rules you obtained, compute lift.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# lift = {# your code here}\n",
    "lift = dict()\n",
    "support_covid = [1 if 'covid' in title else 0 for title in titles].count(1)\n",
    "for word in titles_voc:\n",
    "    support_word = [1 if word in title else 0 for title in titles].count(1)\n",
    "    lift[word] = support[word] / (support_word * support_covid)\n",
    "# ---------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.4.3 Show the 5 rules with highest confidence and the 5 rules with highest lift with the provided code.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'africa': 1.0, 'ajayi': 1.0, 'america': 1.0, 'amid': 1.0, 'antibody': 1.0}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# Print confidence\n",
    "{k: v for k, v in sorted(confidence.items(), key=lambda item: item[1], reverse=True)[:5]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'africa': 0.002564102564102564,\n",
       " 'ajayi': 0.002564102564102564,\n",
       " 'america': 0.002564102564102564,\n",
       " 'amid': 0.002564102564102564,\n",
       " 'antibody': 0.002564102564102564}"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# PLEASE ADD YOUR CODE SOLUTION AND RUN THE CELL HERE\n",
    "# Print lift\n",
    "{k: v for k, v in sorted(lift.items(), key=lambda item: item[1], reverse=True)[:5]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4 [Submit your notebook]()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Distributed-Information-Systems\" data-toc-modified-id=\"Distributed-Information-Systems-0\"><span class=\"toc-item-num\">0&nbsp;&nbsp;</span>Distributed Information Systems</a></span></li><li><span><a href=\"#Rename-your-notebook\" data-toc-modified-id=\"Rename-your-notebook-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Rename your notebook</a></span></li><li><span><a href=\"#Word-Representation-for-Concept-Identification\" data-toc-modified-id=\"Word-Representation-for-Concept-Identification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Word Representation for Concept Identification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-the-vocabulary-by-selecting-top-k-frequent-words\" data-toc-modified-id=\"Build-the-vocabulary-by-selecting-top-k-frequent-words-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Build the vocabulary by selecting top-k frequent words</a></span></li><li><span><a href=\"#Construct-the-word-cooccurence-matrix\" data-toc-modified-id=\"Construct-the-word-cooccurence-matrix-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Construct the word cooccurence matrix</a></span></li><li><span><a href=\"#Perform-SVD-on-the-matrix-and-select-the-largest-singular-values\" data-toc-modified-id=\"Perform-SVD-on-the-matrix-and-select-the-largest-singular-values-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Perform SVD on the matrix and select the largest singular values</a></span></li></ul></li><li><span><a href=\"#Vector-based-retrieval-using-Word-representations\" data-toc-modified-id=\"Vector-based-retrieval-using-Word-representations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Vector-based retrieval using Word representations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Document-and-query-vectors-from-word-representations\" data-toc-modified-id=\"Document-and-query-vectors-from-word-representations-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Document and query vectors from word representations</a></span></li><li><span><a href=\"#Retrieve-top-10-relevant-documents\" data-toc-modified-id=\"Retrieve-top-10-relevant-documents-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Retrieve top-10 relevant documents</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-retrieval-result-using-DCG\" data-toc-modified-id=\"Evaluate-retrieval-result-using-DCG-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Evaluate retrieval result using DCG</a></span></li><li><span><a href=\"#Explain-the-DCG-values-plot\" data-toc-modified-id=\"Explain-the-DCG-values-plot-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Explain the DCG values plot</a></span></li></ul></li><li><span><a href=\"#Submit-your-notebook\" data-toc-modified-id=\"Submit-your-notebook-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Submit your notebook</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "***Midterm Exam, Winter Semester 2021-2022***\n",
    "\n",
    "The following materials are allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation.\n",
    "\n",
    "The exam will be held on your computer, but digital communication by any means is strictly prohibited. \n",
    "By participating to this exam you agree to these conditions.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "\n",
    "1. You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "* We will publish 15 minutes before the end of the exam a password for uploading your solutions on Moodle.\n",
    "* It is not recommended to leave the exam before the password is published. If you need to leave earlier, contact us."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rename your notebook\n",
    "Replace SciperNo with your **personal SCIPER Number**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /usr/local/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "#Required libraries\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    documents = []\n",
    "    orig_docs = []\n",
    "    DIR = './'\n",
    "    tknzr = TweetTokenizer()\n",
    "    with open(\"epfldocs.txt\", encoding = \"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for text in content:\n",
    "        orig_docs.append(text)\n",
    "        # split into words\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        documents.append(' '.join(words))\n",
    "    return documents, orig_docs\n",
    "\n",
    "documents, orig_docs = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(documents) == 1075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Representation for Concept Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build word representations in a latent concept space using SVD. Differently to Latent Semantic Indexing (LSI) we will derive the latent concepts space from the **word co-occurrence matrix** (and not from the term-document matrix, as in standard LSI).\n",
    "\n",
    "An entry (i,j) in the word co-occurrence matrix corresponds to the number of times the word i co-occurs with the word j in the context of word i. The context of the words consist of the words preceding or succeeding the word in the text.  \n",
    "\n",
    "By deriving an SVD from the word co-occurrence matrix, and selecting the top dimensions of the latent space, we obtain a word representation as vectors over a concept space. Commonly such word representations are also called word embeddings.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the vocabulary by selecting top-k frequent words\n",
    "No code is required for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary is the list of all words\n",
    "# vocabulary_to_index maps words to their index\n",
    "\n",
    "def create_vocabulary_frequency(corpus, vocab_len):\n",
    "    '''Select top-k (k = vocab_len) words in term of frequencies as vocabulary'''\n",
    "    vocabulary_to_index = {}\n",
    "    count = defaultdict(int)\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "                count[word] += 1\n",
    "    \n",
    "    sorted_count_by_freq = sorted(count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    vocabulary = []\n",
    "    for i, x in enumerate(sorted_count_by_freq[:vocab_len]):\n",
    "        vocabulary.append(x[0])\n",
    "        vocabulary_to_index[x[0]] = i\n",
    "    return vocabulary, vocabulary_to_index\n",
    "\n",
    "vocab_freq, vocabulary_to_index = create_vocabulary_frequency(documents, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the word cooccurence matrix\n",
    "\n",
    "In this question, you need to construct the word co-occurence matrix, given the vocabulary and the set of documents.\n",
    "\n",
    "The value of a cell (i,j) is the number of times the word i co-occurs with the word j in the context of word i.\n",
    "\n",
    "For this question, a word $w_i$ cooccurs with a word $w_j$ in the context of word $w_i$ if $w_j$ preceeds or succeeds $w_i$ with a distance **at most 2**.\n",
    "\n",
    "Example: For this document \"*how to bake bread without bake recip*\", the words coocur with the word \"*bread*\" are \"*to, bake, without, bake*\".\n",
    "\n",
    "Make sure that you consider only words that appear in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_word_cooccurence_matrix(vocabulary_to_index, documents, k=2):\n",
    "    matrix = np.zeros((len(vocabulary_to_index), len(vocabulary_to_index)))\n",
    "    for document in documents:\n",
    "        terms = document.split()\n",
    "        for ind, term_i in enumerate(terms):\n",
    "            if term_i in vocabulary_to_index:\n",
    "                for context_ind in range(max(0, ind-2), min(len(terms), ind+3)):\n",
    "                    if context_ind != ind and terms[context_ind] in vocabulary_to_index:\n",
    "                        matrix[vocabulary_to_index[term_i], vocabulary_to_index[terms[context_ind]]] += 1\n",
    "    return matrix\n",
    "\n",
    "word_cooccur_matrix = construct_word_cooccurence_matrix(vocabulary_to_index, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally check whether the matrix you constructed is correct using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_matrix = False\n",
    "if assert_matrix:\n",
    "    word_coor_mat = np.load(\"word_coocur_matrix.npy\")\n",
    "    assert(word_coor_mat == word_cooccur_matrix[:100,:100]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform SVD on the matrix and select the largest singular values \n",
    "\n",
    "We perform SVD on the matrix $\\mathbf{M} = \\mathbf{K}\\mathbf{S}\\mathbf{D}^T$ and select the first 128 largest singular values.\n",
    "\n",
    "Then, we can use the submatrix $\\mathbf{K_s}$, corresponding to the largest singular values, as the word representation matrix. \n",
    "\n",
    "Hint 1 : Are the words represented in $\\mathbf{K_s}$ as rows or columns?\n",
    "\n",
    "Hint 2: np.linalg.svd(M, full_matrices=False) performs SVD on the matrix $\\mathbf{M}$ and returns $\\mathbf{K}, \\mathbf{S}, \\mathbf{D}^T$\n",
    "\n",
    " -  $\\mathbf{K}, \\mathbf{D}^T$ are matrices with orthonormal columns\n",
    " -  $\\mathbf{S}$ is a **vector** of singular values in a **descending** order\n",
    " \n",
    "Hint 3: np.diag(V) converts a vector to a diagonal matrix\n",
    "\n",
    "Hint 4: To select:\n",
    " - the first k rows of a matrix A, use A[0:k, :]\n",
    " - the first k columns of a matrix A, use A[:, 0:k]\n",
    " - the submatrix from first k rows and k columns of a matrix A, use A[0:k, 0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a word coocurrence matrix and the number of singular values that will be selected\n",
    "# Output: K_s, S_s, Dt_s are similar to the defintion in the lecture\n",
    "\n",
    "def truncated_svd(word_cooccur_matrix, num_val):\n",
    "    # The following may take 1-2 minutes since we are decomposing a matrix of size 5000x1075\n",
    "    K, S, Dt = np.linalg.svd(word_cooccur_matrix, full_matrices=False) \n",
    "    \n",
    "    K_sel = K[:, :num_val]\n",
    "    S_sel = np.diag(S)[:num_val, :num_val]\n",
    "    Dt_sel = Dt[:num_val, :]\n",
    "    return K_sel, S_sel, Dt_sel\n",
    "\n",
    "K_s, S_s, Dt_s = truncated_svd(word_cooccur_matrix,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector-based retrieval using Word representations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document and query vectors from word representations\n",
    "\n",
    "For each document and query, we construct the corresponding vector by **averaging** its word representations.\n",
    "\n",
    "Hint: not all words are in the vocabulary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vecs(documents, word_embedding_matrix, vocabulary_to_index):\n",
    "    doc_vecs = np.zeros((len(documents), word_embedding_matrix.shape[1]))\n",
    "\n",
    "    w_emb = lambda w: word_embedding_matrix[vocabulary_to_index[w]] if w in vocabulary_to_index else np.zeros((word_embedding_matrix.shape[1]))\n",
    "    d_emb = lambda d: np.average(list(map(w_emb, d.split()+[''])), axis=0)\n",
    "\n",
    "    doc_vecs = np.stack(list(map(d_emb, documents)), axis=0)\n",
    "    \n",
    "    return doc_vecs\n",
    "\n",
    "doc_vecs = get_doc_vecs(documents, K_s, vocabulary_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top-10 relevant documents\n",
    "\n",
    "Retrieve top-10 relevant documents for the query \"*computer science*\"\n",
    "\n",
    "Hint: you may use the function get_doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"computer science\"\n",
    "\n",
    "query_vec = get_doc_vecs([query], K_s, vocabulary_to_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smeros/.miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy*1.0/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "def retrieve_documents(doc_vecs, query_vec, top_k):\n",
    "    scores = [[cosine_similarity(query_vec, doc_vecs[d,:]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    retrieved = []\n",
    "    for i in range(top_k):\n",
    "        doc_ids.append(scores[i][1])\n",
    "        retrieved.append(orig_docs[scores[i][1]])\n",
    "    return doc_ids, retrieved\n",
    "\n",
    "retrieved_ids, retrieved_docs = retrieve_documents(doc_vecs, query_vec, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "We consider the scikit reference code as an ‚Äúoracle‚Äù that supposedly gives the correct result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval oracle \n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), vocabulary=vocab_freq, min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(documents)\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.1):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1), \n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids\n",
    "\n",
    "# gt_ids are the document ids retrieved by the oracle\n",
    "gt_ids = search_vec_sklearn(query, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also assume that there is a user that has done the grading of all the documents according to their relevance. \n",
    "The top-10 results using scikit-learn have grade 3, the next 10 results have grade 2, \n",
    "the rest in the list has grade 1 while non-relevant results have grade 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = []\n",
    "for i in range(len(documents)):\n",
    "    if i in gt_ids[:10]:\n",
    "        grade.append(3)\n",
    "    elif i in gt_ids[10:20]:\n",
    "        grade.append(2)\n",
    "    elif i in gt_ids[20:]:\n",
    "        grade.append(1)\n",
    "    else:\n",
    "        grade.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate retrieval result using DCG \n",
    "\n",
    "Discounted Cumulative Gain (DCG) is a retrieval metric that also takes into account the ordering of the result. \n",
    "\n",
    "The DCG accumulated at a rank $k$ is defined as:\n",
    "\n",
    "$DCG_k = \\sum_{i=1}^k \\frac{grade[i]}{log_2(i+1)}$\n",
    "\n",
    "where $grade[i]$ is the relevance score given by the user for the result at position $i$.\n",
    "\n",
    "Hint: the logarithm is computed using the function np.log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(k, retrieved_ids, grade):\n",
    "    dcg_val = 0\n",
    "    for i in range(1, k):\n",
    "        dcg_val += grade[i] / math.log2(i+1)\n",
    "    return dcg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the DCG for the top-1 to the top-10 retrieval results and we plot the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a24d003d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjMsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+AADFEAAAVaElEQVR4nO3df2xdd33G8eexHSexnaYkcVJI0rotTiBCoIJV2JD4MWBK2dRqEptaDbYhIJpEgQ20rWxTQWV/bDCNbVqBRR1DY4yu69AWobAijW5MsFZ1gRXacq/dEBq39bGbtOm5cWPH9md/+Ca4jl3f2Mc5957zfkmR7rnn6+uPjq4fnXzP55yvI0IAgNbXlncBAIBsEOgAUBAEOgAUBIEOAAVBoANAQXTk9Yu3bdsWfX19ef16AGhJDz744NMR0bvYvtwCva+vT4ODg3n9egBoSbZ/utQ+plwAoCAIdAAoCAIdAAqCQAeAgiDQAaAgCHQAKAgCHQAKIrc+dKCopqZn9cXv/EQTk9N5l4ImNdC3RW/as+i9QatCoAMZ+5+hcf3pN34sSbJzLgZN6bfffDWBDrSCSpJKkn74yV/Upg3rcq4GZcIcOpCx6miql23eQJjjoiPQgYxVkpr2XLYp7zJQQgQ6kKHpmVk9NlbT3h0EOi4+Ah3I0E9PTGhqZlZ7CHTkgEAHMlQdnbsgupcpF+SAQAcyVElS2dLVvT15l4ISItCBDFWTVFds6dLGzva8S0EJEehAhiqjKfPnyA2BDmRkcnpGR49PMH+O3Cwb6La/aHvM9o+W2P/rth+q//uu7ddkXybQ/I6Mn9LMbHCGjtw0cob+JUn7X2T/TyS9OSJeLelTkg5mUBfQcqr1W/4JdORl2We5RMS3bfe9yP7vztu8T9Ku1ZcFtJ7KaKqONuvKbd15l4KSynoO/X2SvrHUTtsHbA/aHhwfH8/4VwP5qiaprurtVmcHl6aQj8y+ebbfqrlA/4OlxkTEwYgYiIiB3t7sHx0J5Kma1JhuQa4yCXTbr5Z0h6QbIuJ4Fp8JtJKJqWk9fmKCZ7ggV6sOdNuXS/qapPdERHX1JQGtZyipSZL6CXTkaNmLora/KuktkrbZHpH0CUnrJCkiviDpVklbJX3Oc8uzTEfEwFoVDDSjs4ta0IOOPDXS5XLTMvvfL+n9mVUEtKChJNX6jjZdvqUr71JQYlyOBzJQSWrq39Gj9jYWEUV+CHQgA1We4YImQKADq3Ry4oxGnztNoCN3BDqwStWx+gVRAh05I9CBVTr3DBc6XJAzAh1Ypepoqp71HXrZ5g15l4KSI9CBVaokqfbs6FH9PgwgNwQ6sAoRwSpFaBoEOrAKT9em9MzEGQIdTYFAB1ZhiFv+0UQIdGAVKqxShCZCoAOrUE1Sbenu1LaezrxLAQh0YDUqo6n6t9PhguZAoAMrFBEaSmrMn6NpEOjACj118rTSyWnmz9E0CHRghVjUAs2GQAdWqDpa73DZTqCjORDowApVklQ7LlmvzV3r8i4FkESgAytWTbjlH82FQAdWYGY2NDxW4xnoaCoEOrACx05M6PSZWZ6BjqZCoAMrwC3/aEbLBrrtL9oes/2jJfbb9l/bHrb9kO3XZl8m0FzOdrj0b+/JuRLgZxo5Q/+SpP0vsv86Sf31fwckfX71ZQHNrZKk2r1lo7rXd+RdCnDOsoEeEd+WdOJFhtwg6R9izn2SLrX90qwKBJrRUMIFUTSfLObQd0o6Nm97pP7eeWwfsD1oe3B8fDyDXw1cfFPTs3psvMb8OZpOFoG+2GPmYrGBEXEwIgYiYqC3tzeDXw1cfEePn9L0bBDoaDpZBPqIpN3ztndJejKDzwWaUmWUDhc0pywC/ZCk36h3u7xB0smIeCqDzwWaUjVJ1d5mXdXbnXcpwAsse4ne9lclvUXSNtsjkj4haZ0kRcQXJB2W9E5Jw5ImJL13rYoFmkE1SdW3tUsb1rXnXQrwAssGekTctMz+kPTBzCoCmlw1qemVL2W6Bc2HO0WBC3D6zIyOHj+lfh6ZiyZEoAMXYHispggWtUBzItCBC0CHC5oZgQ5cgOpYqs72NvVt7cq7FOA8BDpwAaqjqa7e3qOOdv500Hz4VgIXoJrUtGcHT1hEcyLQgQalp8/oiWefZ/4cTYtABxpUTWqSxFMW0bQIdKBBQ/VVimhZRLMi0IEGVZJUXZ3t2nnpxrxLARZFoAMNqiap+rf3qK1tsSdGA/kj0IEGVUZZ1ALNjUAHGnDi1JSerk0yf46mRqADDagm3PKP5kegAw2o0uGCFkCgAw2ojKa6ZEOHtm9an3cpwJIIdKAB1STV3ss2yabDBc2LQAeWERH1Z7gw3YLmRqADyxhLJ3Xy+TPMn6PpEejAMljUAq2CQAeWQcsiWkVDgW57v+2K7WHbtyyy/3Lb99r+vu2HbL8z+1KBfFRGU23rWa8t3Z15lwK8qGUD3Xa7pNslXSdpn6SbbO9bMOyPJd0VEddIulHS57IuFMhLdaymvZexqAWaXyNn6NdKGo6IIxExJelOSTcsGBOSLqm/3izpyexKBPIzOxsaSlKmW9ASOhoYs1PSsXnbI5Jev2DMJyV90/aHJHVLensm1QE5e+LZ5zUxNcOiFmgJjZyhL3YnRSzYvknSlyJil6R3Svqy7fM+2/YB24O2B8fHxy+8WuAiO9vh0k+gowU0EugjknbP296l86dU3ifpLkmKiP+VtEHStoUfFBEHI2IgIgZ6e3tXVjFwEVXOdbgwh47m10igPyCp3/aVtjs1d9Hz0IIxj0t6myTZfqXmAp1TcLS8oSTVzks3atOGdXmXAixr2UCPiGlJN0u6R9Kjmutmedj2bbavrw/7mKQP2P4/SV+V9FsRsXBaBmg5laTG2TlaRiMXRRURhyUdXvDerfNePyLpjdmWBuRremZWj43V9KY9580eAk2JO0WBJRw9PqGpmVnt2c4FUbQGAh1YAotaoNUQ6MASqkkqW3r5dubQ0RoIdGAJ1SRV39ZubVjXnncpQEMIdGAJldFU/Zydo4UQ6MAiTp+Z0dHjE8yfo6UQ6MAijoyf0sxs8FAutBQCHVjE0BgdLmg9BDqwiMpoqnXtVt/W7rxLARpGoAOLqCaprtzWrc4O/kTQOvi2AouosKgFWhCBDixwanJax048z6IWaDkEOrDA8FhNkrSHC6JoMQQ6sMDZRS04Q0erIdCBBaqjqdZ3tGn3lq68SwEuCIEOLFBJUvXv6FF722LL6QLNi0AHFqjS4YIWRaAD85ycOKPkuUnmz9GSCHRgnmr9ln86XNCKCHRgnspoPdA5Q0cLItCBeapJqp71HXrZ5g15lwJcMAIdmKcymmrPjh7ZdLig9TQU6Lb3267YHrZ9yxJjfs32I7Yftv1P2ZYJrL2IUDVJeWQuWlbHcgNst0u6XdI7JI1IesD2oYh4ZN6Yfkkfl/TGiHjG9va1KhhYK0/XpvTMxBnmz9GyGjlDv1bScEQciYgpSXdKumHBmA9Iuj0inpGkiBjLtkxg7VUTLoiitTUS6DslHZu3PVJ/b749kvbY/o7t+2zvX+yDbB+wPWh7cHx8fGUVA2uEDhe0ukYCfbGrQ7Fgu0NSv6S3SLpJ0h22Lz3vhyIORsRARAz09vZeaK3AmqomqbZ0d2pbT2fepQAr0kigj0jaPW97l6QnFxnz7xFxJiJ+IqmiuYAHWsbcLf90uKB1NRLoD0jqt32l7U5JN0o6tGDMv0l6qyTZ3qa5KZgjWRYKrKW5Dpcat/yjpS0b6BExLelmSfdIelTSXRHxsO3bbF9fH3aPpOO2H5F0r6Tfi4jja1U0kLUnT55WbXJa/QQ6WtiybYuSFBGHJR1e8N6t816HpI/W/wEtp1q/IEoPOloZd4oCmteyuJ1AR+si0AHNLWpx2SUbtLlrXd6lACtGoAOqd7gw3YIWR6Cj9GZmQ0NJTXu29+RdCrAqBDpK7/ETE5qcnuUMHS2PQEfpnb0gSg86Wh2BjtI727LYv4MpF7Q2Ah2lV0lSXb6lS12dDd2WATQtAh2ld/YZLkCrI9BRalPTszoyfopH5qIQCHSU2tHjpzQ9G9zyj0Ig0FFqLGqBIiHQUWrVJFV7m3VVb3fepQCrRqCj1Cqjqfq2dml9R3vepQCrRqCj1KpJyvw5CoNAR2mdPjOjn56YYP4chUGgo7SGx2qK4JZ/FAeBjtI61+HClAsKgkBHaVWTVJ3tbbpiS1fepQCZINBRWpUk1dXbe9TRzp8BioFvMkprKKlpL89wQYEQ6Cil9PQZPfHs88yfo1AaCnTb+21XbA/bvuVFxr3LdtgeyK5EIHvVpCZJ2rOdQEdxLBvottsl3S7pOkn7JN1ke98i4zZJ+rCk+7MuEsjauVWKOENHgTRyhn6tpOGIOBIRU5LulHTDIuM+JenTkk5nWB+wJiqjqbo627Xz0o15lwJkppFA3ynp2Lztkfp759i+RtLuiPj6i32Q7QO2B20Pjo+PX3CxQFaGxlL179iktjbnXQqQmUYCfbFvfJzbabdJ+qykjy33QRFxMCIGImKgt7e38SqBjFVG6XBB8TQS6COSds/b3iXpyXnbmyS9StJ/2T4q6Q2SDnFhFM3qeG1ST9cmeYYLCqeRQH9AUr/tK213SrpR0qGzOyPiZERsi4i+iOiTdJ+k6yNicE0qBlbpXIcLgY6CWTbQI2Ja0s2S7pH0qKS7IuJh27fZvn6tCwSyRocLiqqjkUERcVjS4QXv3brE2Lesvixg7VSTVJs3rtP2TevzLgXIFHeKonSqSaq9OzbJpsMFxUKgo1QiQpXRVP10uKCACHSUSvLcpJ47Pc38OQqJQEepVOoXROlwQRER6CiVIQIdBUago1Qqo6l6N63Xlu7OvEsBMkego1SqSao9XBBFQRHoKI3Z2VA1qTHdgsIi0FEaI888r+fPzGgvgY6CItBRGmdv+WfZORQVgY7SONuy2L+dOXQUE4GO0qgmqXZeulGbNqzLuxRgTRDoKI3KKB0uKDYCHaUwPTOrI+OnmD9HoRHoKIWjxyc0NTNLhwsKjUBHKVS55R8lQKCjFCqjqdosvZwOFxQYgY5SqCaprtjarQ3r2vMuBVgzBDpKgWe4oAwIdBTe6TMzOnp8gguiKDwCHYV3ZPyUZmaDlkUUXkOBbnu/7YrtYdu3LLL/o7Yfsf2Q7f+0fUX2pQIrQ4cLymLZQLfdLul2SddJ2ifpJtv7Fgz7vqSBiHi1pLslfTrrQoGVqiSp1rVbfVu78y4FWFONnKFfK2k4Io5ExJSkOyXdMH9ARNwbERP1zfsk7cq2TGDlhpJUV23rUWcHM4wotka+4TslHZu3PVJ/bynvk/SNxXbYPmB70Pbg+Ph441UCq1BJUubPUQqNBLoXeS8WHWi/W9KApM8stj8iDkbEQEQM9Pb2Nl4lsEKnJqd17MTz2kvLIkqgo4ExI5J2z9veJenJhYNsv13SH0l6c0RMZlMesDpDYzVJUj8XRFECjZyhPyCp3/aVtjsl3Sjp0PwBtq+R9LeSro+IsezLBFamOjrX4UIPOspg2UCPiGlJN0u6R9Kjku6KiIdt32b7+vqwz0jqkfQvtn9g+9ASHwdcVNUk1YZ1bdq9pSvvUoA118iUiyLisKTDC967dd7rt2dcF5CJSpKqf/smtbctdikIKBb6uFBoc89wYboF5UCgo7CenZhS8twkD+VCaRDoKKxqMtfhQg86yoJAR2GdfYYLHS4oCwIdhVVNUm1a36GXbt6QdynARUGgo7Aqo6n6d/TIpsMF5UCgo5AiQtUk1V7mz1EiBDoKabw2qWcmztCyiFIh0FFIQ/UOFy6IokwIdBRSpf4MF1oWUSYEOgqpmqTa0t2pbT3r8y4FuGgIdBRSJUm5QxSlQ6CjcCJCQ0mN+XOUDoGOwnny5GnVJqeZP0fpEOgoHBa1QFkR6CicSv0ZLiw7h7Ih0FE41dFUl12yQZs3rsu7FOCiItBROJUkZf4cpUSgo1BmZkPDYzXtpWURJUSgo1AePzGhyelZnuGCUiLQUSjnbvkn0FFCBDoKpXquw4UpF5RPQ4Fue7/tiu1h27cssn+97X+u77/fdl/WhQKNqCSpLt/Spa7OjrxLAS66ZQPddruk2yVdJ2mfpJts71sw7H2SnomIl0v6rKQ/y7pQoBFDScp0C0qrkdOYayUNR8QRSbJ9p6QbJD0yb8wNkj5Zf323pL+x7YiIDGuVJP13dVx/8vVHlh+IUnpsvKZ37NuRdxlALhoJ9J2Sjs3bHpH0+qXGRMS07ZOStkp6ev4g2wckHZCkyy+/fEUF96zvYH4US3rFSy/Rr1yzM+8ygFw0EuiLrbC78My7kTGKiIOSDkrSwMDAis7eX3fFS/S6K163kh8FgEJr5KLoiKTd87Z3SXpyqTG2OyRtlnQiiwIBAI1pJNAfkNRv+0rbnZJulHRowZhDkn6z/vpdkr61FvPnAIClLTvlUp8Tv1nSPZLaJX0xIh62fZukwYg4JOnvJH3Z9rDmzsxvXMuiAQDna6hZNyIOSzq84L1b570+LelXsy0NAHAhuFMUAAqCQAeAgiDQAaAgCHQAKAjn1V1oe1zST1f449u04C7UkuN4vBDH42c4Fi9UhONxRUT0LrYjt0BfDduDETGQdx3NguPxQhyPn+FYvFDRjwdTLgBQEAQ6ABREqwb6wbwLaDIcjxfiePwMx+KFCn08WnIOHQBwvlY9QwcALECgA0BBtFygL7dgdZnY3m37XtuP2n7Y9kfyrilvttttf9/21/OuJW+2L7V9t+0f178jP5d3TXmx/bv1v5Ef2f6q7Q1517QWWirQG1ywukymJX0sIl4p6Q2SPljy4yFJH5H0aN5FNIm/kvQfEfEKSa9RSY+L7Z2SPixpICJepbnHgBfyEd8tFeiat2B1RExJOrtgdSlFxFMR8b3661Rzf7ClXVDT9i5JvyTpjrxryZvtSyS9SXNrFSgipiLi2XyrylWHpI31FdW6dP6qa4XQaoG+2ILVpQ2w+Wz3SbpG0v35VpKrv5T0+5Jm8y6kCVwlaVzS39enoO6w3Z13UXmIiCck/bmkxyU9JelkRHwz36rWRqsFekOLUZeN7R5J/yrpdyLiubzryYPtX5Y0FhEP5l1Lk+iQ9FpJn4+IaySdklTKa062X6K5/8lfKellkrptvzvfqtZGqwV6IwtWl4rtdZoL869ExNfyridHb5R0ve2jmpuK+wXb/5hvSbkakTQSEWf/x3a35gK+jN4u6ScRMR4RZyR9TdLP51zTmmi1QG9kwerSsG3NzZE+GhF/kXc9eYqIj0fErojo09z34lsRUcizsEZExKikY7b31t96m6RHciwpT49LeoPtrvrfzNtU0AvEDa0p2iyWWrA657Ly9EZJ75H0Q9s/qL/3h/U1YIEPSfpK/eTniKT35lxPLiLiftt3S/qe5jrDvq+CPgKAW/8BoCBabcoFALAEAh0ACoJAB4CCINABoCAIdAAoCAIdAAqCQAeAgvh/fVZQbqjxndAAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = []\n",
    "for i in range(10):\n",
    "    val = dcg(i, retrieved_ids, grade)\n",
    "    vals.append(val)\n",
    "    \n",
    "plt.plot(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the DCG values plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit your notebook\n",
    "\n",
    "Go to [Moodle](https://moodle.epfl.ch/course/view.php?id=4051) > Exams > Midterm and follow the instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò DIS Final Exam - Fall 2022\n",
    "\n",
    "**üéâ Welcome to DIS Final exam that takes place on the 1st of February 2023 from 15:00 to 18:00.**\n",
    "\n",
    "> Please fill the following info:\n",
    "> - Your Name: \n",
    "> - Your SCIPER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer all the parts of the exam:\n",
    "\n",
    "- [PART 0: Rename your notebook with your SciperNo](#part0)\n",
    "\n",
    "- [PART 1: Multiple Choice Questions - Quiz](#part1)\n",
    "\n",
    "- [PART 2: Theory questions](#part2)\n",
    "\n",
    "- [PART 3: Programming exercise](#part3)\n",
    "\n",
    "    - [3.1: Parse and understand the data](#part31)\n",
    "        - 3.1.1 Create the vocabulary of the documents\n",
    "\n",
    "    - [3.2: Encode documents with Vector Space Retrieval](#part32)\n",
    "        - 3.2.1 Build the term-frequency matrix.\n",
    "        - 3.2.2 Build the inverse document-frequency matrix\n",
    "        - 3.2.3 Vectorize input with Vector Space Model\n",
    "\n",
    "    - [3.3: k-Nearest-Neighbors (kNN)](#part33)\n",
    "        - 3.3.1 Implement kNN function\n",
    "        - 3.3.2 Print k=10 closests documents to the given query\n",
    "        - 3.3.3 Implement probabilistic and weigting estimation of kNN\n",
    "        - 3.3.4 Compute weighting and probabilistic estimation of the given query\n",
    "        - 3.3.5 Implement a Rocchio classifier\n",
    "        - 3.3.6 Compute Rocchio estimation of the given query\n",
    "\n",
    "    - [3.4: Naive Bayes Classifier](#part34)\n",
    "        - 3.4.1 Compute the Naive Bayes estimation for the given query\n",
    "        - 3.4.2 Discuss the difference the above classifers\n",
    "\n",
    "    - [3.5: Association rules](#part35)\n",
    "        - 3.5.1 Compute support and confidence\n",
    "        - 3.5.2 Compute lift\n",
    "        - 3.5.3 Explanation of implemented metrics\n",
    "        \n",
    "- [SUBMIT EXAM](#submit)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üçÄ GOOD LUCK üçÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part0'></a>\n",
    "## PART 0: Rename your notebook with your SciperNo\n",
    "\n",
    "The final sumbitted file should have the following name: `SciperNo.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## PART 1: [Multiple Choice Questions - Quiz](https://moodle.epfl.ch/mod/quiz/view.php?id=1235302)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## PART 2: Theory Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Given a document collection with a vocabulary consisting of three words, $V = {a,b,c}$, and two documents $d_1$ = aabc and $d_2 = abc$. The query is $q = ab$.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2.1. Using standard vector space retrieval, is it possible to enforce both a ranking $d_1 > d_2$ and $d_2 > d_1$ by adding suitable documents to the collection. If yes, give examples of such documents to be added, if no, provide an argument why this cannot be the case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "Yes, it is possible.\n",
    "\n",
    "    d1>d2: adding d3=‚Äùb‚Äù\n",
    "    d2>d1: adding d3=‚Äùc‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2.2. Using smoothed probabilistic retrieval (with $\\lambda=0.5$), is it possible to enforce both a ranking $d_1 > d_2$ and $d_2 > d_1$ by adding suitable documents to the collection. If yes, give examples of such documents to be added, if no, provide an argument why this cannot be the case.**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "Yes, it is possible.\n",
    "\n",
    "    d1>d2: without adding any document, it holds true\n",
    "    d2>d1: adding d3=‚Äùaaaa‚Äù\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **2.3. Is it possible to enforce a ranking $d_2 > d_1$ with vector space retrieval and $d_1 > d_2$ with probabilistic retrieval ($\\lambda=0.5$), by adding the same documents to the collection? If yes, give examples of such documents to be added, if no, provide an argument why this cannot be the case.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "Yes, it is possible. Adding a document like d3=‚Äùc‚Äù would make d2>d1 for   VSR and d1>d2 for smoothed probabilistic retrieval."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## PART 3: Programming exercise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° THE BACKSTORY\n",
    "\n",
    "You are given a \"news topic classification\" dataset (`data.csv`), and the task is to apply document classification techniques you've learned during the semester. The goal is to classify news articles based on the topic they refer to.\n",
    "\n",
    "### üì∞ THE DATA\n",
    "\n",
    "This dataset contains ~7000 samples of news articles which consists of 3 columns:\n",
    "\n",
    "The first column is `label`, the second is `title` and the third is `description`.\n",
    "\n",
    "The topic labels are numbered 1-4 where `1` represents topic **\"World\"**, `2` represents topic **\"Sports\"**, `3` represents **\"Business\"** and `4` represents **\"Sci/Tech\"**.\n",
    "\n",
    "| Column     | Description                   |\n",
    "|------------|-------------------------------|\n",
    "| **label**  | The topic label/topic id of the article|\n",
    "| **title**  | The title of the article |\n",
    "| **description**  | The description of the article |\n",
    "\n",
    "\n",
    "### ‚úÖ THE TASK\n",
    "\n",
    "You need to build a KNN and a Naive Bayes classifer to classify the articles into the 4 different categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part31'></a>\n",
    "### 3.1: Parse and understand the data\n",
    "\n",
    "*(1 sub-question)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/foroutan/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/foroutan/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries- you can additionally import any library you want.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of news articles:  6994\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Read a list of documents from a file. Each line in a file is a document\n",
    "data_path = \"data.csv\"\n",
    "data = pd.read_csv(data_path)\n",
    "print(\"Number of news articles: \", len(data))\n",
    "\n",
    "# Plot the distribution of topics\n",
    "labels = data.label.unique()\n",
    "sizes = [Counter(data.label)[i] for i in labels]\n",
    "plt.figure( figsize=(5,5) )\n",
    "plt.pie(sizes ,  labels=labels , autopct='%1.1f%%')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions - NOTHING TO CHANGE HERE\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "# Tokenize, stem a document\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return \" \".join([stemmer.stem(word.lower()) for word in tokens if word not in stopwords.words('english')])\n",
    "\n",
    "# Preprocess articles\n",
    "def preprocess_text(documents):\n",
    "    docs = list()\n",
    "    for doc in documents:\n",
    "        docs.append(tokenize(doc).split())  # tokenize\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenize titles of the articles \n",
    "original_documents = [doc[\"title\"].strip() for _, doc in data.iterrows()]\n",
    "tokenized_documents = preprocess_text(original_documents)\n",
    "documents_topics = list(data.label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.1.1 Create the vocabulary of the articles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_frequency(documents):\n",
    "    \"\"\"\n",
    "    It parses the input documents and creates a dictionary with the terms and term frequencies.\n",
    "    \n",
    "    INPUT:\n",
    "    Doc1: hello hello world\n",
    "    Doc2: hello friend\n",
    "    \n",
    "    OUTPUT:\n",
    "    {'hello': 3,\n",
    "    'world': 1,\n",
    "    'friend': 1}\n",
    "\n",
    "    :param documents: list of list of str, with the tokenized documents.\n",
    "    :return: dict, with keys the words and values the frequency of each word.\n",
    "    \"\"\"\n",
    "    vocabulary = dict()\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for document in documents:\n",
    "        for word in document:\n",
    "            if word in vocabulary:\n",
    "                vocabulary[word] += 1\n",
    "            else:\n",
    "                vocabulary[word] = 1\n",
    "\n",
    "    # --------------\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Vocabulary Size: 8051'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create the vocabulary\n",
    "vocabulary = get_vocabulary_frequency(tokenized_documents)\n",
    "f\"Vocabulary Size: {len(vocabulary)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "us : 308\n"
     ]
    }
   ],
   "source": [
    "# print the most frequent token\n",
    "voc_sorted_keys = sorted(vocabulary, key=vocabulary.get, reverse=True)\n",
    "print(f\"{voc_sorted_keys[0]} : {vocabulary[voc_sorted_keys[0]]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part32'></a>\n",
    "### PART 3.2: Encode documents with Vector Space Retrieval\n",
    "\n",
    "*(3 sub-questions)*\n",
    "\n",
    "In this part, we will encode/vectorize the documents using the **Vector Space Model**. \n",
    "More specifically:\n",
    "- we will compute the term-frequency matrix **(tf)**\n",
    "- we will compute the inverse document frequency **(idf)**\n",
    "- we will vectorize/encode the articles with **tf-idf**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.2.1 Build the term-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(documents, vocabulary):\n",
    "    \"\"\"\n",
    "    It creates the term-frequency matrix with rows the terms of the vocabulary and columns the number of documents.\n",
    "    Each value of the matrix represents the frequency (normalized to document max frequecy) of a term (row) \n",
    "    in a document (column).\n",
    "    Example:\n",
    "    \n",
    "    > INPUT:\n",
    "    documents:\n",
    "    Doc1: hello hello world\n",
    "    Doc2: hello friend\n",
    "    \n",
    "    voc: \n",
    "    [hello, world, friend]\n",
    "    \n",
    "    > OUPUT:    \n",
    "    [[1, 1],\n",
    "    [0.5, 0],\n",
    "    [0, 1]]\n",
    "    \n",
    "    :param documents: list of list of str, with the tokenized documents.\n",
    "    :param vocabulary: dict with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :return: np.array with the document-term frequencies\n",
    "    \"\"\"\n",
    "    document_term_freq = np.zeros(shape=(len(vocabulary), len(documents)))\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    for j, document in enumerate(documents):\n",
    "        counter = Counter(document)\n",
    "        max_count = counter.most_common(1)[0][1]\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in counter:\n",
    "                document_term_freq[i,j] = counter[word] / max_count\n",
    "    # --------------\n",
    "    \n",
    "    return document_term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8051, 6994)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = get_tf(tokenized_documents, vocabulary)\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.2.2 Build the inverse document-frequency matrix (idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute IDF, storing idf values in a dictionary\n",
    "def get_idf(vocabulary, documents):\n",
    "    \"\"\"\n",
    "    It computes IDF scores, storing idf values in a dictionary.\n",
    "    \n",
    "    :param documents: list of list of str, with the tokenized tweets.\n",
    "    :param vocabulary: dict with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :return: dict with the terms as keys and values the idf for each term.\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    idf = dict()\n",
    "    num_documents = len(documents)\n",
    "    for i, term in enumerate(vocabulary):\n",
    "        idf[term] = math.log(num_documents/sum(term in document for document in documents), math.e)\n",
    "    # --------------\n",
    "    return idf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8051"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = get_idf(vocabulary, tokenized_documents)\n",
    "len(idf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.2.3 Vectorization of input with the Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6994, 8051)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Function to generate the vector for a document (with normalisation)\n",
    "def vectorize_vsr(document, vocabulary, idf):\n",
    "    \"\"\"\n",
    "    It takes the input text and vectorizes it based on the tf-idf formula.\n",
    "    \n",
    "    :param document: list of str, with the tokenized document\n",
    "    :param vocabulary: dict, with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :param idf: dict, with the terms as keys and values the idf for each term.\n",
    "    :return: np.array, with the vectorized document\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    term_freq = Counter(document)\n",
    "    max_freq = term_freq.most_common(1)[0][1]\n",
    "    for i, term in enumerate(vocabulary):\n",
    "        vector[i] = idf[term] * term_freq[term]/max_freq\n",
    "    # --------------\n",
    "    return vector\n",
    "    \n",
    "vectorized_documents = np.array([vectorize_vsr(s, vocabulary, idf)  for i, s in enumerate(tokenized_documents)])\n",
    "vectorized_documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part33'></a>\n",
    "### PART 3.3: k-Nearest-Neighbors (kNN)\n",
    "\n",
    "*(7 sub-questions)*\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "> #### 3.3.1 Implement kNN function (finding k nearest documents for a given document)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    \"\"\"\n",
    "    It computes cosine similarity.\n",
    "    \n",
    "    :param v1: list of floats, with the vector of a document.\n",
    "    :param v2: list of floats, with the vector of a document.\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    if sumxy == 0:\n",
    "        sim = 0\n",
    "    else:\n",
    "        sim = sumxy/math.sqrt(sumxx*sumyy)\n",
    "    return sim\n",
    "\n",
    "def euclidean_distance(v1, v2):\n",
    "    \"\"\" It computes the euclidean distance between to vectors.\n",
    "    :param v1: First vector (numpy array).\n",
    "    :param v2: Second vector (numpy array).\n",
    "    :return: Euclidean distance (float)\n",
    "    \"\"\"\n",
    "    return np.linalg.norm(v1 - v2)\n",
    "    \n",
    "def knn(doc_vectors, query_vector, k=10):\n",
    "    \"\"\" It finds the `k` nearest documents to the given query (based on euclidean distance).\n",
    "    :param doc_vectors: An array of document vectors (np.array(np.array)).\n",
    "    :param query_vector: Query representation (np.array)\n",
    "    :return: List of document indices (list(int))\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    dist_scores = [(i, euclidean_distance(np.array(doc), np.array(query_vector))) for i, doc in enumerate(doc_vectors)]\n",
    "    dist_scores = sorted(dist_scores, key=lambda a: a[1])\n",
    "    top_k_docs = [i for i in list(zip(*dist_scores[0:k]))[0]]\n",
    "    # --------------\n",
    "    return top_k_docs\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.2 Print k=10 closests documents to the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 : Microsoft Patches the Patch\n",
      "2 : SpaceShipOne: One down, one to go\n",
      "3 : Oracle, PeopleSoft\n",
      "4 : Olympics: Party, Party, Party - Greece's Parting Gift\n",
      "5 : Oil, stocks both rise\n",
      "6 : Names in the Game\n",
      "7 : Missed target\n",
      "8 : To finish first, first be Finnish\n",
      "9 : Three into two\n",
      "10 : How to keep oil flowing? Invest, invest, invest (AFP)\n"
     ]
    }
   ],
   "source": [
    "query_title = \"Tiny telescope's big discovery opens new doors\" # label = 4\n",
    "\n",
    "query = tokenize(query_title).split()\n",
    "query_vectors = vectorize_vsr(query, vocabulary, idf)\n",
    "\n",
    "top_k_docs = knn(vectorized_documents, query_vectors[0])\n",
    "\n",
    "for k, doc_index in enumerate(top_k_docs):\n",
    "    print(f\"{k+1} : {original_documents[doc_index]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.3 Implement probabilistic and weigting estimation of kNN "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def knn_weighting_estimate(doc_vectors, doc_labels, query_vector, k=10):\n",
    "    \"\"\" Weighting estimation for kNN classification\n",
    "    :param doc_vectors: Document vectors (np.array(np.array))\n",
    "    :param doc_labels: Document labels/topics (list)\n",
    "    :param query_vector: Query vector (np.array)\n",
    "    :param k: Number of nearest neighbors to retrieve\n",
    "    \n",
    "    :return: A dictionary containing the estimation (sorted) score for each label/topic (dict)\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    top_k_doc_indices = knn(doc_vectors, query_vector, k)\n",
    "    top_k_labels = [doc_labels[i] for i in top_k_doc_indices]\n",
    "\n",
    "    scores = {t:0 for t in list(set(doc_labels))}\n",
    "    for i in top_k_doc_indices:\n",
    "        scores[doc_labels[i]] += cosine_similarity(query_vector, doc_vectors[i])\n",
    "    # --------------\n",
    "    return scores\n",
    "\n",
    "def knn_probabilistic_estimate(doc_vectors, doc_labels, query_vector, k=10):\n",
    "    \"\"\" Probabilistic estimation for kNN classification\n",
    "    :param doc_vectors: Document vectors (np.array(np.array))\n",
    "    :param doc_labels: Document labels/topics (list)\n",
    "    :param query_vector: Query vector (np.array)\n",
    "    :param k: Number of nearest neighbors to retrieve\n",
    "    \n",
    "    :return: A dictionary containing the estimation (sorted) score for each label/topic (dict)\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    top_k_doc_indices = knn(doc_vectors, query_vector, k)\n",
    "    top_k_labels = [doc_labels[i] for i in top_k_doc_indices]\n",
    "\n",
    "    scores = {t:0 for t in list(set(doc_labels))}\n",
    "    for i in top_k_doc_indices:\n",
    "        scores[doc_labels[i]] += 1\n",
    "\n",
    "    scores = {t:scores[t] / k for t in scores}\n",
    "    # --------------\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.4 Compute weighting and probabilistic estimation of the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query: (\"Airlines Agree to Cut Flights at Chicago O'Hare\", 3)\n",
      "Weighting estimate: [(3, 0.40466850242282926), (1, 0), (2, 0), (4, 0)]\n",
      "Probabilistic estimate: [(2, 0.4), (3, 0.4), (4, 0.2), (1, 0.0)]\n",
      "*************************************************\n",
      "\n",
      "Query: ('Stuttgart Closing on Qualification', 2)\n",
      "Weighting estimate: [(3, 0.2870546649144036), (2, 0.266082291031066), (4, 0.26170928796986676), (1, 0)]\n",
      "Probabilistic estimate: [(2, 0.4), (3, 0.3), (4, 0.3), (1, 0.0)]\n",
      "*************************************************\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# query_titles = [(\"Hundreds laid off at Fleet offices\", 3), (\"Stuttgart Closing on Qualification\", 2), (\"Shoppach doesn't appear ready to hit the next level\", 2)]\n",
    "query_titles = [(\"Airlines Agree to Cut Flights at Chicago O'Hare\", 3), (\"Stuttgart Closing on Qualification\", 2)]\n",
    "# query_titles = [(\"After Wait, Google Set for Market Debut\", 3), (\"Stuttgart Closing on Qualification\", 2)]\n",
    "# query_titles = [(\"Republican Convention Light on Stars\", 1)]\n",
    "queries = [tokenize(q[0]).split() for q in query_titles] \n",
    "query_vectors = [vectorize_vsr(q, vocabulary, idf) for q in queries]\n",
    "k = 10\n",
    "\n",
    "for i, query_v in enumerate(query_vectors):\n",
    "    print(f\"Query: {query_titles[i]}\")\n",
    "    w_estimate = knn_weighting_estimate(vectorized_documents, documents_topics, query_v, k)\n",
    "    w_estimate = sorted(w_estimate.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Weighting estimate: {w_estimate}\")\n",
    "   \n",
    "    prob_estimate = knn_probabilistic_estimate(vectorized_documents, documents_topics, query_v, k)\n",
    "    prob_estimate = sorted(prob_estimate.items(), key=lambda x: x[1], reverse=True)\n",
    "    print(f\"Probabilistic estimate: {prob_estimate}\")\n",
    "\n",
    "    print(\"*************************************************\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.5 Compute weighting and probabilistic estimation of the given query for different values of `k`:\n",
    "\n",
    "Discuss the changes in the results by increasing the value of `k`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k: 1, w_label = 1, p_label: 4\n",
      "k: 5, w_label = 3, p_label: 3\n",
      "k: 10, w_label = 3, p_label: 2\n",
      "k: 15, w_label = 3, p_label: 3\n",
      "k: 20, w_label = 3, p_label: 3\n"
     ]
    }
   ],
   "source": [
    "# KNN estimation for different values of k (first query)\n",
    "for k in [1, 5, 10, 15, 20]:\n",
    "    w_estimate = knn_weighting_estimate(vectorized_documents, documents_topics, query_vectors[0], k)\n",
    "    w_estimate = sorted(w_estimate.items(), key=lambda x: x[1], reverse=True)\n",
    "    w_label = w_estimate[0][0]\n",
    "\n",
    "    prob_estimate = knn_probabilistic_estimate(vectorized_documents, documents_topics, query_vectors[0], k)\n",
    "    prob_estimate = sorted(prob_estimate.items(), key=lambda x: x[1], reverse=True)\n",
    "    p_label = prob_estimate[0][0]\n",
    "\n",
    "    print(f\"k: {k}, w_label = {w_label}, p_label: {p_label}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.6 Implement a Rocchio classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rocchio_estimate(doc_vectors, doc_labels, query_vector):\n",
    "    \"\"\" \n",
    "    Rocchio classification\n",
    "    :param doc_vectors: Document vectors (np.array(np.array))\n",
    "    :param doc_labels: Document labels/topics (list)\n",
    "    :param query_vector: Query vector (np.array)\n",
    "    \n",
    "    :return: A dictionary containing the estimation score for each label/topic (dict)\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    topic_to_doc = {t:[] for t in list(set(doc_labels))}\n",
    "    for i, doc in enumerate(doc_vectors):\n",
    "        topic_to_doc[doc_labels[i]].append(np.array(doc))\n",
    "\n",
    "    centroids = {t:sum(topic_to_doc[t]) / len(topic_to_doc[t]) for t in topic_to_doc}\n",
    "    scores = {t:euclidean_distance(centroids[t], query_vector) for t in centroids}\n",
    "    # --------------\n",
    "    return scores\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.3.7 Compute Rocchio estimation of the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rocchio estimate: [(3, 13.007451557333788), (4, 13.07197927312842), (2, 13.084889489152548), (1, 13.08623713524477)]\n"
     ]
    }
   ],
   "source": [
    "roc_estimate = rocchio_estimate(vectorized_documents, documents_topics, query_vectors[0])\n",
    "roc_estimate = sorted(roc_estimate.items(), key=lambda x: x[1])\n",
    "print(f\"Rocchio estimate: {roc_estimate}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part34'></a>\n",
    "### PART 3.4: Naive Bayes Classifier\n",
    "\n",
    "*(2 sub-questions)*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Classifier\n",
    "def get_topic_tf(doc_vectors, doc_labels, vocabulary):\n",
    "    \"\"\" It computes term frequency for each topic/label\n",
    "    :param doc_vectors: Document vectors (np.array(np.array))\n",
    "    :param doc_labels: Document labels/topics (list)\n",
    "    :vocabulary: A dictionary, with keys the words and values the frequency of each word.\n",
    "    :return: A dictionary, with keys the topics/labels and values a dictionary of word frequencies  \n",
    "    \"\"\"\n",
    "    topic_term_freq = {t:{w:0 for w in vocabulary} for t in list(set(doc_labels))}\n",
    "    for i, doc in enumerate(doc_vectors):\n",
    "        counter = Counter(doc)\n",
    "        for word in vocabulary:\n",
    "            if word in counter:\n",
    "                topic_term_freq[doc_labels[i]][word] += counter[word]\n",
    "    return topic_term_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.4.1 Compute the Naive Bayes estimation for the given query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def navie_bayes_classifier(tf_dict, query, topics_probs):\n",
    "    \"\"\" Naive Bayes classification\n",
    "    :param tf_dict: A dictionary, with keys the topics/labels and values a dictionary of word frequencies  \n",
    "    :param query: Query vector\n",
    "    :param topics_probs: Probaility distribution of each topic/label (dict)\n",
    "    :return: A dictionary containing the log probability estimation for each topic\n",
    "    \"\"\"\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    log_probabilities = {t:0 for t in tf_dict}\n",
    "    for topic in tf_dict:\n",
    "        prob = 0\n",
    "        for word in query:\n",
    "            if word in tf_dict[topic]: \n",
    "                pw = (tf_dict[topic][word] + 1) / (sum([tf_dict[t][word] for t in tf_dict]) + 1)\n",
    "                prob += math.log(pw)\n",
    "\n",
    "        prob += math.log(topics_probs[topic])\n",
    "        log_probabilities[topic] = prob\n",
    "    # --------------\n",
    "    return log_probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Naive Bayes Estimation: [(3, -4.8294503149491845), (4, -9.900134971426137), (1, -10.153488856666009), (2, -12.556024509020881)]\n"
     ]
    }
   ],
   "source": [
    "# Compute the probability distribution of topics/labels\n",
    "topics_freq = Counter(documents_topics)\n",
    "topics_probs = {t:topics_freq[t]/len(documents_topics) for t in topics_freq}\n",
    "# Compute word frequency per topic\n",
    "tf_dict = get_topic_tf(tokenized_documents, documents_topics, vocabulary)\n",
    "\n",
    "nb_estimation = navie_bayes_classifier(tf_dict, queries[0], topics_probs)\n",
    "nb_estimation = sorted(nb_estimation.items(), key=lambda x: x[1], reverse=True)\n",
    "print(f\"Naive Bayes Estimation: {nb_estimation}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.4.2 Discuss the difference the above classifers:\n",
    "1. Which kNN classifer is more accurate? Weighting or probabilistic estimation? Why?\n",
    "2. What is the difference between Rocchio and kNN classification?\n",
    "3. When Naive Bayes is prefered over kNN? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part35'></a>\n",
    "### PART 3.5: Association Rules\n",
    "*(3 sub-questions)*\n",
    "\n",
    "Now we would like to identify frequent rules that govern how words appear together in the news article **titles**.\n",
    "\n",
    "Using the `tokenized_documents` provided before and by considering the pair of words containing _\"microsoft\"_ (we only consider rules of size 2) do the following:\n",
    "\n",
    "* Compute **support** and **confidence** for the rules `microsoft` -> `X`, where X is a word appearing with microsoft in the title of an article.\n",
    "* From the confidence of the rules you obtained, compute **lift**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.5.1 Compute support and confidence for the rules `microsoft` -> `X`, where X is a word appearing with microsoft in the title of an article.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# support    = {}\n",
    "# confidence = {}\n",
    "import copy \n",
    "\n",
    "# find documents that 'microsoft' appears\n",
    "docs_with_microsoft = list()\n",
    "for document in tokenized_documents:\n",
    "    if 'microsoft' in document:\n",
    "        docs_with_microsoft.append(document)\n",
    "        \n",
    "# find the frequency of word 'microsoft'\n",
    "frequency_of_microsoft = len(docs_with_microsoft)\n",
    "\n",
    "#copy vocabulary (to leave the original intact) and remove the microsoft frequency\n",
    "vocabulary_c = copy.deepcopy(vocabulary)\n",
    "vocabulary_c.pop('microsoft')\n",
    "\n",
    "# compute support and confidence for each word in vocabulary\n",
    "support = dict()\n",
    "confidence = dict()\n",
    "for word in vocabulary_c:\n",
    "    frequency_of_microsoft_x = 0\n",
    "    for document in docs_with_microsoft:\n",
    "        if word in document:\n",
    "            frequency_of_microsoft_x += 1\n",
    "    \n",
    "    support[word] = frequency_of_microsoft_x / len(tokenized_documents)\n",
    "    confidence[word] = frequency_of_microsoft_x / frequency_of_microsoft\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **3.5.2 From the confidence of the rules you obtained, compute lift.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------\n",
    "# YOUR CODE HERE\n",
    "\n",
    "# Compute the lift\n",
    "lift = dict()\n",
    "for word in vocabulary_c:\n",
    "    lift[word] = confidence[word] / (vocabulary[word] / len(tokenized_documents))\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': 0.0014297969688304261,\n",
       " 'window': 0.0012868172719473834,\n",
       " 'music': 0.0012868172719473834}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 3 rules with highest support\n",
    "{k: v for k, v in sorted(support.items(), key=lambda item: item[1], reverse=True)[:3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'search': 0.06493506493506493,\n",
       " 'window': 0.05844155844155844,\n",
       " 'music': 0.05844155844155844}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 3 rules with highest confidence\n",
    "{k: v for k, v in sorted(confidence.items(), key=lambda item: item[1], reverse=True)[:3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'hotmail': 45.41558441558441,\n",
       " '2003': 45.41558441558441,\n",
       " 'beta': 45.41558441558441}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Show the 3 rules with highest lift\n",
    "{k: v for k, v in sorted(lift.items(), key=lambda item: item[1], reverse=True)[:3]}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîö END OF EXAM\n",
    "> Don't forget to change the submitted file with your SciperNo as the file name before submitting.\n",
    "\n",
    "<a id='submit'></a>\n",
    "#### [SUBMIT HERE](https://moodle.epfl.ch/mod/quiz/view.php?id=1235303)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üìò DIS Midterm - Fall 2022\n",
    "\n",
    "**üéâ Welcome to DIS Midterm that takes place on the 27th of Octomber 2022 from 12:15 to 13:00.**\n",
    "\n",
    "> Please fill the following info:\n",
    "> - Your Name: \n",
    "> - Your SCIPER:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### üí° THE BACKSTORY\n",
    "\n",
    "You are an engineer working in the sports news articles website: _allaboutsports.ch_ . The editors' team of this news portal wants to create a piece for the upcoming Summer Olympic Games for the swimming Olympic medalist Katie Ledecky. To do so, they want to collect information not only from the news coverage but also from what is being said about her on social media. Therefore, you are using the Twitter data that have have the hashtag of _#allaboutsportsch_ news portal to find relevant to the athlete tweets that will help the editors.\n",
    "\n",
    "\n",
    "### üê¶ THE DATA\n",
    "\n",
    "The collected tweets are stored into the `allaboutsports_tweets.csv` which contains the following columns:\n",
    "\n",
    "| Column     | Description                   |\n",
    "|------------|-------------------------------|\n",
    "| **id**     | The id of the tweet           |\n",
    "| **tweet**  | The text/content of the tweet |\n",
    "| **relevant**  | Gold labels for retrieval model evaluation in Part 5 |\n",
    "\n",
    "\n",
    "### ‚úÖ THE TASK\n",
    "\n",
    "Build a retrieval system that searches the tweets and retrieve the ones that talk about Katie Ledecky.\n",
    "\n",
    "You will test a Vector Space retrieval model and a Probabilistic model, and you will compare their results & performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Answer all the parts of the midterm:\n",
    "\n",
    "- [PART 0: Rename your notebook with your SciperNo](#part0)\n",
    "\n",
    "- [PART 1: Parse and understand the data](#part1)\n",
    "    - 1.1 Create the vocabulary of the documents/tweets\n",
    "    - 1.2 Print the 5 most frequent words present in the tweets\n",
    "\n",
    "- [PART 2: Encode documents with Vector Space Retrieval](#part2)\n",
    "    - 2.1 Build the document-frequency matrix.\n",
    "    - 2.2 Build the inverse document-frequency matrix\n",
    "    - 2.3 Vectorize input with Vector Space Model\n",
    "    \n",
    "- [PART 3: Encode documents with Probabilistic Retrieval](#part3)\n",
    "    - 3.1 Compute collection probabilities for each document\n",
    "    - 3.2 Implement query-document likelohood\n",
    "\n",
    "- [PART 4: Retrieve documents](#part4)\n",
    "    - 4.1 Retrieve documents with Vector Space Retrieval \n",
    "    - 4.2 Retrieve documents with Probabilistic retrieval\n",
    "\n",
    "- [PART 5: Evaluate your retrieval system](#part5)\n",
    "    - 5.1 Discuss the precision and recall between the Vector Space and Probabilistic Retrieval\n",
    "    - 5.2 Explain the role of k in retrieval performance\n",
    "    - 5.3 Explain the role of lambda in the Probabilistic retrieval performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# üçÄ GOOD LUCK üçÄ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part0'></a>\n",
    "## PART 0: Rename your notebook with your SciperNo\n",
    "\n",
    "The final sumbitted file should have the following name: `SciperNo.ipynb`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part1'></a>\n",
    "## PART 1: Parse and understand the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romanou/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/romanou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import libraries- you can additionally import any library you want.\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from collections import Counter\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import operator\n",
    "from functools import reduce\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Utility functions - Nothing to change here.\n",
    "stemmer = PorterStemmer()\n",
    "def tokenize(text):\n",
    "    text = \"\".join([ch for ch in text if ch not in string.punctuation])\n",
    "    tokens = nltk.word_tokenize(text)\n",
    "    return [word.lower() for word in tokens if word not in stopwords.words('english')]\n",
    "\n",
    "def preprocess_text(documents):\n",
    "    docs = list()\n",
    "    for doc in documents:\n",
    "        docs.append(tokenize(doc))  # tokenize\n",
    "    return docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read the data\n",
    "tweets = pd.read_csv('allaboutsports_tweets.csv')\n",
    "\n",
    "# Clean the data\n",
    "tweets['clean_tweet'] = preprocess_text(tweets['tweet'].tolist())\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 1.1 Create the vocabulary of the documents/tweets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabulary_frequency(documents):\n",
    "    \"\"\"\n",
    "    It parses the input documents and creates a dictionary with the terms and term frequencies.\n",
    "    \n",
    "    INPUT:\n",
    "    Doc1: hello hello world\n",
    "    Doc2: hello friend\n",
    "    \n",
    "    OUTPUT:\n",
    "    {'hello': 2,\n",
    "    'world': 1,\n",
    "    'friend': 1}\n",
    "\n",
    "    :param documents: list of list of str, with the tokenized tweets.\n",
    "    :return: dict, with keys the words and values the frequency of each word.\n",
    "    \"\"\"\n",
    "    vocabulary = dict()\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    for document in documents:\n",
    "        for word in document:\n",
    "            if word in vocabulary:\n",
    "                vocabulary[word] += 1\n",
    "            else:\n",
    "                vocabulary[word] = 1\n",
    "\n",
    "    # --------------\n",
    "    return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "voc = get_vocabulary_frequency(tweets['clean_tweet'].tolist())\n",
    "len(voc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 1.2 Print the 5 most frequent words present in the tweets.\n",
    "> Use the vocabulary frequencies you created in the previous question to find the top-5 words/terms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>frequency</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>allaboutsportsch</td>\n",
       "      <td>50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>federer</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>roger</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>olympic</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>paris</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               term  frequency\n",
       "0  allaboutsportsch         50\n",
       "1           federer         18\n",
       "2             roger         15\n",
       "3           olympic         10\n",
       "4             paris          9"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# --------------\n",
    "# YOUR CODE HERE\n",
    "\n",
    "pd.DataFrame(list(reversed(sorted(voc.items(), key=lambda item: item[1]))), columns=['term', 'frequency'])[:5]\n",
    "\n",
    "# --------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part2'></a>\n",
    "## PART 2: Encode documents with Vector Space Retrieval\n",
    "\n",
    "In this part we will encode/vectorize the documents using the **Vector Space Model**. \n",
    "More specifically:\n",
    "- we will compute the term-frequency matrix **(tf)**\n",
    "- we will compute the inverse document frequency **(idf)**\n",
    "- we will vectorize/encode the tweets with **tf-idf**\n",
    "- we will implement the **cosine similarity**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 2.1 Build the term-frequency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tf(documents, vocabulary):\n",
    "    \"\"\"\n",
    "    It creates the term-frequency matrix with rows the terms of the vocabulary and columns the number of documents.\n",
    "    Each value of the matrix represents the frequency (normalized to document max frequecy) of a term (row) in a document (column).\n",
    "    Example:\n",
    "    \n",
    "    > INPUT:\n",
    "    documents:\n",
    "    Doc1: hello hello world\n",
    "    Doc2: hello friend\n",
    "    \n",
    "    voc: \n",
    "    [hello, world, friend]\n",
    "    \n",
    "    > OUPUT:    \n",
    "    [[1, 1],\n",
    "    [0.5, 0],\n",
    "    [0, 1]]\n",
    "    \n",
    "    :param documents: list of list of str, with the tokenized tweets.\n",
    "    :param vocabulary: dict with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :return: np.array with the document-term frequencies\n",
    "    \"\"\"\n",
    "    document_term_freq = np.zeros(shape=(len(vocabulary), len(documents)))\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    for j, document in enumerate(documents):\n",
    "        counter = Counter(document)\n",
    "        max_count = counter.most_common(1)[0][1]\n",
    "        for i, word in enumerate(vocabulary):\n",
    "            if word in counter:\n",
    "                document_term_freq[i,j] = counter[word] / max_count\n",
    "    # --------------\n",
    "    \n",
    "    return document_term_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(412, 50)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf = get_tf(tweets['clean_tweet'].tolist(), voc)\n",
    "tf.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 2.2 Build the inverse document-frequency matrix (idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_idf(documents, vocabulary):\n",
    "    \"\"\"\n",
    "    It computes IDF scores, storing idf values in a dictionary.\n",
    "    \n",
    "    :param documents: list of list of str, with the tokenized tweets.\n",
    "    :param vocabulary: dict with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :return: dict with the terms as keys and values the idf for each term.\n",
    "    \"\"\"\n",
    "    idf = dict()\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    num_documents = len(documents)\n",
    "    for i, term in enumerate(vocabulary):\n",
    "        idf[term] = math.log(num_documents/sum(term in document for document in documents), math.e)\n",
    "    # --------------\n",
    "    return idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf = get_idf(tweets['clean_tweet'].tolist(), voc)\n",
    "len(idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.120263536200091"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idf['katie']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorization of input with the Vector Space Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_vsr(document, vocabulary, idf):\n",
    "    \"\"\"\n",
    "    It takes the input text and vectorizes it based on the tf-idf formula.\n",
    "    \n",
    "    :param document: list of str, with the tokenized tweet\n",
    "    :param vocabulary: dict, with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :param idf: dict, with the terms as keys and values the idf for each term.\n",
    "    :return: np.array, with the vectorized tweet\n",
    "    \"\"\"\n",
    "    vector = np.zeros(len(vocabulary))\n",
    "    term_freq = Counter(document)\n",
    "    max_freq = term_freq.most_common(1)[0][1]\n",
    "    for i, term in enumerate(vocabulary):\n",
    "        vector[i] = idf[term] * term_freq[term]/max_freq\n",
    "    return vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 412)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorized_documents = np.array([vectorize_vsr(doc, voc, idf) for doc in tweets['clean_tweet'].tolist()])\n",
    "vectorized_documents.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity for Vector Space Retrieval "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(v1,v2):\n",
    "    \"\"\"\n",
    "    It computes cosine similarity.\n",
    "    \n",
    "    :param v1: list of floats, with the vector of a document.\n",
    "    :param v2: list of floats, with the vector of a document.\n",
    "    :return: float\n",
    "    \"\"\"\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    if sumxy == 0:\n",
    "        sim = 0\n",
    "    else:\n",
    "        sim = sumxy/math.sqrt(sumxx*sumyy)\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part3'></a>\n",
    "## PART 3: Encode documents with Probabilistic Retrieval\n",
    "\n",
    "In this part we will encode/vectorize the documents using the **Probabilistic Model**. \n",
    "More specifically:\n",
    "- we will compute the collection probabilities for each term **($P(t|M_c)$)**\n",
    "- we will copute the query-document likelihood **$P(t_i|document)$** for each query term $t_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.1 Compute collection probabilities $P(t|M_c$) for each document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_collection_prob(vocabulary):\n",
    "    \"\"\"\n",
    "    Computes the collection probabilities of each term present in the documents/tweets.\n",
    "    \n",
    "    :param vocabulary: dict with the vocabulary (computed in 1.1) and each term's frequency.\n",
    "    :return: dict with the collection probabilities for each term in the vocabulary.\n",
    "    \"\"\"\n",
    "    probs = dict()\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    for term in vocabulary:\n",
    "        probs[term] = vocabulary[term] / sum(vocabulary.values())\n",
    "    # --------------\n",
    "    return probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "412"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_Mc = get_collection_prob(voc)\n",
    "len(p_Mc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 3.2 Implement query-document likelihood $P(q|doc)$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_query_likelihood(query, document, p_Mc, l):\n",
    "    \"\"\"\n",
    "    It computes the probability of a query given a document/tweet.\n",
    "    \n",
    "    :param query: np.array with the tokenized query\n",
    "    :param document: np.array with the tokenized document\n",
    "    :param p_Mc: dict with the collection probabilities for each term in the vocabulary.\n",
    "    :param l: float, smoothing variable lambda.    \n",
    "    :return: float with the query-document likelihood\n",
    "    \"\"\"\n",
    "\n",
    "    # --------------\n",
    "    # YOUR CODE HERE\n",
    "    term_probs = list()\n",
    "    counter = Counter(document)\n",
    "    for i, word in enumerate(query):\n",
    "        # term_doc_prob: P(t|Doc) = lambda * p_Md + (1-lambda) * p_Mc\n",
    "        term_probs.append(l * (counter[word] / len(document)) + ((1-l) * p_Mc.get(word,0)))\n",
    "\n",
    "    # prob = 0 if len(term_probs) == 0 else math.prod(term_probs)  # works on python 3.8\n",
    "    prob = 0 if len(term_probs) == 0 else reduce(operator.mul, term_probs, 1)\n",
    "    # --------------\n",
    "    return prob\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part4'></a>\n",
    "## PART 4: Retrieve documents\n",
    "\n",
    "In this part, we will apply both **Vector Space Retrieval** and **Probabilistic retrieval** in order to get the relevant tweets to Katie Ledecky athlete. \n",
    "\n",
    "There is nothing to implement in this part, however, you should run the following cells and test your implementation in Parts 2&3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = [\"katie\",\"ledecky\",\"athlete\"]\n",
    "doc_ids = tweets['id'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieves with Vector Space Retrieval for `query = \"Katie Ledecky\"` and prints the top 10 relevant documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vectorize query and tweets\n",
    "vectorized_documents_vsr =  np.array([vectorize_vsr(doc, voc, idf) for doc in tweets['clean_tweet'].tolist()])\n",
    "vectorized_query_vsr = np.array(vectorize_vsr(query, voc, idf))\n",
    "\n",
    "# performs vector space retrieval\n",
    "scores = dict()\n",
    "for idx, doc_vec in zip(doc_ids, vectorized_documents_vsr):\n",
    "    scores[idx] = cosine_similarity(doc_vec, vectorized_query_vsr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.578184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.319205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0.305536</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.295565</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>0.282030</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>0.203919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>0.186898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>45</td>\n",
       "      <td>0.138721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>12</td>\n",
       "      <td>0.118039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     score\n",
       "0   1  0.578184\n",
       "1   4  0.319205\n",
       "2   2  0.305536\n",
       "3   6  0.295565\n",
       "4   5  0.282030\n",
       "5   3  0.203919\n",
       "6   7  0.186898\n",
       "7  45  0.138721\n",
       "8  12  0.118039\n",
       "9  50  0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top 5 retrieved tweets\n",
    "retrieved_tweets_vsr = pd.DataFrame(list(reversed(sorted(scores.items(), key=lambda item: item[1]))),\n",
    "                                    columns=['id', 'score'])\n",
    "retrieved_tweets_vsr[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Retrieve with Probabilistic Retrieval for `query = \"Katie Ledecky\"` and prints the top 10 relevant along with their probability (score)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performs probabilistic retrieval\n",
    "probs = dict()\n",
    "for idx, doc in zip(doc_ids, tweets['clean_tweet'].tolist()):\n",
    "    probs[idx] = compute_query_likelihood(query, doc,  p_Mc, 0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>0.035059</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>45</td>\n",
       "      <td>0.028115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>0.028115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0.002260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>0.001855</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>0.001544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0.001194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>50</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id     score\n",
       "0   7  0.035059\n",
       "1  45  0.028115\n",
       "2  12  0.028115\n",
       "3   6  0.002260\n",
       "4   2  0.002260\n",
       "5   4  0.001855\n",
       "6   5  0.001544\n",
       "7   3  0.001194\n",
       "8   1  0.000140\n",
       "9  50  0.000000"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print top 5 retrieved tweets\n",
    "retrieved_tweets_prob = pd.DataFrame(list(reversed(sorted(probs.items(), key=lambda item: item[1]))),\n",
    "                                     columns=['id', 'score'])\n",
    "retrieved_tweets_prob[:10]            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='part5'></a>\n",
    "## PART 5: Evaluate retrieval\n",
    "\n",
    "In this part, we will evaluate both retrieval systems and discuss the impact of lambda value as well as the number of retrieved documents.\n",
    "\n",
    "We are now going to use the column `'relevant'` in the dataset. It is referring to whether the tweet is relevant to the query or not. We define this column as the 'oracle' that in an ideal scenario knows which tweets are relevant for Katie Ledecky and which are not.\n",
    "Based on this, we will compute the performance of the retrieval systems we built. üéâ"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Precision@k & Recall@k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_precision_at_k(retrieved_tweets, gt, k=5):\n",
    "    \"\"\"\n",
    "    It computes the precision score at a defined set of retrieved documents (k).\n",
    "    \n",
    "    :param predict: list of predictions\n",
    "    :param gt: list of actual relevant data\n",
    "    :param k: int\n",
    "    :return: float, the precision at a given k\n",
    "    \"\"\"\n",
    "    results = retrieved_tweets.merge(gt, how=\"outer\", on=\"id\")\n",
    "    return np.array(results[:k]['relevant'].tolist()).mean()\n",
    "\n",
    "def compute_recall_at_k(retrieved_tweets, gt, k=5):\n",
    "    \"\"\"\n",
    "    It computes the recall score at a defined set of retrieved documents (k).\n",
    "    \n",
    "    :param predict: list of predictions\n",
    "    :param gt: list of actual relevant data\n",
    "    :param k: int\n",
    "    :return: float, the precision at a given k\n",
    "    \"\"\"\n",
    "    relevant = len(tweets[tweets['relevant']==1])\n",
    "    results = retrieved_tweets.merge(gt, how=\"outer\", on=\"id\")[:k]\n",
    "    hits = len(results[results['relevant']==1])\n",
    "    return hits / relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 5.1 Discuss the difference in performance between the Vector Space and Probabilistic Retrieval based on the Precision and Recall scores in the provided table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Precision@5</th>\n",
       "      <th>Recall@5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>Vector Space Retrieval</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.833</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>Probabilistic Retrieval</td>\n",
       "      <td>0.4</td>\n",
       "      <td>0.333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Model  Precision@5  Recall@5\n",
       "0   Vector Space Retrieval          1.0     0.833\n",
       "1  Probabilistic Retrieval          0.4     0.333"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vsr_precision = compute_precision_at_k(retrieved_tweets_vsr, tweets[['id', 'relevant']], 5)\n",
    "prob_precision = compute_precision_at_k(retrieved_tweets_prob, tweets[['id', 'relevant']], 5)\n",
    "\n",
    "vsr_recall = compute_recall_at_k(retrieved_tweets_vsr, tweets[['id', 'relevant']], 5)\n",
    "prob_recall = compute_recall_at_k(retrieved_tweets_prob, tweets[['id', 'relevant']], 5)\n",
    "\n",
    "pd.DataFrame([('Vector Space Retrieval', vsr_precision, vsr_recall),\n",
    "              ('Probabilistic Retrieval',prob_precision, prob_recall)], \n",
    "             columns=['Model', 'Precision@5', 'Recall@5']).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "\n",
    "|"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 5.2 Discuss the following plot regarding the impact of the $k$ variable in the Precision@k metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "ks = [1, 5, 10, 15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x1434fb898>"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# run Probabilistic Retrieval and evaluate it on different k\n",
    "res = list()\n",
    "for k in ks:\n",
    "    res.append({'Precision': compute_precision_at_k(retrieved_tweets_prob, tweets[['id', 'relevant']], k),\n",
    "                'k': k})\n",
    "res_df = pd.DataFrame(res)\n",
    "sns.relplot(data=res_df, x=\"k\", y=\"Precision\", kind=\"line\").set(title='Precision@k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "|\n",
    "\n",
    "|\n",
    "The more documents we retrieve, the more unrelated/irrelevant ones we will get too, and therefore the precision@k will be decreased at some point.\n",
    "\n",
    "_Extra note: When it comes to the recall@k case which takes into account all the relevant docs, the more documents we retrieve the more relevant to the query documents we will have._\n",
    "\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> #### 5.3 Discuss the following plot regarding the impact of the $\\lambda$ (lambda) in the query-document likelihood probability $P(q|Doc)$.\n",
    "\n",
    "In this example we estimate the likehood for a given query and a given tweet (see below). The $P(t|M_c)$ values are the same as in the rest of the notebook and are calculated based on the whole document collection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The query: \"katie ledecky swimmer\"\"\n",
      "Tweet: \"Is Katie Ledecky competing in the 2024 Paris Olympics? #allaboutsportsch\"\n"
     ]
    }
   ],
   "source": [
    "new_query = [\"katie\",\"ledecky\",\"swimmer\"]\n",
    "a_document= tweets['clean_tweet'].tolist()[3]\n",
    "\n",
    "print('The query: \"{}\"\"'.format(' '.join(new_query)))\n",
    "print('Tweet: \"{}\"'.format(tweets['tweet'].tolist()[3]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Likelihood  lambda\n",
      "0    0.000247    0.00\n",
      "1    0.001855    0.25\n",
      "2    0.004954    0.50\n",
      "3    0.009544    0.75\n",
      "4    0.015625    1.00\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<seaborn.axisgrid.FacetGrid at 0x14365d518>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# for each lambda get the query-document likehood estimation.\n",
    "lambdas = [0, 0.25, 0.5, 0.75, 1]\n",
    "probabilities = list()\n",
    "for l in lambdas:\n",
    "    probabilities.append({'Likelihood': compute_query_likelihood(new_query, a_document,  p_Mc, l),\n",
    "                         'lambda': l})\n",
    "\n",
    "res_df = pd.DataFrame(probabilities)\n",
    "print(res_df)\n",
    "sns.relplot(data=res_df, x=\"lambda\", y=\"Likelihood\", \n",
    "            kind=\"line\").set(title='Likelihood of a document on different Lambda values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**‚û°Ô∏è PLEASE WRITE YOUR ANSWER HERE**\n",
    "\n",
    "|\n",
    "\n",
    "Answer:\n",
    "By increasing the value of lambda, we more focus on the term frequency of the given document, while by decreasing the value we give more weight on the term distribution in the whole corpus.\n",
    "\n",
    "|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## üîö END OF EXAM\n",
    "> Don't forget to change the submitted file with your SciperNo as the file name before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Distributed-Information-Systems\" data-toc-modified-id=\"Distributed-Information-Systems-0\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Distributed Information Systems</a></span></li><li><span><a href=\"#Word-Representation-for-Concept-Identification\" data-toc-modified-id=\"Word-Representation-for-Concept-Identification-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Word Representation for Concept Identification</a></span><ul class=\"toc-item\"><li><span><a href=\"#Build-the-vocabulary-by-selecting-top-k-frequent-words\" data-toc-modified-id=\"Build-the-vocabulary-by-selecting-top-k-frequent-words-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Build the vocabulary by selecting top-k frequent words</a></span></li><li><span><a href=\"#Construct-the-word-cooccurence-matrix\" data-toc-modified-id=\"Construct-the-word-cooccurence-matrix-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Construct the word cooccurence matrix</a></span></li><li><span><a href=\"#Perform-SVD-on-the-matrix-and-select-the-largest-singular-values\" data-toc-modified-id=\"Perform-SVD-on-the-matrix-and-select-the-largest-singular-values-2.3\"><span class=\"toc-item-num\">2.3&nbsp;&nbsp;</span>Perform SVD on the matrix and select the largest singular values</a></span></li></ul></li><li><span><a href=\"#Vector-based-retrieval-using-Word-representations\" data-toc-modified-id=\"Vector-based-retrieval-using-Word-representations-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Vector-based retrieval using Word representations</a></span><ul class=\"toc-item\"><li><span><a href=\"#Document-and-query-vectors-from-word-representations\" data-toc-modified-id=\"Document-and-query-vectors-from-word-representations-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Document and query vectors from word representations</a></span></li><li><span><a href=\"#Retrieve-top-10-relevant-documents\" data-toc-modified-id=\"Retrieve-top-10-relevant-documents-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Retrieve top-10 relevant documents</a></span></li></ul></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Evaluate-retrieval-result-using-DCG\" data-toc-modified-id=\"Evaluate-retrieval-result-using-DCG-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Evaluate retrieval result using DCG</a></span></li><li><span><a href=\"#Explain-the-DCG-values-plot\" data-toc-modified-id=\"Explain-the-DCG-values-plot-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Explain the DCG values plot</a></span></li></ul></li><li><span><a href=\"#Submit-your-notebook\" data-toc-modified-id=\"Submit-your-notebook-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Submit your notebook</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Distributed Information Systems\n",
    "***Midterm Exam, Fall-Winter Semester 2021-22***\n",
    "\n",
    "The following materials are allowed: exercise sheets and solutions, past exams with your own solution, personally written notes and personally collected documentation.\n",
    "\n",
    "The exam will be held on your computer, but digital communication by any means is strictly prohibited. \n",
    "By participating to this exam you agree to these conditions.\n",
    "\n",
    "These are the instructions for the exam:\n",
    "\n",
    "1. You are not allowed to leave the examination room in the first 20 and the last 15 minutes of the exam.\n",
    "* We will publish 15 minutes before the end of the exam a password for uploading your solutions on Moodle.\n",
    "* It is not recommended to leave the exam before the password is published. If you need to leave earlier, contact us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/romanou/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/romanou/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "#Required libraries\n",
    "import math\n",
    "import os\n",
    "import string\n",
    "from collections import defaultdict\n",
    "from operator import itemgetter\n",
    "from pprint import pprint\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import nltk\n",
    "import numpy as np\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer, word_tokenize\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english')).union(set(stopwords.words('french')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus():\n",
    "    '''Reads corpus from files.'''\n",
    "    \n",
    "    documents = []\n",
    "    orig_docs = []\n",
    "    DIR = './'\n",
    "    tknzr = TweetTokenizer()\n",
    "    with open(\"epfldocs.txt\", encoding = \"utf-8\") as f:\n",
    "        content = f.readlines()\n",
    "    for text in content:\n",
    "        orig_docs.append(text)\n",
    "        # split into words\n",
    "        tokens = tknzr.tokenize(text)\n",
    "        # convert to lower case\n",
    "        tokens = [w.lower() for w in tokens]\n",
    "        # remove punctuation from each word\n",
    "        table = str.maketrans('', '', string.punctuation)\n",
    "        stripped = [w.translate(table) for w in tokens]\n",
    "        # remove remaining tokens that are not alphabetic\n",
    "        words = [word for word in stripped if word.isalpha()]\n",
    "        # filter out stop words\n",
    "        words = [w for w in words if not w in stop_words]\n",
    "\n",
    "        documents.append(' '.join(words))\n",
    "    return documents, orig_docs\n",
    "\n",
    "documents, orig_docs = read_corpus()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert(len(documents) == 1075)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Representation for Concept Identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will build word representations in a latent concept space using SVD. Differently to Latent Semantic Indexing (LSI) we will derive the latent concepts space from the **word co-occurrence matrix** (and not from the term-document matrix, as in standard LSI).\n",
    "\n",
    "An entry (i,j) in the word co-occurrence matrix corresponds to the number of times the word i co-occurs with the word j in the context of word i. The context of the words consist of the words preceding or succeeding the word in the text.  \n",
    "\n",
    "By deriving an SVD from the word co-occurrence matrix, and selecting the top dimensions of the latent space, we obtain a word representation as vectors over a concept space. Commonly such word representations are also called word embeddings.\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build the vocabulary by selecting top-k frequent words\n",
    "No code is required for this part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# vocabulary is the list of all words\n",
    "# vocabulary_to_index maps words to their index\n",
    "\n",
    "def create_vocabulary_frequency(corpus, vocab_len):\n",
    "    '''Select top-k (k = vocab_len) words in term of frequencies as vocabulary'''\n",
    "    vocabulary_to_index = {}\n",
    "    count = defaultdict(int)\n",
    "    for document in corpus:\n",
    "        for word in document.split():\n",
    "                count[word] += 1\n",
    "    \n",
    "    sorted_count_by_freq = sorted(count.items(), key=lambda kv: kv[1], reverse=True)\n",
    "\n",
    "    vocabulary = []\n",
    "    for i, x in enumerate(sorted_count_by_freq[:vocab_len]):\n",
    "        vocabulary.append(x[0])\n",
    "        vocabulary_to_index[x[0]] = i\n",
    "    return vocabulary, vocabulary_to_index\n",
    "\n",
    "vocab_freq, vocabulary_to_index = create_vocabulary_frequency(documents, 5000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct the word cooccurence matrix\n",
    "\n",
    "In this question, you need to construct the word co-occurence matrix, given the vocabulary and the set of documents.\n",
    "\n",
    "The value of a cell (i,j) is the number of times the word i co-occurs with the word j in the context of word i.\n",
    "\n",
    "For this question, a word $w_i$ cooccurs with a word $w_j$ in the context of word $w_i$ if $w_j$ preceeds or succeeds $w_i$ with a distance **at most 2**.\n",
    "\n",
    "Example: For this document \"*how to bake bread without bake recip*\", the words coocur with the word \"*bread*\" are \"*to, bake, without, bake*\".\n",
    "\n",
    "Make sure that you consider only words that appear in the vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def construct_word_cooccurence_matrix(vocabulary_to_index, documents, k=2):\n",
    "    matrix = np.zeros((len(vocabulary_to_index), len(vocabulary_to_index)))\n",
    "    for document in documents:\n",
    "        terms = document.split()\n",
    "        for ind, term_i in enumerate(terms):\n",
    "            if term_i in vocabulary_to_index:\n",
    "                for context_ind in range(max(0, ind-2), min(len(terms), ind+3)):\n",
    "                    if context_ind != ind and terms[context_ind] in vocabulary_to_index:\n",
    "                        matrix[vocabulary_to_index[term_i], vocabulary_to_index[terms[context_ind]]] += 1\n",
    "    return matrix\n",
    "\n",
    "word_cooccur_matrix = construct_word_cooccurence_matrix(vocabulary_to_index, documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can optionally check whether the matrix you constructed is correct using the following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert_matrix = False\n",
    "if assert_matrix:\n",
    "    word_coor_mat = np.load(\"word_coocur_matrix.npy\")\n",
    "    assert(word_coor_mat == word_cooccur_matrix[:100,:100]).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Perform SVD on the matrix and select the largest singular values \n",
    "\n",
    "We perform SVD on the matrix $\\mathbf{M} = \\mathbf{K}\\mathbf{S}\\mathbf{D}^T$ and select the first 128 largest singular values.\n",
    "\n",
    "Then, we can use the submatrix $\\mathbf{K_s}$, corresponding to the largest singular values, as the word representation matrix. \n",
    "\n",
    "Hint 1 : Are the words represented in $\\mathbf{K_s}$ as rows or columns?\n",
    "\n",
    "Hint 2: np.linalg.svd(M, full_matrices=False) performs SVD on the matrix $\\mathbf{M}$ and returns $\\mathbf{K}, \\mathbf{S}, \\mathbf{D}^T$\n",
    "\n",
    " -  $\\mathbf{K}, \\mathbf{D}^T$ are matrices with orthonormal columns\n",
    " -  $\\mathbf{S}$ is a **vector** of singular values in a **descending** order\n",
    " \n",
    "Hint 3: np.diag(V) converts a vector to a diagonal matrix\n",
    "\n",
    "Hint 4: To select:\n",
    " - the first k rows of a matrix A, use A[0:k, :]\n",
    " - the first k columns of a matrix A, use A[:, 0:k]\n",
    " - the submatrix from first k rows and k columns of a matrix A, use A[0:k, 0:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input: a word coocurrence matrix and the number of singular values that will be selected\n",
    "# Output: K_s, S_s, Dt_s are similar to the defintion in the lecture\n",
    "\n",
    "def truncated_svd(word_cooccur_matrix, num_val):\n",
    "    # The following may take 1-2 minutes since we are decomposing a matrix of size 5000x1075\n",
    "    K, S, Dt = np.linalg.svd(word_cooccur_matrix, full_matrices=False) \n",
    "    \n",
    "    K_sel = K[:, :num_val]\n",
    "    S_sel = np.diag(S)[:num_val, :num_val]\n",
    "    Dt_sel = Dt[:num_val, :]\n",
    "    return K_sel, S_sel, Dt_sel\n",
    "\n",
    "K_s, S_s, Dt_s = truncated_svd(word_cooccur_matrix,128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vector-based retrieval using Word representations\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Document and query vectors from word representations\n",
    "\n",
    "For each document and query, we construct the corresponding vector by **averaging** its word representations.\n",
    "\n",
    "Hint: not all words are in the vocabulary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_doc_vecs(documents, word_embedding_matrix, vocabulary_to_index):\n",
    "    doc_vecs = np.zeros((len(documents), word_embedding_matrix.shape[1]))\n",
    "\n",
    "    w_emb = lambda w: word_embedding_matrix[vocabulary_to_index[w]] if w in vocabulary_to_index else np.zeros((word_embedding_matrix.shape[1]))\n",
    "    d_emb = lambda d: np.average(list(map(w_emb, d.split()+[''])), axis=0)\n",
    "\n",
    "    doc_vecs = np.stack(list(map(d_emb, documents)), axis=0)\n",
    "    \n",
    "    return doc_vecs\n",
    "\n",
    "doc_vecs = get_doc_vecs(documents, K_s, vocabulary_to_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retrieve top-10 relevant documents\n",
    "\n",
    "Retrieve top-10 relevant documents for the query \"*computer science*\"\n",
    "\n",
    "Hint: you may use the function get_doc_vecs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"computer science\"\n",
    "\n",
    "query_vec = get_doc_vecs([query], K_s, vocabulary_to_index)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/smeros/.miniconda3/lib/python3.7/site-packages/ipykernel_launcher.py:8: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  \n"
     ]
    }
   ],
   "source": [
    "def cosine_similarity(v1, v2):\n",
    "    sumxx, sumxy, sumyy = 0, 0, 0\n",
    "    for i in range(len(v1)):\n",
    "        x = v1[i]; y = v2[i]\n",
    "        sumxx += x*x\n",
    "        sumyy += y*y\n",
    "        sumxy += x*y\n",
    "    return sumxy*1.0/math.sqrt(sumxx*sumyy)\n",
    "\n",
    "def retrieve_documents(doc_vecs, query_vec, top_k):\n",
    "    scores = [[cosine_similarity(query_vec, doc_vecs[d,:]), d] for d in range(len(documents))]\n",
    "    scores.sort(key=lambda x: -x[0])\n",
    "    doc_ids = []\n",
    "    retrieved = []\n",
    "    for i in range(top_k):\n",
    "        doc_ids.append(scores[i][1])\n",
    "        retrieved.append(orig_docs[scores[i][1]])\n",
    "    return doc_ids, retrieved\n",
    "\n",
    "retrieved_ids, retrieved_docs = retrieve_documents(doc_vecs, query_vec, top_k=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation\n",
    "We consider the scikit reference code as an ‚Äúoracle‚Äù that supposedly gives the correct result. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieval oracle \n",
    "tf = TfidfVectorizer(analyzer='word', ngram_range=(1,1), vocabulary=vocab_freq, min_df = 1, stop_words = 'english')\n",
    "features = tf.fit_transform(documents)\n",
    "npm_tfidf = features.todense()\n",
    "\n",
    "# Return all document ids that that have cosine similarity with the query larger than a threshold\n",
    "def search_vec_sklearn(query, features, threshold=0.1):\n",
    "    new_features = tf.transform([query])\n",
    "    cosine_similarities = linear_kernel(new_features, features).flatten()\n",
    "    related_docs_indices, cos_sim_sorted = zip(*sorted(enumerate(cosine_similarities), key=itemgetter(1), \n",
    "                                                       reverse=True))\n",
    "    doc_ids = []\n",
    "    for i, cos_sim in enumerate(cos_sim_sorted):\n",
    "        if cos_sim < threshold:\n",
    "            break\n",
    "        doc_ids.append(related_docs_indices[i])\n",
    "    return doc_ids\n",
    "\n",
    "# gt_ids are the document ids retrieved by the oracle\n",
    "gt_ids = search_vec_sklearn(query, features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also assume that there is a user that has done the grading of all the documents according to their relevance. \n",
    "The top-10 results using scikit-learn have grade 3, the next 10 results have grade 2, \n",
    "the rest in the list has grade 1 while non-relevant results have grade 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "grade = []\n",
    "for i in range(len(documents)):\n",
    "    if i in gt_ids[:10]:\n",
    "        grade.append(3)\n",
    "    elif i in gt_ids[10:20]:\n",
    "        grade.append(2)\n",
    "    elif i in gt_ids[20:]:\n",
    "        grade.append(1)\n",
    "    else:\n",
    "        grade.append(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate retrieval result using DCG \n",
    "\n",
    "Discounted Cumulative Gain (DCG) is a retrieval metric that also takes into account the ordering of the result. \n",
    "\n",
    "The DCG accumulated at a rank $k$ is defined as:\n",
    "\n",
    "$DCG_k = \\sum_{i=1}^k \\frac{grade[i]}{log_2(i+1)}$\n",
    "\n",
    "where $grade[i]$ is the relevance score given by the user for the result at position $i$.\n",
    "\n",
    "Hint: the logarithm is computed using the function np.log2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg(k, retrieved_ids, grade):\n",
    "    dcg_val = 0\n",
    "    for i in range(1, k):\n",
    "        dcg_val += grade[i] / math.log2(i+1)\n",
    "    return dcg_val"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the DCG for the top-1 to the top-10 retrieval results and we plot the values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1a24d003d0>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "vals = []\n",
    "for i in range(10):\n",
    "    val = dcg(i, retrieved_ids, grade)\n",
    "    vals.append(val)\n",
    "    \n",
    "plt.plot(vals)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explain the DCG values plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Submit your notebook\n",
    "\n",
    "Go to [Moodle](https://moodle.epfl.ch/course/view.php?id=4051) > Exams > Midterm and follow the instructions.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "name": "_merged",
  "toc": {
   "base_numbering": "0",
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Table of Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": false,
   "toc_window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "75fd394e35225182f207b93437350142e41aafd8fa2b11cc1a17258e1fa2f196"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
